<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.4">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Introduction â€“ The Biostatistics Book</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./part_A.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script async="" src="https://hypothes.is/embed.js"></script><script>
  window.document.addEventListener("DOMContentLoaded", function (_event) {
    document.body.classList.add('hypothesis-enabled');
  });
</script><script src="site_libs/kePrint-0.0.1/kePrint.js"></script><link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script><script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script><script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">
<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    <img src="./logo.png" alt="" class="navbar-logo"></a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">The Biostatistics Book</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./The-Biostatistics-Book.pdf">
              <i class="bi bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./The-Biostatistics-Book.epub">
              <i class="bi bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
      </ul>
</div>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-1" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-1">
<li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
      </ul>
</div>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./intro.html"><span class="chapter-title">Introduction</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part_A.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Parametric Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Correlation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./simple_linear_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./polynomial_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Polynomial Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./multiple_linear_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Multiple Linear Regression</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generalised_linear_models.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Generalised Linear Models (GLM)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./non-linear_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Nonlinear Models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regularisation.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Regularisation Techniques</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part_B.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Non-Parametric Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./assumption_tests.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Testing Assumptions</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quantile_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Quantile Regression</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./part_C.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Semi-Parametric Methods</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./generalised_additive_models.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Generalised Additive Models</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Summary</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Appendix A</span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">On this page</h2>
   
  <ul class="collapse">
<li><a href="#the-scientific-method-in-practice" id="toc-the-scientific-method-in-practice" class="nav-link active" data-scroll-target="#the-scientific-method-in-practice">The Scientific Method in Practice</a></li>
  <li><a href="#the-statistical-toolbox" id="toc-the-statistical-toolbox" class="nav-link" data-scroll-target="#the-statistical-toolbox">The Statistical Toolbox</a></li>
  <li><a href="#i.-parametric-methods-known-distribution" id="toc-i.-parametric-methods-known-distribution" class="nav-link" data-scroll-target="#i.-parametric-methods-known-distribution">I. Parametric Methods (Known Distribution)</a></li>
  <li><a href="#ii.-non-parametric-methods-distribution-free" id="toc-ii.-non-parametric-methods-distribution-free" class="nav-link" data-scroll-target="#ii.-non-parametric-methods-distribution-free">II. Non-Parametric Methods (Distribution-Free)</a></li>
  <li><a href="#iii.-semi-parametric-methods" id="toc-iii.-semi-parametric-methods" class="nav-link" data-scroll-target="#iii.-semi-parametric-methods">III. Semi-Parametric Methods</a></li>
  <li><a href="#iv.-machine-learning-methods" id="toc-iv.-machine-learning-methods" class="nav-link" data-scroll-target="#iv.-machine-learning-methods">IV. Machine Learning Methods</a></li>
  <li><a href="#v.-miscellaneous-methods" id="toc-v.-miscellaneous-methods" class="nav-link" data-scroll-target="#v.-miscellaneous-methods">V. Miscellaneous Methods</a></li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-title">Introduction</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><section id="the-scientific-method-in-practice" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="the-scientific-method-in-practice">The Scientific Method in Practice</h2>
<p>Answering questions about the natural world using a scientific workflow requires that we draw on many yearsâ€™ of accumulated knowledge and experience. The workflow unpacks into roughly the following sequence of steps:</p>
<ol type="1">
<li>Look around you at the world, be curious about it, and ask questions to figure out an explanation for the pattern or phenomenon that tickled your interest.</li>
<li>Create an unambiguous statement of the question you want to answer, think about what is causing the pattern or phenomenon you observed, and how you might go about measuring the response (the thing you observed initially).</li>
<li>Translate this question into a testable hypothesis. This is the statement that you can test using the data you will collect.</li>
<li>Design an experiment or sampling campaign to collect data that will allow you to test this hypothesis. Clearly understand what the data youâ€™ll collect will look like, both for the response and the explanatory variables. For example, do you have a categorical or continuous predictor, is the response continuous, binary, ordinal, etc.? For this, you should have a firm grasp of the various kinds of <a href="https://tangledbank.netlify.app/BCB744/basic_stats/01-data-in-R.html">Data Classes and Structures in R</a>.</li>
<li>Think deeply about any confounding influences that might affect your data, and specify exactly what additional data you will have to collect to isolate the hypothesised influence in your analysis. You need to fully understand all the ways that factors not considered in your hypothesis might affect your studyâ€™s outcome. Omissions cannot be rectified after the fact without repeating the entire experiment or sampling work. It requires knowledge and experience to avoid confounding influences ruining your work.</li>
<li>Depending on your experimentâ€™s design (4) and the nature of the data youâ€™ll obtain (4, 5), choose the appropriate statistical methods to analyse them. You should be able to develop a good idea of what statistical methods youâ€™ll useâ€”even before the experiment has been done! Decide on the parametric test, or, should the statistical god with the dice not provide an outcome that favours your expectations, you can also decide upfront on a non-parametric equivalent. It is important not to decide on the statistical method after youâ€™ve collected the data. This is called <em>p</em>-hacking, and it is almost a cardinal sin in science.</li>
<li>Do the experiment or go out into the world to sample, and collect the data. Have funâ€”this is why we do science, afterall!</li>
<li>Go have a few drinks after a hard dayâ€™s work and celebrate your success.</li>
<li>Analyse your newly-collected data. This will include explaratory data analyses (see <a href="https://tangledbank.netlify.app/BCB744/basic_stats/02-summarise-and-describe.html">Exploring With Summaries and Descriptions</a> and <a href="https://tangledbank.netlify.app/BCB744/basic_stats/03-visualise.html">Exploring With Figures</a>), and then the application of the statistical methods you chose in step 6.</li>
<li>Communicate your results in tables and figures.</li>
</ol>
<p>This textbook deals with many of these steps (except for 1, 5, and 7). This knowledge is codified in the form of the statistical method, which provides a systematic framework for collecting,<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> analysing, and interpreting data. In this chapter, I introduce the fundamental concepts of inferential statistics, which allow us to make inferences about populations based on sample data. I also provide an overview of the types of statistical methods used in inferential statistics, and discuss the importance of understanding the assumptions underlying these methods.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Yes, statistics also informs us about how to collect data.</p></div></div></section><section id="the-statistical-toolbox" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="the-statistical-toolbox">The Statistical Toolbox</h2>
<p>With inferential statistics you can analyse data obtained from representative samples to draw conclusions or test hypotheses about populations or processes. I broadly categorise these methods into four main types, each serving different research applications<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>:</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;This categorisation reflects my teaching approach, based on the order in which I think topics need to be covered, rather than a strict classification by statisticians. It is intended to provide a high-level overview of the types of statistical methods used in inferential statistics.</p></div></div><ol type="1">
<li>
<p><strong>Hypothesis Tests</strong>: These parametric and non-parametric techniques assess whether sample data provide evidence for or against a specific claim (hypothesis) about population parameters such as their means, proportions, variances, or correlations between variables. Common hypothesis tests include:</p>
<ul>
<li>Comparisons of group means or medians for a continuous variable (e.g., <em>t</em>-tests, ANOVA, Mann-Whitney <em>U</em> test)</li>
<li>Comparisons of group proportions for a categorical variable (e.g., <span class="math inline">\chi</span>-square test, Fisherâ€™s exact test)</li>
<li>Assessments of the relationship between two continuous or ordinal variables (e.g., Pearsonâ€™s correlation, Spearmanâ€™s rank correlation)</li>
</ul>
</li>
<li>
<p><strong>Regression Analysis</strong>: Regression with its parametric and non-parametric offerings lets us analyse the relationship between a response variable and one or more predictor variables. Regression models estimate coefficients representing the predictor effects, allow for prediction of the response, and enable hypothesis tests on the predictors. Common regression models include:</p>
<ul>
<li>Linear regression for continuous response variables</li>
<li>Logistic regression for binary response variables</li>
<li>Generalised linear models (GLMs) for non-normal response variables</li>
<li>Various non-linear regressions for complex relationships, such as generalised additive models (GAMs)</li>
</ul>
</li>
<li><p><strong>Survival Analysis</strong>: Methods like the Kaplan-Meier estimator and Cox proportional hazards model analyse time-to-event data, where the interest lies in modelling the waiting times until certain events occur. I do not cover survival analysis in this book or any of my modules.</p></li>
<li><p><strong>Multivariate Analysis:</strong> This includes an assortment of methods to analyse multiple response and predictor variables simultaneously. Dimension reduction methods, such as canonical correlation analysis (CCA) and non-metric multidimensional scaling (nMDS), help simplify complex datasets by identifying key patterns and relationships. Classification, including cluster analysis, is used to group similar observations together based on their characteristics. Multivariate approaches make fewer assumptions about the dataâ€™s distribution, and there are techniques to deal with parametric and non-parametric data types (often without discrimination). Although these methods are not covered in this textbook, they are taught in my <a href="https://tangledbank.netlify.app/BCB743/BCB743_index.html">Quantitative Ecology</a> module, which will eventually be developed into its own textbook.</p></li>
</ol>
<p>The above methods include parametric or non-parametric (sometimes called â€˜robustâ€™) methods. Parametric methods assume that the data follow a specific distribution (e.g., normal, Poisson), while non-parametric methods make fewer assumptions about the data distribution. I will cover the parametric methods first, in Part A, followed by non-parametric methods in Part B. Part C of the book will look at semi-parametric methods, which combine aspects of both parametric and non-parametric approaches.</p>
</section><section id="i.-parametric-methods-known-distribution" class="level2 page-columns page-full"><h2 class="anchored" data-anchor-id="i.-parametric-methods-known-distribution">I. Parametric Methods (Known Distribution)</h2>
<p>Parametric statistics rely on specific assumptions about the underlying probability distribution of the population from which the sample data were drawn. Biologists are taught that our data must be normally distributed, but this an unreasonable expectation considering the widely varying data sources we will encounter. Some biological processes simply do not generate normally distributed data!</p>
<p>Nevertheless, parametric statistics have through convention (rather than best practice) become the starting point for introductory forays into statistics. This is not terrible, because, should we be fortunate enough to have normally distributed data, parametric methods are more powerful than their non-parametric counterparts; however, they are also more sensitive to violations of some assumptions about our data.</p>
<p>The staple parametric statistics, such as the <em>t</em>-test, ANOVAs, Pearson correlation, and simple linear regression, require that two key assumptions are met: i) that our data (or sometimes the residuals) are <strong>normality distributed</strong> and ii) that the <strong>variances are homoscedastic</strong>. Section X is devoted to statistical tests that we may use to test the assumptions. However, because of the Central Limit Theorem, parametric methods can withstand moderate violations of the normality assumption when the sample size is large.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;The CLT states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, even if the underlying population is not perfectly normal.</p></div><div id="fn4"><p><sup>4</sup>&nbsp;In fact, many statistical tests that would ordinarily require the assumption of normality to be met have been extended to other probability distributions, as can be seen from the practice to append the word â€˜Generalisedâ€™ to the name of the test. For example, the Generalised Additive Model (GAM) is a generalised semi-parametric method, Generalised Non-Linear Models (GNLMs) permit fitting non-linear models to non-parametric data, and Generalised Linear and Non-Linear Mixed-Effects Models (GLMMs and GNLMMs) do the same with hierarchical data.</p></div></div><p>A common mistake biologists makes is to think that parametric tests only apply to normal data. This is not true. Generalised linear models (GLMs) extend the statistical framework to accommodate non-normal error distributions, such as Poisson for count data or binomial for binary outcomes.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> GLMs require that the distribution of the response variable belongs to the exponential family of distributions and that a suitable link function is chosen to connect the mean of the response to the linear predictor. Therefore, the defining characteristic of parametric methods is the assumption of a <strong>known distribution</strong> for the response variable, not necessarily that is is normal.</p>
<p>Within the parametric statistics framework, we can divide the methods into four groups depending on the type of question we are asking. We can ask questions about i) <strong>difference in means</strong>, ii) <strong>differences in proportions</strong>, iii) <strong>relationships between variables</strong>, or iv) the <strong>effect of one or more predictors on a response variable</strong>.</p>
<section id="a.-hypotheses-about-the-means-of-groups" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="a.-hypotheses-about-the-means-of-groups">A. Hypotheses About the Means of Groups</h3>
<p>The simplest form of comparison is to test whether the sample <strong>means</strong> of two or more groups differ.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> Although this seems quite unimaginative, comparisons of the measures of central tendency are very common statistical tests in biology. Because this concept is so simple to understand, it serves as a good starting point for learning about hypothesis testing and the interpretation of the statistics which tell us about the strength of the evidence for or against our hypotheses.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;When it comes to central tendency, the mean is the parameter that is being compared by parametric statistics. Non-parametric statistics, on the other hand, consider the median as the statistic of central tendency.</p></div></div><p>You might have hypotheses that require you to compare the means of the outcomes of different experimental treatments, differences in the number of sea urchins among populations of kelp, or the number of species within replicate samples taken from different vegetation types. Look at some of the following examples to see if any of them resonate with your own research question, and then use this as a guide to find the appropriate statistical test in this book.</p>
<section id="one-sample-t-test-section-x.x.x" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="one-sample-t-test-section-x.x.x">One-Sample <em>t</em>-Test (Section X.X.X)</h4>
<p><strong>Example:</strong> Is the mean height of a sample of <em>Protea</em> sp. grown in a specific experimental landscape (given below) different from the known (established <em>a priori</em>) average height of the same species (163.3 <span class="math inline">\pm</span> 15.5 cm) in the general population?</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>   Height
1     150
2     152
3     148
8     150
9     149
10    148</code></pre>
</div>
</div>
<p>The example requires that you have <em>one normally-distributed continuous outcome variable</em> with <em>independent observations</em> and that you want to compare its mean value against a known population mean established <em>a priori</em>.</p>
<p>In this case, youâ€™ll want to use the R function <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code>. Since this function can accommodate data with equal or unequal variances<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> via the <code>var.equal</code> argument, you only need to assure the data are normally distributed. The test can be one-sided or two-sided. Alternatively, consider non-parametric alternatives, such as the Wilcoxon signed-rank test.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;A <em>t</em>-test for equal variances is typically called the Studentâ€™s <em>t</em>-test, while a <em>t</em>-test for unequal variances is called Welchâ€™s <em>t</em>-test. By default, the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function in R performs Welchâ€™s <em>t</em>-test, which is more robust to unequal variances.</p></div></div></section><section id="two-sample-t-test-section-x.x.x" class="level4"><h4 class="anchored" data-anchor-id="two-sample-t-test-section-x.x.x">Two-Sample <em>t</em>-Test (Section X.X.X)</h4>
<!-- **Example:** Is the uptake rate of ammonium by *Chlorella* sp. in the presence of a nitrogen-fixing bacteria different from the uptake rate in the absence of the bacteria? -->
<p><strong>Example:</strong> Is the average number of leopard cubs born per female leopard in the Overberg region different from that in the Cederberg region? The dataset is:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>      Region Cubs_Per_Female
1   Overberg               2
2   Overberg               3
3   Overberg               2
18 Cederberg               3
19 Cederberg               2
20 Cederberg               1</code></pre>
</div>
</div>
<p>This requires that we obtain <em>two samples of continuous, normally-distributed measurements</em>. In other words, our experiment or sampling campaign will include two groups (sometimes two treatments, other times a treatment and a control) and we collect a sample of measurements of the response in both of them. This is again catered for by the <code><a href="https://rdrr.io/r/stats/t.test.html">t.test()</a></code> function, and, as before, we donâ€™t have to fuss too much about the variances as equal and unequal variances can be accommodated. If the normality assumption is not met, consider a non-parametric alternative such as the Mann-Whitney U test.</p>
<p>A variant of the two-sample <em>t</em>-test is the paired <em>t</em>-test, which is used when the two samples are related (not independent); for example, the same individuals are measured before and after applying a treatment.</p>
</section><section id="analysis-of-variance-anova-for-2-samples-section-x.x.x" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="analysis-of-variance-anova-for-2-samples-section-x.x.x">Analysis of Variance (ANOVA) for &gt;2 Samples (Section X.X.X)</h4>
<!-- **Example:** Is the average density of kelp plants within a kelp forest the same within a marine protected area compared to areas 2 km and 5 km away from the MPA? -->
<p><strong>Example:</strong> Is the chirp rate of bladder grasshoppers different between the four seasons?</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<table class="table table-sm table-striped small">

<thead><tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">Season</th>
<th style="text-align: right;">Chirp Rate</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">Spring</td>
<td style="text-align: right;">17.7</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">Spring</td>
<td style="text-align: right;">13.9</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">Spring</td>
<td style="text-align: right;">15.7</td>
</tr>
<tr class="even">
<td style="text-align: left;">58</td>
<td style="text-align: left;">Winter</td>
<td style="text-align: right;">10.2</td>
</tr>
<tr class="odd">
<td style="text-align: left;">59</td>
<td style="text-align: left;">Winter</td>
<td style="text-align: right;">4.0</td>
</tr>
<tr class="even">
<td style="text-align: left;">60</td>
<td style="text-align: left;">Winter</td>
<td style="text-align: right;">10.6</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Chirp Rate Data for Bladder Grasshoppers Across Four Seasons</div></div>
</div>
<p>We have <em>three or more samples of continuous, normally-distributed observations</em>. These data must also have more-or-less equal variances, so the homoscedasticity assumption is important. The <code><a href="https://rdrr.io/r/stats/aov.html">aov()</a></code> function in R is used to perform the ANOVA, which can be one-way, two-way, a repeated measures ANOVA, or an ANCOVA.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> If the normality or homoscedasticity assumptions are not met, consider non-parametric alternatives, such as the Kruskal-Wallis test, or try transforming the data.</p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;A repeated measures ANOVA is used when the same subjects are measured at different time points or under different conditions. A two-way ANOVA is used when there are two independent variables (there are also higher-order ANOVAs but they become more of a pain to interpret and require cumbersome experimental designs). An ANCOVA is used when you want to compare the means of groups while controlling for the effect of a continuous covariate. There are many kinds of ANOVA designs and each relates to specific experimental designs well beyond the scope of this book. Tony Underwood provides a pedantic overview of ANOVA designs in his book <em>Experiments in Ecology</em> <span class="citation" data-cites="underwood1997experiments">(<a href="references.html#ref-underwood1997experiments" role="doc-biblioref">Underwood 1997</a>)</span> if you really want to go there.</p></div></div></section><section id="analysis-of-covariance-ancova-section-x.x.x" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="analysis-of-covariance-ancova-section-x.x.x">Analysis of Covariance (ANCOVA)* (Section X.X.X)</h4>
<p><strong>Example:</strong> We have a set of data about African penguins and we want to determine if there are differences between male and female penguins in terms of their mean foraging time, and if that difference is influenced by their diving depth. The dataset is as follows:</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<table class="lightable-classic table table-sm table-striped small" data-quarto-postprocess="true">

<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Sex</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Foraging time (hr)</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Diving depth (m)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="even">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">15</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">20</td>
</tr>
<tr class="even">
<td style="text-align: center;">Female</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">25</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">30</td>
</tr>
<tr class="even">
<td style="text-align: center;">Female</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">35</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Female</td>
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">40</td>
</tr>
<tr class="even">
<td style="text-align: center;">Female</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">45</td>
</tr>
<tr class="odd">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">3.3</td>
<td style="text-align: center;">50</td>
</tr>
<tr class="even">
<td style="text-align: center;">Male</td>
<td style="text-align: center;">3.5</td>
<td style="text-align: center;">55</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Foraging time and diving depth of African penguin.</div></div>
</div>
<p>In this example, we are interested in the mean foraging time of male and female penguins, controlling for their diving depth. An ANCOVA focuses on the differences in means (the categorical variable), and the continuous covariates (diving depth) is specifically controlled for to remove its effect from the dependent variable. This reduces the error variance and so more accurately assesses the comparison of group means. The assumptions of normality and homoscedasticity apply. The functions <code><a href="https://rdrr.io/r/stats/aov.html">aov()</a></code> accommodates the categorical and continuous predictors.</p>
</section><section id="multivariate-analysis-of-variance-manova" class="level4"><h4 class="anchored" data-anchor-id="multivariate-analysis-of-variance-manova">Multivariate Analysis of Variance (MANOVA)</h4>
<p>MANOVAs are similar to ANOVAs, except here you have <em>multiple dependent variables</em>, all <em>independent, continuous, and normally-distributed</em>. This is useful when you want to compare the means of multiple groups across multiple dependent variables. For example, you might want to compare the average foraging time together with diving depth of African penguins in three colonies (two in South Africa and one in Namibia) around the coast. The <code><a href="https://rdrr.io/r/stats/manova.html">manova()</a></code> function in R is used to perform a MANOVA and there are similar variants to what we have seen in ANOVA.</p>
</section></section><section id="b.-hypotheses-about-the-proportions-of-groups" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="b.-hypotheses-about-the-proportions-of-groups">B. Hypotheses About the Proportions of Groups</h3>
<p>You can compare the proportions of groups using tests for proportions when the outcome variable is binary (e.g., success/failure, presence/absence, up/down, day/night). These tests are used to determine if the proportion of successes differs between groups. Use the following tests to compare group proportions:</p>
<section id="one-sample-test-for-proportions" class="level4"><h4 class="anchored" data-anchor-id="one-sample-test-for-proportions">One-Sample Test for Proportions</h4>
<p><strong>Example:</strong> Is the proportion of African penguins foraging in a specific colony different from the known proportion of the same species in the general population? The data might look like this:</p>
<ul>
<li><code>Sample data: 55 of the 100 penguins observed were foraging in a specific colony</code></li>
<li><code>The known proportion of penguins foraging in the general population is 60%</code></li>
</ul>
<p>In this scenario, we are comparing the proportion of a single sample (the proportion of foraging African penguins in a specific colony) to a known population proportion. The data must consist of a <em>binary outcome variable</em> (e.g., foraging vs.&nbsp;not foraging) and the observations must be independent. The <code><a href="https://rdrr.io/r/stats/prop.test.html">prop.test()</a></code> function in R is used to perform this test, which can be either one-sided or two-sided. If the requirement of independent observations is not met, consider non-parametric alternatives, such as the sign test.</p>
</section><section id="two-sample-test-for-proportions" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="two-sample-test-for-proportions">Two-Sample Test for Proportions</h4>
<p><strong>Example:</strong> Is the proportion of endangered sea turtles successfully reaching the ocean different between two beaches? Here are data:</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<table class="table table-sm table-striped small">

<thead><tr class="header">
<th style="text-align: left;">Beach</th>
<th style="text-align: right;">Successes</th>
<th style="text-align: right;">Observed</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Beach A</td>
<td style="text-align: right;">75</td>
<td style="text-align: right;">100</td>
</tr>
<tr class="even">
<td style="text-align: left;">Beach B</td>
<td style="text-align: right;">65</td>
<td style="text-align: right;">120</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Number of Sea Turtles Reaching the Ocean on Two Beaches</div></div>
</div>
<p>Here we compare the proportions from two independent samples (e.g., the proportion of sea turtles successfully reaching the ocean on Beach A versus Beach B). As before, the data yield <em>a binary outcome</em> (e.g., reached the ocean vs.&nbsp;did not reach the ocean) for each group, and the observations within each group are independent. The <code><a href="https://rdrr.io/r/stats/prop.test.html">prop.test()</a></code> function is used it has one-sided or two-sided options. If the sample sizes are small or expected frequencies are low, consider using Fisherâ€™s exact test instead of the proportion test. If the assumption of independent observations within groups is violated, you may need to consider methods that account for dependency in the data, such as Generalised Estimating Equations (GEE) or mixed-effects models.</p>
</section><section id="chi-square-test-for-count-data" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="chi-square-test-for-count-data">Chi-square Test for Count Data</h4>
<p><strong>Example:</strong> Is there an association between vegetation type and the presence of leopards in different areas of Kruger National Park? A hypothetical dataset:</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<table class="table table-sm table-striped small">

<thead><tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Presence</th>
<th style="text-align: right;">Absence</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Grassland</td>
<td style="text-align: right;">20</td>
<td style="text-align: right;">30</td>
</tr>
<tr class="even">
<td style="text-align: left;">Woodland</td>
<td style="text-align: right;">25</td>
<td style="text-align: right;">40</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Shrubland</td>
<td style="text-align: right;">35</td>
<td style="text-align: right;">15</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Contingency Table of Plant Species and Insect Occurrence</div></div>
</div>
<p>Here we examine the relationship between two categorical variables (vegetation type and leopard presence) within Kruger National Park. The data are organised into a contingency table, where each cell represents the count or frequency of observations for a specific combination of categories. The chi-square test of independence is used to determine if thereâ€™s a significant association between the variables.</p>
<p>As with other categorical tests, the data yield <em>discrete outcomes</em> (e.g., savanna, woodland, or riverine for vegetation type; present or absent for leopard presence). The observations should be independent, meaning the presence of a leopard in one area should not influence its presence in another.</p>
<p>The <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code> function in R is commonly used for this analysis. This test compares the observed frequencies in each cell of the contingency table to the frequencies that would be expected if there were no association between vegetation type and leopard presence.</p>
<p>If the sample size is large and the expected frequencies in each cell are adequate (typically &gt; 5), the chi-square test is appropriate. However, if the sample size is small or if there are cells with low expected frequencies, consider using Fisherâ€™s exact test instead.</p>
<p>If the assumption of independence is violated (e.g., if the data include multiple observations from the same leopard individuals or territories), you may need to consider more advanced methods that account for dependency in the data, such as log-linear models or Generalised Estimating Equations (GEE).</p>
</section><section id="fishers-exact-test" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="fishers-exact-test">Fisherâ€™s Exact Test</h4>
<p><strong>Example:</strong> Is there a significant association between the presence of certain plant species and the occurrence of rare fynbos endemic insects in the Cape Floristic Region? Here are the data:</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<table class="table table-sm table-striped small">

<thead><tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">Present</th>
<th style="text-align: right;">Absent</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Plant A</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">8</td>
</tr>
<tr class="even">
<td style="text-align: left;">Plant B</td>
<td style="text-align: right;">3</td>
<td style="text-align: right;">7</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Contingency Table of Plant Species and Insect Occurrence</div></div>
</div>
<p>Fisherâ€™s Exact Test is used when we have two categorical variables and want to determine if thereâ€™s a significant association between them, particularly when sample sizes are small or when we have sparse data in some categories. This test is especially useful in ecological studies where rare species or events are being investigated.</p>
<p>In this example we examine the relationship between the presence of specific plant species and the occurrence of rare fynbos endemic insects. The data are organised into a 2x2 contingency table, where each cell represents the count of observations for a combination of presence/absence of the plant species and the insect species.</p>
<p>The test calculates the exact probability of observing the given set of cell frequencies under the null hypothesis of no association. It does not rely on approximations and it more accurate than the chi-square test for small samples. Use the <code><a href="https://rdrr.io/r/stats/fisher.test.html">fisher.test()</a></code> function to perform this analysis. Like other categorical tests, the observations should be independent, meaning the presence of an insect in one area should not influence its presence in another.</p>
<p>Fisherâ€™s Exact Test is particularly appropriate when:</p>
<ul>
<li>The total sample size is less than 1000</li>
<li>The expected frequency in any cell of the contingency table is less than 5</li>
<li>Youâ€™re dealing with rare events or species</li>
</ul>
<p>If the sample size becomes very large, Fisherâ€™s Exact Test can become computationally intensive, and the chi-square test may be more practical.</p>
<p>If the assumption of independence is violated (e.g., if the data include multiple observations from the same locations over time), you may need to consider more advanced methods that account for dependency in the data, such as mixed-effects models or Generalised Estimating Equations (GEE).</p>
</section></section><section id="sec-pearson" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="sec-pearson">C. Hypotheses About the Strength of Association</h3>
<p><strong>Example:</strong> Is there a relationship between the foraging time and diving depth of African penguins?</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<table class="lightable-classic table table-sm table-striped small" data-quarto-postprocess="true">

<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">Foraging time (hr)</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Diving depth (m)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">15</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">20</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">25</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">30</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">35</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">40</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">45</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3.3</td>
<td style="text-align: center;">50</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.5</td>
<td style="text-align: center;">55</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Foraging time and diving depth of African penguin.</div></div>
</div>
<p>Youâ€™ll want to use a Pearsonâ€™s correlation to determine if there is a linear relationship between <em>two continuous variables</em>, both of them normally distributed and homoscedastic. A correlation analysis does not presume causation and does not provide a predictive model, both of which are the domain of regression. The strength of the relationship is quantified by the correlation coefficient called Pearsonâ€™s rho, which ranges from -1 to 1. Use the <code>cor.test(..., method = "pearson")</code> function in R to perform this analysis.</p>
<p>Non-parametric alternatives such as the Spearmanâ€™s rank correlation or Kendallâ€™s tau correlation (see â€˜II. Non-Parametric Methodsâ€™) are available and implemented with the same R function.</p>
</section><section id="d.-modelling-and-predicting-causal-relationships" class="level3 page-columns page-full"><h3 class="anchored" data-anchor-id="d.-modelling-and-predicting-causal-relationships">D. Modelling and Predicting Causal Relationships</h3>
<p>The relationship between one or a few predictors and an outcome can be represented by a function, which is a model that reconstructs part of the â€˜realityâ€™ of the observed phenomenon. Regression analysis helps you understand how changes in the continuous predictor variable(s) drive changes in a continuous outcome variable. The model quantifies the strength of the associations and makes predictions for new data points. You may use regression models for hypothesis testing and for identifying which predictor variables have the most substantial impact on the outcome.</p>
<section id="simple-linear-regression" class="level4"><h4 class="anchored" data-anchor-id="simple-linear-regression">Simple Linear Regression</h4>
<p><strong>Example:</strong> The same dataset of <a href="#sec-pearson">foraging time and diving depth of African penguins</a> can be used to model the relationship between these two variables. Does diving depth depend on foraging time?</p>
<p>What is different now is that we are interested in <em>predicting the diving depth</em> (response) of penguins based on their foraging time (predictor). Assuming there is a linear response, we can use a simple linear regression model to quantify the relationship between these two continuous variables. The model provides an equation that describes how the diving depth changes as the foraging time increases. The assumptions of normality and homoscedasticity apply to the residuals, and are accessed after having fit the model.</p>
<p>This calls for a simple linear regression model and you can fit it using the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function in R. The model can also be specified as a generalised linear model (GLM) with <code>glm(..., family = gaussian)</code>.</p>
<p>If assumptions fail, apply data transformations (e.g., log, square root), robust regression (<code>rlm()</code> in <strong>MASS</strong> package), or consider non-linear models.</p>
</section><section id="polynomial-regression" class="level4"><h4 class="anchored" data-anchor-id="polynomial-regression">Polynomial Regression</h4>
<p>Iâ€™ll not provide an example here. It suffices to say that a polynomial regression is effectively a simple linear regression that allows for a curvilinear relationship between the predictor and the outcome. To accomplish this, the model includes polynomial terms (e.g., quadratic, cubic, which are simply powers of the predictor) to capture the non-linear patterns in the data. The model can be fit using the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function in R.</p>
<p>Assess the relationship between <span class="math inline">x</span> vs.&nbsp;<span class="math inline">y</span> by making a scatterplot of the data and eye balling a best fit curve through the scatter of points. Is the line curvy or bendy? Do you know in advance if a more complicated model describes the response? If the answer is â€˜yesâ€™ to the first and â€˜noâ€™ to the second question, then a polynomial regression might be just the thing for you.</p>
</section><section id="sec-mlr" class="level4 page-columns page-full"><h4 class="anchored" data-anchor-id="sec-mlr">Multiple Linear Regression (MLR)</h4>
<p><strong>Example:</strong> Iâ€™ve added a second predictor to the dataset of <a href="#sec-pearson">foraging time and diving depth of African penguins</a>. Does diving depth depend on the penguinsâ€™ body mass index (BMI) and foraging time?</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<table class="lightable-classic table table-sm table-striped small" data-quarto-postprocess="true">

<thead><tr class="header">
<th style="text-align: center;" data-quarto-table-cell-role="th">BMI</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Foraging time (hr)</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Diving depth (m)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">1.2</td>
<td style="text-align: center;">10</td>
</tr>
<tr class="even">
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">1.5</td>
<td style="text-align: center;">15</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">1.8</td>
<td style="text-align: center;">20</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">25</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">2.3</td>
<td style="text-align: center;">30</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">2.5</td>
<td style="text-align: center;">35</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">2.8</td>
<td style="text-align: center;">40</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">3.0</td>
<td style="text-align: center;">45</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3.3</td>
<td style="text-align: center;">3.3</td>
<td style="text-align: center;">50</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.5</td>
<td style="text-align: center;">3.5</td>
<td style="text-align: center;">55</td>
</tr>
</tbody>
</table>
<div class="quarto-table-caption margin-caption">Foraging time and diving depth of African penguin.</div></div>
</div>
<p>The only difference between this example and the simple linear regression is that we now have two predictors (foraging time and BMI) instead of one. The predictors can be <em>continuous</em> (as in the example) <em>and/or categorical</em>. If you are more concerned with the means of the categorical variables, consider an ANCOVA as an alternative option. The multiple linear regression model can be extended to include interaction terms between predictors. You can quantify the relationship between both predictors and the outcome simultaneously, and ask which of the two best predicts the response. The same assumptions apply as in the simple linear regression and we hope for a linear relationship between <span class="math inline">x_1</span> and <span class="math inline">x_2</span> vs.&nbsp;<span class="math inline">y</span>. Other considerations are provided in the chapter on <a href="./multiple_linear_regression.html">MLR</a>.</p>
<p>The R functions <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> and <code>glm(..., family = gaussian)</code> accommodate situations such as these where we have multiple predictors.</p>
</section><section id="generalised-linear-models-glm" class="level4"><h4 class="anchored" data-anchor-id="generalised-linear-models-glm">Generalised Linear Models (GLM)</h4>
<p>GLMs are a class of regression models that extend the simple linear regression framework to accommodate various types of response distributions. As such, they can accommodate data that violate the assumptions of normality and homoscedasticity, as well as situations where the response variable is not continuous.</p>
<p>Use GLMs to model count data (e.g., number of occurrences), binary outcomes (e.g., success/failure), and other non-continuous response variables that cannot be adequately represented by a normal distribution. Unlike linear models, which assume a normal error distribution, GLMs specify the distribution of the response variable using a probability distribution from the exponential family, such as the Gaussian (normal), binomial, Poisson, or negative binomial distributions.</p>
<p>GLMs incorporate a link function that relates the linear predictor (a linear combination of the predictor variables) to the expected value of the response variable. This link function can take various forms, including the identity (linear), logit (for binary data), probit, or other transformations, depending on the nature of the response variable and the desired relationship between the predictors and the outcome.</p>
<p>The <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> function is a staple for fitting GLMs. It is designed to handle the exponential family distributions and will allow you to specify the appropriate distribution and link function for your data and research question. A few common types of GLMs are presented next.</p>
<p><em>Logistic Regression</em> (<a href="generalised_linear_models.html" class="quarto-xref"><span>Generalised Linear Models (GLM)</span></a>)</p>
<p>Youâ€™ll encounter binomial data in experiments or processes with binary outcomes, such as presence/absence, success/failure, or alive/dead. To model this type of data, you will want to use logistic regression. Logistic regression estimates the log-odds of the outcome as a linear combination of the predictor variables. The logistic function is then used to convert these log-odds into probabilities, which range from 0 to 1, so it is suitable for predicting the likelihood of the binary outcomes.</p>
<ul>
<li>
<strong>Use When:</strong> You have a binary outcome variable and want to model the relationship between predictors and the probability of the outcome.</li>
<li>
<strong>Data Requirements:</strong> Binary outcome, continuous or categorical predictors.</li>
<li>
<strong>Assumptions:</strong> Linear relationship between the log-odds of the outcome and predictors.</li>
<li>
<strong>Diagnostics:</strong> Check for influential observations, multicollinearity, and overall model fit.</li>
<li>
<strong>If Assumptions Fail:</strong> Consider interactions, alternative link functions (probit, complementary log-log) in <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code>, or non-linear logistic regression, zero-inflated models when excess zeroes.</li>
<li>
<strong>R Function:</strong> <code>glm(..., family = binomial)</code>
</li>
<li>
<strong>Model Selection:</strong> Stepwise regression, regularisation techniques, information criteria (AIC, BIC).</li>
</ul>
<p><em>Poisson Regression</em> (<a href="generalised_linear_models.html" class="quarto-xref"><span>Generalised Linear Models (GLM)</span></a>)</p>
<p>Typical examples of count data include the number of offspring, parasites, or seeds. Poisson regression is used to model the relationship between predictors and the count outcome. The model assumes that the count data follow a Poisson distribution, where the mean and variance are equal. Poisson regression is suitable for data with a single count outcome.</p>
<ul>
<li>
<strong>Use When:</strong> You have count data and want to model the relationship between predictors and the count outcome.</li>
<li>
<strong>Data Requirements:</strong> Count outcome, continuous or categorical predictors.</li>
<li>
<strong>Assumptions:</strong> Equidispersion (variance equals the mean).</li>
<li>
<strong>Diagnostics:</strong> Check for overdispersion, excess zeros, and overall model fit.</li>
<li>
<strong>If Assumptions Fail:</strong> Negative binomial regression (<code>glm.nb()</code> in the <strong>MASS</strong> package, overdispersion), zero-inflated models (<code>zeroinfl()</code> in the <strong>pscl</strong> package, excess zeros).</li>
<li>
<strong>R Function:</strong> <code>glm(..., family = poisson)</code>
</li>
</ul>
<p><em>Negative Binomial Regression</em></p>
<p>Negative binomial regression is an extension of Poisson regression that accommodates overdispersion, where the variance exceeds the mean. It is used when the count data exhibit more variability than expected under a Poisson distribution. The model assumes that the count data follow a negative binomial distribution, which has an additional parameter to account for overdispersion. Biological and ecological processes such as species abundance, parasite counts, and gene expression often exhibit overdispersion.</p>
<ul>
<li>
<strong>Use When:</strong> You have count data with overdispersion and want to model the relationship between predictors and the count outcome.</li>
<li>
<strong>Data Requirements:</strong> Count outcome, continuous or categorical</li>
<li>
<strong>Assumptions:</strong> Overdispersion (variance exceeds the mean).</li>
<li>
<strong>Diagnostics:</strong> Check for overdispersion, excess zeros, and overall model fit.</li>
<li>
<strong>R Function:</strong> <code>glm.nb()</code> in <strong>MASS</strong> package</li>
</ul>
<p><em>Gamma Regression</em></p>
<p>Gamma regression is for modelling continuous, positive outcomes that exhibit a right-skewed distribution and possibly also a non-constant variance (heteroscedasticity). The gamma distribution is well suited for continuous measurements where the variability increases as the mean increases. You might encounter this kind of distribution in growth rates, enzyme activity levels, species abundance data, and other phenomena or processes characterised by positive, skewed data.</p>
<ul>
<li>
<strong>Use When:</strong> You have a continuous, positive outcome and want to model the relationship between predictors and the outcome.</li>
<li>
<strong>Data Requirements:</strong> Continuous, positive outcome, continuous or categorical predictors.</li>
<li>
<strong>Assumptions:</strong> Outcome values are positive, potentially non-constant variance.</li>
<li>
<strong>Diagnostics:</strong> Check for overall model fit, influential observations, and residual</li>
<li>
<strong>R Function:</strong> <code>glm(..., family = Gamma)</code>
</li>
</ul>
<p><em>Beta Regression</em></p>
<p>Beta regression is a statistical technique appropriate when the response variable is a continuous proportion or rate bounded between 0 and 1. These types of data might, for example, arise in ecology where one might study the proportions of time animals spend exhibiting different behaviours, the relative abundances of species in a community, or the proportions of habitat patches comprising a landscape. Proportional data inherently exhibit heteroscedasticity (non-constant variance).</p>
<ul>
<li>
<strong>Use When:</strong> You have a proportional outcome (<span class="math inline">0 &lt; y &lt; 1</span>) and want to model the relationship between predictors and the outcome.</li>
<li>
<strong>Data Requirements:</strong> Proportional outcome (<span class="math inline">0 &lt; y &lt; 1</span>), continuous or categorical predictors.</li>
<li>
<strong>Assumptions:</strong> Outcome values within (<span class="math inline">0,1</span>), potentially non-constant variance.</li>
<li>
<strong>Diagnostics:</strong> Check for overall model fit, influential observations, and residual analysis.</li>
<li>
<strong>If Assumptions Fail:</strong> Transformations, consider alternative link functions, or zero/one-inflated beta regression.</li>
<li>
<strong>R Function:</strong> <code>betareg()</code> in the <strong>betareg</strong> package</li>
</ul>
<p><strong>Modelling Non-Linear Relationships</strong></p>
<p>We use non-linear models when the relationship between predictor variables and the outcome variable is not linear. This non-linearity arises from the predictor variables themselves being non-linearly related to the outcome or from the modelâ€™s parameters (coefficients) appearing non-linearly in the functional form. The visualised response curve is typically curved, rather than a straight line. These models are often derived from theoretical understanding or prior knowledge about the underlying mechanisms governing the relationship between the predictors and the outcome variables.</p>
<p><em>Non-Linear Least Squares (NLS) Regression</em> (<a href="non-linear_regression.html" class="quarto-xref"><span>Nonlinear Models</span></a>)</p>
<ul>
<li>
<strong>Use When:</strong> The relationship between the predictors and the outcome is non-linear.</li>
<li>
<strong>Data Requirements:</strong> Continuous outcome, continuous predictors.</li>
<li>
<strong>Assumptions:</strong> Appropriate functional form, normality, and homoscedasticity of residuals.</li>
<li>
<strong>Diagnostics:</strong> Check residual plots, normality of residuals, and leverage/influence points.</li>
<li>
<strong>R Function:</strong> <code><a href="https://rdrr.io/r/stats/nls.html">nls()</a></code> (for non-linear regression models with user-specified functions)</li>
</ul>
<p><strong>Generalised Non-Linear Models (GNLMs)</strong></p>
<p>GNLMs are an extension of generalised linear models (GLMs) that allow for non-linear relationships between the predictors and the outcome variable. GNLMs are used when the relationship between the predictors and the outcome is non-linear, and the outcome variable follows a non-normal distribution. GNLMs are particularly useful for count data, binary outcomes, and other non-continuous response variables that exhibit non-linear relationships with the predictors.</p>
<p><strong>Linear and Non-Linear Hierarchical Models (Mixed-Effects Models)</strong></p>
<p>Hierarchical models are used when data are structured hierarchically, such as when multiple observations are nested within higher-level units (e.g., plants within fields, sheep within rangelands). These models account for the correlation between observations within the same group and allow for the estimation of both fixed effects (population-level parameters) and random effects (group-level parameters). Hierarchical models are also known as multilevel models or mixed-effects models.</p>
<p><em>Linear Mixed-Effects Models (LMMs)</em> (Section X.X.X)</p>
<ul>
<li>
<strong>Use When:</strong> You have nested or hierarchical data structures and the relationship between the predictors and the outcome is linear.</li>
<li>
<strong>Data Requirements:</strong> Continuous outcome, continuous predictors, potentially with nested or hierarchical data structures.</li>
<li>
<strong>Assumptions:</strong> Normality, homoscedasticity of residuals, correct specification of random effects structure.</li>
<li>
<strong>If Assumptions Fail:</strong> Consider transformations, robust regression, or non-linear mixed-effects models.</li>
<li>
<strong>Diagnostics:</strong> Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.</li>
<li>
<strong>R Function:</strong> <code>lmer()</code> in the <strong>lme4</strong> package (for linear mixed-effects models with user-specified functions)</li>
</ul>
<p><em>Non-Linear Mixed-Effects Models (NLMMs)</em> (<a href="non-linear_regression.html" class="quarto-xref"><span>Nonlinear Models</span></a>)</p>
<ul>
<li>
<strong>Use When:</strong> You have nested or hierarchical data structures and the relationship between the predictors and the outcome is non-linear.</li>
<li>
<strong>Data Requirements:</strong> Continuous outcome, continuous predictors, potentially with nested or hierarchical data structures.</li>
<li>
<strong>Assumptions:</strong> Appropriate functional form, normality, and homoscedasticity of residuals, correct specification of random effects structure.</li>
<li>
<strong>If Assumptions Fail:</strong> Generalised non-linear mixed models (GNLMMs) and generalised additive mixed models (GAMMs) can be used when the assumptions of non-linear mixed models (NLMMs) are violated. Else, consult a statistician.</li>
<li>
<strong>Diagnostics:</strong> Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.</li>
<li>
<strong>R Function:</strong> <code>nlme()</code> in the <strong>nlme</strong> package (for non-linear mixed-effects models with user-specified functions)</li>
</ul>
<p><strong>Generalised Linear and Non-Linear Mixed-Effects Models (GLMMs and GNLMMs)</strong></p>
<p>GLMMs and GNLMMs combine the flexibility of regression model generalisation (i.e.&nbsp;by accommodating non-Gaussian distribution families) with the ability to account for nested or hierarchical data structures. GLMMs are used when the outcome variable is not normally distributed (a different, known distribution) and the data are structured hierarchically. GLMMs include both fixed effects (population-level parameters) and random effects (group-level parameters) and can accommodate a wide range of outcome distributions, including binary, count, and continuous outcomes.</p>
<ul>
<li>
<strong>Use When:</strong> You have non-normally distributed outcome data and nested or hierarchical data structures.</li>
<li>
<strong>Data Requirements:</strong> Binary outcome, continuous or categorical predictors, potentially with nested or hierarchical data structures.</li>
<li>
<strong>Assumptions:</strong> Linear relationship between the log-odds of the outcome and predictors, correct specification of random effects structure.</li>
<li>
<strong>Diagnostics:</strong> Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.</li>
<li>
<strong>R Function:</strong> <code>glmer()</code> in the <strong>lme4</strong> package</li>
</ul>
<p><strong>Other Regression Models</strong></p>
<p><em>Zero-Inflated Models</em></p>
<ul>
<li>
<strong>Use When:</strong> You have count data with an excess of zeros and want to model the zero-inflation separately from the count process.</li>
<li>
<strong>Data Requirements:</strong> Count outcome, continuous or categorical</li>
<li>
<strong>Assumptions:</strong> Correct specification of zero-inflation and count processes, no omitted variables.</li>
<li>
<strong>Diagnostics:</strong> Check zero-inflation and count process, overall model fit.</li>
<li>
<strong>R Function:</strong> <code>zeroinfl()</code> in the <strong>pscl</strong> package</li>
</ul>
<p><em>Survival Analysis</em></p>
<ul>
<li>
<strong>Data Requirements:</strong> Time-to-event outcome, continuous or categorical predictors.</li>
<li>
<strong>Assumptions:</strong> Proportional hazards, non-informative censoring.</li>
<li>
<strong>Diagnostics:</strong> Check proportional hazards assumption, influential observations, and overall model fit.</li>
<li>
<strong>R Function:</strong> <code><a href="https://rdrr.io/pkg/survival/man/coxph.html">survival::coxph()</a></code>
</li>
</ul>
<p><em>Time Series Analysis</em></p>
<ul>
<li>
<strong>Data Requirements:</strong> Time-ordered data, potentially with autocorrelation.</li>
<li>
<strong>Assumptions:</strong> Stationarity, no autocorrelation in residuals.</li>
<li>
<strong>Diagnostics:</strong> Check autocorrelation, stationarity, and overall model fit.</li>
<li>
<strong>R Function:</strong> <code><a href="https://rdrr.io/r/stats/arima.html">arima()</a></code>, <code>auto.arima()</code> in the <strong>forecast</strong> package</li>
</ul>
<p><em>Structural Equation Modelling (SEM)</em></p>
<ul>
<li>
<strong>Data Requirements:</strong> Continuous outcome, continuous</li>
<li>
<strong>Assumptions:</strong> Correct specification of the structural model, no omitted variables, no measurement error.</li>
<li>
<strong>Diagnostics:</strong> Check model fit, parameter estimates, and overall model validity.</li>
<li>
<strong>R Function:</strong> <code>sem()</code> in the <strong>lavaan</strong> package</li>
</ul>
<p><em>Bayesian Regression</em></p>
<ul>
<li>
<strong>Data Requirements:</strong> Continuous outcome, continuous or categorical predictors.</li>
<li>
<strong>Assumptions:</strong> Correct specification of priors, likelihood, and model structure.</li>
<li>
<strong>Diagnostics:</strong> Check for convergence, posterior predictive checks, and overall model fit.</li>
<li>
<strong>R Function:</strong> <code>brms::brm()</code>
</li>
</ul></section></section></section><section id="ii.-non-parametric-methods-distribution-free" class="level2"><h2 class="anchored" data-anchor-id="ii.-non-parametric-methods-distribution-free">II. Non-Parametric Methods (Distribution-Free)</h2>
<p>Non-parametric statistics are statistical methods that do not rely on assumptions about the specific form or parameters of the population distribution. They are also referred to as <em>distribution-free methods</em>. These methods often use ranks or other order statistics of the data rather than the actual data values themselves.</p>
<section id="a.-hypotheses-about-groups" class="level3"><h3 class="anchored" data-anchor-id="a.-hypotheses-about-groups">A. Hypotheses About Groups</h3>
<p><em>One-Sample Tests for Medians</em></p>
<p>Use a one-sample test to compare the median of a single sample to a known population median. It is as an alternative to one-sample <em>t</em>-tests when the data do not meet the assumptions of parametric tests.</p>
<ul>
<li>Wilcoxon signed-rank test</li>
<li>Sign test</li>
</ul>
<p><em>Two-Sample Tests for Medians</em> (Section X.X.X)</p>
<p>Use two-sample tests to compare the medians of two independent or related samples. Use it when the assumptions of parametric two-sample tests are violated.</p>
<ul>
<li>Mann-Whitney U test (two independent groups)</li>
<li>Wilcoxon rank-sum test (two independent groups)</li>
<li>Kruskal-Wallis test (multiple groups)</li>
<li>Friedman test (related samples)</li>
</ul></section><section id="b.-hypotheses-about-proportions" class="level3"><h3 class="anchored" data-anchor-id="b.-hypotheses-about-proportions">B. Hypotheses About Proportions</h3>
<ul>
<li>
<em>Chi-Square Test for Independence:</em> Comparing proportions of two groups</li>
</ul></section><section id="c.-correlation-analysis-for-tests-of-association" class="level3"><h3 class="anchored" data-anchor-id="c.-correlation-analysis-for-tests-of-association">C. Correlation Analysis for Tests of Association</h3>
<p>Use non-parametric correlation to assess the strength and direction of a relationship between two continuous (or ordinal) variables when the assumptions of parametric correlation tests cannot be met.</p>
<p><em>Spearmanâ€™s Rank Correlation</em> (<a href="correlation.html" class="quarto-xref"><span>Correlation</span></a>)</p>
<p>A non-parametric measure of the strength and direction of association between two variables.</p>
<p><em>Kendallâ€™s Tau Correlation</em> (<a href="correlation.html" class="quarto-xref"><span>Correlation</span></a>)</p>
<p>A non-parametric measure of the strength and direction of association between two variables.</p>
</section><section id="d.-regression-analysis" class="level3"><h3 class="anchored" data-anchor-id="d.-regression-analysis">D. Regression Analysis</h3>
<p><em>Quantile Regression</em> (Section X.X.X)</p>
<p>Models different quantiles of the response distribution.</p>
<p><em>Robust Regression</em> (Section X.X.X)</p>
<p>Less sensitive to outliers than ordinary least squares regression.</p>
<p><em>Kernel Density Estimation</em></p>
<p>KDE is a non-parametric method for visualising the distribution of a continuous variable. Unlike histograms, which bin data into discrete intervals, KDE creates a smooth curve that represents the estimated probability density function (PDF) of the underlying data. It does this by placing a kernel function (often a symmetric curve like a Gaussian or Epanechnikov) at each data point and summing up the contributions of these kernels across the entire range of the variable. The bandwidth of the kernel controls the smoothness of the resulting density estimate. Wider bandwidths lead to smoother curves but may obscure finer details, while narrower bandwidths reveal more local fluctuations but can be noisy. KDE is useful when the underlying distribution of the data is unknown or non-standard and it offers a convenient way to visualise and understand the shape and spread of the data without being constrained by parametric assumptions.</p>
<p><em>Local Regression (LOESS)</em></p>
<p>LOESS (Locally Estimated Scatterplot Smoothing) is a non-parametric regression technique that produces a smooth curve through a set of data points by fitting simple models to localised subsets of the data. It achieves this by weighting the data points in each subset, with higher weights assigned to points closer to the point being estimated. The model used for local fitting is typically a low-degree polynomial, although other choices are possible.</p>
<p>LOESS is primarily used for data exploration and visualisation. It is best known for smoothing scatterplots and revealing underlying trends or patterns in the data. It is advantageous because it doesnâ€™t assume any particular functional form for the relationship between the predictors and the response variable, so it to adapts to various data shapes. But LOESS does not provide a single, easily interpretable equation for the entire dataset, making it less suitable for making predictions or drawing global inferences. It can also be computationally demanding with large datasets as it fits separate models in the vicinity of locally-selected points.</p>
<p><em>Penalised Regression</em></p>
<p>Penalised regression (also known as regularisation) is used to enhance the performance of regression models. This might be desirable when dealing with high-dimensional data or when the predictor variables are highly collinear. It introduces a penalty to the regression objective function which discourages the model from having overly complex or large coefficients. This effectively prevents overfitting. Common types of penalised regression include Ridge regression (L2 regularisation), which adds the sum of the squared coefficients as a penalty term, and Lasso regression (L1 regularisation), which adds the sum of the absolute values of the coefficients. The penalty terms encourage simpler models by shrinking some coefficients towards zero, with Lasso potentially setting some coefficients exactly to zero, thus performing variable selection. The balance between fitting the data well and maintaining model simplicity helps in improving the modelâ€™s generalisation to new data. Penalised regression methods can achieve a trade-off between bias and variance and result in more robust and interpretable models.</p>
</section></section><section id="iii.-semi-parametric-methods" class="level2"><h2 class="anchored" data-anchor-id="iii.-semi-parametric-methods">III. Semi-Parametric Methods</h2>
<p>Semi-parametric methods combine parametric and non-parametric techniques to provide a balance between flexibility and efficiency. These methods are useful when the assumptions of parametric tests are violated, but the data do not meet the requirements for non-parametric tests. Semi-parametric methods are often more powerful than non-parametric tests, as they make fewer assumptions about the data distribution. These methods are particularly useful when the sample size is small or when the data are skewed or have outliers.</p>
<p><em>Generalised Additive Models (GAMs)</em> (<a href="generalised_additive_models.html" class="quarto-xref"><span>Generalised Additive Models</span></a>)</p>
<ul>
<li>
<strong>Use When:</strong> You have non-linear relationships between predictors and outcome.</li>
<li>
<strong>R Function:</strong> <code>gam()</code> in the <strong>mgcv</strong> package; also <code>gamm4()</code> in the <strong>gamm4</strong> package</li>
<li>
<strong>Data Requirements:</strong> Continuous, binary, or categorical outcome, continuous or categorical predictors, potentially with nested or hierarchical data structures.</li>
<li>
<strong>Advantages:</strong> Flexible modelling of non-linear relationships using smoothing functions, can handle mixed-effects structures.</li>
<li>
<strong>Limitations:</strong> Interpretation can be challenging, potential overfitting.</li>
</ul>
<p><em>Generalised Estimating Equations (GEEs)</em></p>
<ul>
<li>
<strong>Use When:</strong> You have correlated data and non-normally distributed outcomes.</li>
<li>
<strong>R Function:</strong> <code>geeglm()</code> in the <strong>geepack</strong> package; also functions in the <strong>gee</strong> package</li>
<li>
<strong>Data Requirements:</strong> Correlated data, non-normal outcomes, continuous or categorical predictors.</li>
<li>
<strong>Advantages:</strong> Robust to misspecification of the correlation structure, can handle non-normal outcomes, flexible in handling missing data.</li>
<li>
<strong>Limitations:</strong> Assumes correct specification of the correlation structure, may be less efficient than mixed-effects models.</li>
</ul>
<p><em>Semi-Parametric Survival Models</em></p>
<ul>
<li>
<strong>Use When:</strong> You have time-to-event data and want to model the hazard function.</li>
<li>
<strong>R Function:</strong> <code>coxph()</code> in the <strong>survival</strong> package</li>
<li>
<strong>Data Requirements:</strong> Time-to-event data, censoring, continuous or categorical predictors.</li>
<li>
<strong>Assumptions:</strong> Proportional hazards assumption, independence of censoring.</li>
<li>
<strong>Diagnostics:</strong> Check proportional hazards assumption, influential observations, goodness</li>
</ul>
<p><em>Spline Regression</em></p>
<ul>
<li>
<strong>Use When:</strong> You have non-linear relationships between predictors and outcome.</li>
<li>
<strong>R Function:</strong> <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> with splines, <code>gam()</code> in the <strong>mgcv</strong> package</li>
<li>
<strong>Data Requirements:</strong> Continuous outcome, continuous predictors.</li>
<li>
<strong>Assumptions:</strong> Linearity within each spline, potentially non-constant variance.</li>
<li>
<strong>Diagnostics:</strong> Check for overall model fit, influential observations, and residual analysis.</li>
<li>
<strong>If Assumptions Fail:</strong> Transformations, consider alternative link functions, or penalised regression.</li>
</ul></section><section id="iv.-machine-learning-methods" class="level2"><h2 class="anchored" data-anchor-id="iv.-machine-learning-methods">IV. Machine Learning Methods</h2>
<p>Machine learning methods are a set of algorithms that can learn patterns from data without being explicitly programmed. These methods are particularly useful for prediction, classification, and clustering tasks. Machine learning models can handle complex relationships in the data and are often more flexible than traditional statistical models. However, they can be more computationally intensive and may require more data to train effectively.</p>
<p><em>Random Forests</em></p>
<p>A machine learning method that uses an ensemble of decision trees to predict an outcome.</p>
<p><em>Support Vector Machines</em></p>
<p>A machine learning method that finds the optimal hyperplane to separate two classes of data.</p>
<p><em>Ensemble Methods</em></p>
<p>A machine learning technique that combines the predictions of multiple models to improve accuracy.</p>
<p><em>Neural Networks</em></p>
<p>A machine learning method that uses interconnected nodes to model complex relationships in data.</p>
<p><em>Deep Learning</em></p>
<p>A subset of machine learning that uses neural networks with multiple layers to model complex relationships in data.</p>
</section><section id="v.-miscellaneous-methods" class="level2"><h2 class="anchored" data-anchor-id="v.-miscellaneous-methods">V. Miscellaneous Methods</h2>
<p><em>Bootstrapping</em></p>
<p>A resampling method for estimating the sampling distribution of a statistic.</p>
<p><em>Permutation Tests</em></p>
<p>A non-parametric method for testing hypotheses by randomly permuting the data.</p>
<p><em>Monte Carlo Simulation</em></p>
<p>A method for estimating the distribution of a statistic by generating random samples from a known distribution.</p>
<p><em>Bayesian Methods</em></p>
<p>A statistical approach that uses Bayesâ€™ theorem to update prior beliefs based on observed data.</p>
<p><em>Dimensionality Reduction</em></p>
<p>Also called muitvariate analyses. A set of techniques for reducing the number of variables in a dataset while preserving important information.</p>
<p><em>Clustering</em></p>
<p>A set of unsupervised learning techniques for grouping similar data points together.</p>
<p><em>Feature Selection</em></p>
<p>A process for identifying the most important variables in a dataset for predicting an outcome.</p>
<p><em>Regularisation</em></p>
<p>See penalised regression. A technique for preventing overfitting by adding a penalty term to the model coefficients.</p>
<p><em>Cross-Validation</em></p>
<p>A method for estimating the performance of a model by splitting the data into training and test sets.</p>
<p><em>Hyperparameter Tuning</em></p>
<p>The process of selecting the optimal values for the parameters of a machine learning model.</p>
<p><em>Model Evaluation</em></p>
<p>The process of assessing the performance of a model using metrics such as accuracy, precision, recall, and F1 score.</p>
<p><em>Model Interpretation</em></p>
<p>The process of understanding how a model makes predictions by examining the relationship between the input variables and the output.</p>
<p><em>Model Deployment</em></p>
<p>The process of putting a trained model into production so that it can be used to make predictions on new data.</p>
<p><em>Model Monitoring</em></p>
<p>The process of tracking the performance of a deployed model over time to ensure that it continues to make accurate predictions.</p>
<p><em>Model Explainability</em></p>
<p>The process of explaining how a model makes predictions in a way that is understandable to humans.</p>
<p><em>Model Fairness</em></p>
<p>The process of ensuring that a model does not discriminate against certain groups of people based on sensitive attributes.</p>
<p><em>Model Robustness</em></p>
<p>The process of ensuring that a model performs well on new data that is different from the training data.</p>
<!-- The basic high-level decision that would cause a person to decide between any inferential statistical method excluding regressions, and regressions (including all various types) primarily revolves around the research question and the type of relationship or effect they are interested in analysing, namely *describing relationships* vs. *predicting and modelling outcomes*. -->
<!-- **Inferential Statistical Methods (Excluding Regressions):** -->
<!-- - **Purpose:** Often used to test hypotheses, compare groups, and determine if there are significant differences or associations between variables. -->
<!-- - **Example Methods:** *t*-tests, ANOVA, chi-square tests, correlation analysis. -->
<!-- - **Research Questions:** These methods are used when the primary goal is to determine if there is a significant effect, difference, or association without necessarily predicting outcomes. For example: -->
<!--     - Is there a significant difference in mean test scores between two groups? -->
<!--     - Is there an association between two categorical variables? -->
<!--     - Are two variables correlated? -->
<!-- **Regressions (All Various Types):** -->
<!-- - **Purpose:** Used to model relationships between a dependent (response) variable and one or more independent (predictor) variables, often with the goal of predicting the outcome variable or understanding the effect of predictors. -->
<!-- - **Example Methods:** Linear regression, logistic regression, Poisson regression, mixed-effects models, generalised additive models (GAMs), etc. -->
<!-- - **Research Questions:** These methods are used when the primary goal is to predict an outcome variable based on one or more predictors or to understand the magnitude and direction of the effect of predictors on an outcome. For example: -->
<!--     - How does the amount of study time predict test scores? -->
<!--     - What factors influence the probability of disease presence? -->
<!--     - How do multiple environmental variables affect species abundance? -->
<!-- **Decision Point:** -->
<!-- - **If the goal is to understand and quantify the relationship between variables by constructing models that can be used to predict or assess the impact of predictors on an outcome variable, regression methods are appropriate.** -->
<!-- - **If the goal is to test for differences between groups, associations between categorical variables, or simple relationships without prediction or complex modelling, other inferential statistical methods are appropriate.** -->


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-underwood1997experiments" class="csl-entry" role="listitem">
Underwood AJ (1997) Experiments in ecology: Their logical design and interpretation using analysis of variance. Cambridge university press
</div>
</div>
</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Preface">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./part_A.html" class="pagination-link" aria-label="Parametric Methods">
        <span class="nav-page-text">Parametric Methods</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb3" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><a href="#cb3-1"></a><span class="fu"># Introduction</span></span>
<span id="cb3-2"><a href="#cb3-2"></a></span>
<span id="cb3-5"><a href="#cb3-5"></a><span class="in">```{r}</span></span>
<span id="cb3-6"><a href="#cb3-6"></a><span class="co">#| echo: false</span></span>
<span id="cb3-7"><a href="#cb3-7"></a><span class="co">#| message: false</span></span>
<span id="cb3-8"><a href="#cb3-8"></a><span class="co">#| warning: false</span></span>
<span id="cb3-9"><a href="#cb3-9"></a></span>
<span id="cb3-10"><a href="#cb3-10"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb3-11"><a href="#cb3-11"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb3-12"><a href="#cb3-12"></a><span class="in">```</span></span>
<span id="cb3-13"><a href="#cb3-13"></a></span>
<span id="cb3-16"><a href="#cb3-16"></a><span class="in">```{r}</span></span>
<span id="cb3-17"><a href="#cb3-17"></a><span class="co">#| echo: false</span></span>
<span id="cb3-18"><a href="#cb3-18"></a></span>
<span id="cb3-19"><a href="#cb3-19"></a><span class="fu">options</span>(<span class="at">knitr.table.format =</span> <span class="cf">function</span>() {</span>
<span id="cb3-20"><a href="#cb3-20"></a>  <span class="cf">if</span> (knitr<span class="sc">::</span><span class="fu">is_latex_output</span>())</span>
<span id="cb3-21"><a href="#cb3-21"></a>    <span class="st">"latex"</span> <span class="cf">else</span> <span class="st">"pipe"</span></span>
<span id="cb3-22"><a href="#cb3-22"></a>})</span>
<span id="cb3-23"><a href="#cb3-23"></a><span class="in">```</span></span>
<span id="cb3-24"><a href="#cb3-24"></a></span>
<span id="cb3-25"><a href="#cb3-25"></a></span>
<span id="cb3-26"><a href="#cb3-26"></a><span class="fu">## The Scientific Method in Practice</span></span>
<span id="cb3-27"><a href="#cb3-27"></a></span>
<span id="cb3-28"><a href="#cb3-28"></a>Answering questions about the natural world using a scientific workflow requires that we draw on many years' of accumulated knowledge and experience. The workflow unpacks into roughly the following sequence of steps:</span>
<span id="cb3-29"><a href="#cb3-29"></a></span>
<span id="cb3-30"><a href="#cb3-30"></a><span class="ss">1. </span>Look around you at the world, be curious about it, and ask questions to figure out an explanation for the pattern or phenomenon that tickled your interest. </span>
<span id="cb3-31"><a href="#cb3-31"></a><span class="ss">2. </span>Create an unambiguous statement of the question you want to answer, think about what is causing the pattern or phenomenon you observed, and how you might go about measuring the response (the thing you observed initially).</span>
<span id="cb3-32"><a href="#cb3-32"></a><span class="ss">3. </span>Translate this question into a testable hypothesis. This is the statement that you can test using the data you will collect.</span>
<span id="cb3-33"><a href="#cb3-33"></a><span class="ss">4. </span>Design an experiment or sampling campaign to collect data that will allow you to test this hypothesis. Clearly understand what the data you'll collect will look like, both for the response and the explanatory variables. For example, do you have a categorical or continuous predictor, is the response continuous, binary, ordinal, etc.? For this, you should have a firm grasp of the various kinds of <span class="co">[</span><span class="ot">Data Classes and Structures in R</span><span class="co">](https://tangledbank.netlify.app/BCB744/basic_stats/01-data-in-R.html)</span>.</span>
<span id="cb3-34"><a href="#cb3-34"></a><span class="ss">5. </span>Think deeply about any confounding influences that might affect your data, and specify exactly what additional data you will have to collect to isolate the hypothesised influence in your analysis. You need to fully understand all the ways that factors not considered in your hypothesis might affect your study's outcome. Omissions cannot be rectified after the fact without repeating the entire experiment or sampling work. It requires knowledge and experience to avoid confounding influences ruining your work.</span>
<span id="cb3-35"><a href="#cb3-35"></a><span class="ss">6. </span>Depending on your experiment's design (4) and the nature of the data you'll obtain (4, 5), choose the appropriate statistical methods to analyse them. You should be able to develop a good idea of what statistical methods you'll use---even before the experiment has been done! Decide on the parametric test, or, should the statistical god with the dice not provide an outcome that favours your expectations, you can also decide upfront on a non-parametric equivalent. It is important not to decide on the statistical method after you've collected the data. This is called *p*-hacking, and it is almost a cardinal sin in science.</span>
<span id="cb3-36"><a href="#cb3-36"></a><span class="ss">7. </span>Do the experiment or go out into the world to sample, and collect the data. Have fun---this is why we do science, afterall!</span>
<span id="cb3-37"><a href="#cb3-37"></a><span class="ss">8. </span>Go have a few drinks after a hard day's work and celebrate your success.</span>
<span id="cb3-38"><a href="#cb3-38"></a><span class="ss">9. </span>Analyse your newly-collected data. This will include explaratory data analyses (see <span class="co">[</span><span class="ot">Exploring With Summaries and Descriptions</span><span class="co">](https://tangledbank.netlify.app/BCB744/basic_stats/02-summarise-and-describe.html)</span> and <span class="co">[</span><span class="ot">Exploring With Figures</span><span class="co">](https://tangledbank.netlify.app/BCB744/basic_stats/03-visualise.html)</span>), and then the application of the statistical methods you chose in step 6.</span>
<span id="cb3-39"><a href="#cb3-39"></a><span class="ss">10. </span>Communicate your results in tables and figures.</span>
<span id="cb3-40"><a href="#cb3-40"></a></span>
<span id="cb3-41"><a href="#cb3-41"></a>This textbook deals with many of these steps (except for 1, 5, and 7). This knowledge is codified in the form of the statistical method, which provides a systematic framework for collecting,<span class="ot">[^0]</span> analysing, and interpreting data. In this chapter, I introduce the fundamental concepts of inferential statistics, which allow us to make inferences about populations based on sample data. I also provide an overview of the types of statistical methods used in inferential statistics, and discuss the importance of understanding the assumptions underlying these methods.</span>
<span id="cb3-42"><a href="#cb3-42"></a></span>
<span id="cb3-43"><a href="#cb3-43"></a><span class="ot">[^0]: </span>Yes, statistics also informs us about how to collect data. </span>
<span id="cb3-44"><a href="#cb3-44"></a></span>
<span id="cb3-45"><a href="#cb3-45"></a><span class="fu">## The Statistical Toolbox</span></span>
<span id="cb3-46"><a href="#cb3-46"></a></span>
<span id="cb3-47"><a href="#cb3-47"></a>With inferential statistics you can analyse data obtained from representative samples to draw conclusions or test hypotheses about populations or processes. I broadly categorise these methods into four main types, each serving different research applications<span class="ot">[^1]</span>:</span>
<span id="cb3-48"><a href="#cb3-48"></a></span>
<span id="cb3-49"><a href="#cb3-49"></a><span class="ot">[^1]: </span>This categorisation reflects my teaching approach, based on the order in which I think topics need to be covered, rather than a strict classification by statisticians. It is intended to provide a high-level overview of the types of statistical methods used in inferential statistics.</span>
<span id="cb3-50"><a href="#cb3-50"></a></span>
<span id="cb3-51"><a href="#cb3-51"></a><span class="ss">1. </span>**Hypothesis Tests**: These parametric and non-parametric techniques assess whether sample data provide evidence for or against a specific claim (hypothesis) about population parameters such as their means, proportions, variances, or correlations between variables. Common hypothesis tests include:</span>
<span id="cb3-52"><a href="#cb3-52"></a></span>
<span id="cb3-53"><a href="#cb3-53"></a><span class="ss">    - </span>Comparisons of group means or medians for a continuous variable (e.g., *t*-tests, ANOVA, Mann-Whitney *U* test)</span>
<span id="cb3-54"><a href="#cb3-54"></a><span class="ss">    - </span>Comparisons of group proportions for a categorical variable (e.g., $\chi$-square test, Fisher's exact test)</span>
<span id="cb3-55"><a href="#cb3-55"></a><span class="ss">    - </span>Assessments of the relationship between two continuous or ordinal variables (e.g., Pearson's correlation, Spearman's rank correlation)</span>
<span id="cb3-56"><a href="#cb3-56"></a></span>
<span id="cb3-57"><a href="#cb3-57"></a><span class="ss">2. </span>**Regression Analysis**: Regression with its parametric and non-parametric offerings lets us analyse the relationship between a response variable and one or more predictor variables. Regression models estimate coefficients representing the predictor effects, allow for prediction of the response, and enable hypothesis tests on the predictors. Common regression models include:</span>
<span id="cb3-58"><a href="#cb3-58"></a></span>
<span id="cb3-59"><a href="#cb3-59"></a><span class="ss">    - </span>Linear regression for continuous response variables</span>
<span id="cb3-60"><a href="#cb3-60"></a><span class="ss">    - </span>Logistic regression for binary response variables</span>
<span id="cb3-61"><a href="#cb3-61"></a><span class="ss">    - </span>Generalised linear models (GLMs) for non-normal response variables</span>
<span id="cb3-62"><a href="#cb3-62"></a><span class="ss">    - </span>Various non-linear regressions for complex relationships, such as generalised additive models (GAMs)</span>
<span id="cb3-63"><a href="#cb3-63"></a></span>
<span id="cb3-64"><a href="#cb3-64"></a><span class="ss">3. </span>**Survival Analysis**: Methods like the Kaplan-Meier estimator and Cox proportional hazards model analyse time-to-event data, where the interest lies in modelling the waiting times until certain events occur. I do not cover survival analysis in this book or any of my modules.</span>
<span id="cb3-65"><a href="#cb3-65"></a></span>
<span id="cb3-66"><a href="#cb3-66"></a><span class="ss">4. </span>**Multivariate Analysis:** This includes an assortment of methods to analyse multiple response and predictor variables simultaneously. Dimension reduction methods, such as canonical correlation analysis (CCA) and non-metric multidimensional scaling (nMDS), help simplify complex datasets by identifying key patterns and relationships. Classification, including cluster analysis, is used to group similar observations together based on their characteristics. Multivariate approaches make fewer assumptions about the dataâ€™s distribution, and there are techniques to deal with parametric and non-parametric data types (often without discrimination). Although these methods are not covered in this textbook, they are taught in my <span class="co">[</span><span class="ot">Quantitative Ecology</span><span class="co">](https://tangledbank.netlify.app/BCB743/BCB743_index.html)</span> module, which will eventually be developed into its own textbook.</span>
<span id="cb3-67"><a href="#cb3-67"></a></span>
<span id="cb3-68"><a href="#cb3-68"></a>The above methods include parametric or non-parametric (sometimes called 'robust') methods. Parametric methods assume that the data follow a specific distribution (e.g., normal, Poisson), while non-parametric methods make fewer assumptions about the data distribution. I will cover the parametric methods first, in Part A, followed by non-parametric methods in Part B. Part C of the book will look at semi-parametric methods, which combine aspects of both parametric and non-parametric approaches.</span>
<span id="cb3-69"><a href="#cb3-69"></a></span>
<span id="cb3-70"><a href="#cb3-70"></a></span>
<span id="cb3-71"><a href="#cb3-71"></a><span class="fu">## I. Parametric Methods (Known Distribution)</span></span>
<span id="cb3-72"><a href="#cb3-72"></a></span>
<span id="cb3-73"><a href="#cb3-73"></a>Parametric statistics rely on specific assumptions about the underlying probability distribution of the population from which the sample data were drawn. Biologists are taught that our data must be normally distributed, but this an unreasonable expectation considering the widely varying data sources we will encounter. Some biological processes simply do not generate normally distributed data! </span>
<span id="cb3-74"><a href="#cb3-74"></a></span>
<span id="cb3-75"><a href="#cb3-75"></a>Nevertheless, parametric statistics have through convention (rather than best practice) become the starting point for introductory forays into statistics. This is not terrible, because, should we be fortunate enough to have normally distributed data, parametric methods are more powerful than their non-parametric counterparts; however, they are also more sensitive to violations of some assumptions about our data.</span>
<span id="cb3-76"><a href="#cb3-76"></a></span>
<span id="cb3-77"><a href="#cb3-77"></a>The staple parametric statistics, such as the *t*-test, ANOVAs, Pearson correlation, and simple linear regression, require that two key assumptions are met: i) that our data (or sometimes the residuals) are **normality distributed** and ii) that the **variances are homoscedastic**. Section X is devoted to statistical tests that we may use to test the assumptions. However, because of the Central Limit Theorem, parametric methods can withstand moderate violations of the normality assumption when the sample size is large.<span class="ot">[^2]</span></span>
<span id="cb3-78"><a href="#cb3-78"></a></span>
<span id="cb3-79"><a href="#cb3-79"></a><span class="ot">[^2]: </span>The CLT states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, even if the underlying population is not perfectly normal.</span>
<span id="cb3-80"><a href="#cb3-80"></a></span>
<span id="cb3-81"><a href="#cb3-81"></a>A common mistake biologists makes is to think that parametric tests only apply to normal data. This is not true. Generalised linear models (GLMs) extend the statistical framework to accommodate non-normal error distributions, such as Poisson for count data or binomial for binary outcomes.<span class="ot">[^3]</span> GLMs require that the distribution of the response variable belongs to the exponential family of distributions and that a suitable link function is chosen to connect the mean of the response to the linear predictor. Therefore, the defining characteristic of parametric methods is the assumption of a **known distribution** for the response variable, not necessarily that is is normal.</span>
<span id="cb3-82"><a href="#cb3-82"></a></span>
<span id="cb3-83"><a href="#cb3-83"></a><span class="ot">[^3]: </span>In fact, many statistical tests that would ordinarily require the assumption of normality to be met have been extended to other probability distributions, as can be seen from the practice to append the word 'Generalised' to the name of the test. For example, the Generalised Additive Model (GAM) is a generalised semi-parametric method, Generalised Non-Linear Models (GNLMs) permit fitting non-linear models to non-parametric data, and Generalised Linear and Non-Linear Mixed-Effects Models (GLMMs and GNLMMs) do the same with hierarchical data.</span>
<span id="cb3-84"><a href="#cb3-84"></a></span>
<span id="cb3-85"><a href="#cb3-85"></a>Within the parametric statistics framework, we can divide the methods into four groups depending on the type of question we are asking. We can ask questions about i) **difference in means**, ii) **differences in proportions**, iii) **relationships between variables**, or iv) the **effect of one or more predictors on a response variable**. </span>
<span id="cb3-86"><a href="#cb3-86"></a></span>
<span id="cb3-87"><a href="#cb3-87"></a></span>
<span id="cb3-88"><a href="#cb3-88"></a><span class="fu">### A. Hypotheses About the Means of Groups</span></span>
<span id="cb3-89"><a href="#cb3-89"></a></span>
<span id="cb3-90"><a href="#cb3-90"></a>The simplest form of comparison is to test whether the sample **means** of two or more groups differ.<span class="ot">[^4]</span> Although this seems quite unimaginative, comparisons of the measures of central tendency are very common statistical tests in biology. Because this concept is so simple to understand, it serves as a good starting point for learning about hypothesis testing and the interpretation of the statistics which tell us about the strength of the evidence for or against our hypotheses.</span>
<span id="cb3-91"><a href="#cb3-91"></a></span>
<span id="cb3-92"><a href="#cb3-92"></a><span class="ot">[^4]: </span>When it comes to central tendency, the mean is the parameter that is being compared by parametric statistics. Non-parametric statistics, on the other hand, consider the median as the statistic of central tendency.</span>
<span id="cb3-93"><a href="#cb3-93"></a></span>
<span id="cb3-94"><a href="#cb3-94"></a>You might have hypotheses that require you to compare the means of the outcomes of different experimental treatments, differences in the number of sea urchins among populations of kelp, or the number of species within replicate samples taken from different vegetation types. Look at some of the following examples to see if any of them resonate with your own research question, and then use this as a guide to find the appropriate statistical test in this book.</span>
<span id="cb3-95"><a href="#cb3-95"></a></span>
<span id="cb3-96"><a href="#cb3-96"></a><span class="fu">#### One-Sample *t*-Test (Section X.X.X)</span></span>
<span id="cb3-97"><a href="#cb3-97"></a></span>
<span id="cb3-98"><a href="#cb3-98"></a>**Example:** Is the mean height of a sample of *Protea* sp. grown in a specific experimental landscape (given below) different from the known (established *a priori*) average height of the same species (163.3 $\pm$ 15.5 cm) in the general population?</span>
<span id="cb3-99"><a href="#cb3-99"></a></span>
<span id="cb3-102"><a href="#cb3-102"></a><span class="in">```{r}</span></span>
<span id="cb3-103"><a href="#cb3-103"></a><span class="co">#| echo: false</span></span>
<span id="cb3-104"><a href="#cb3-104"></a></span>
<span id="cb3-105"><a href="#cb3-105"></a><span class="co"># Sample data: Heights (cm) of Protea sp. grown in a specific experimental landscape</span></span>
<span id="cb3-106"><a href="#cb3-106"></a>heights <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">150</span>, <span class="dv">152</span>, <span class="dv">148</span>, <span class="dv">149</span>, <span class="dv">151</span>, <span class="dv">147</span>, <span class="dv">153</span>, <span class="dv">150</span>, <span class="dv">149</span>, <span class="dv">148</span>)</span>
<span id="cb3-107"><a href="#cb3-107"></a></span>
<span id="cb3-108"><a href="#cb3-108"></a><span class="co"># Create the dataframe</span></span>
<span id="cb3-109"><a href="#cb3-109"></a>proteas_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Height =</span> heights)</span>
<span id="cb3-110"><a href="#cb3-110"></a></span>
<span id="cb3-111"><a href="#cb3-111"></a><span class="co"># Display the dataframe</span></span>
<span id="cb3-112"><a href="#cb3-112"></a><span class="fu">ht</span>(proteas_data)</span>
<span id="cb3-113"><a href="#cb3-113"></a><span class="in">```</span></span>
<span id="cb3-114"><a href="#cb3-114"></a></span>
<span id="cb3-115"><a href="#cb3-115"></a>The example requires that you have *one normally-distributed continuous outcome variable* with *independent observations* and that you want to compare its mean value against a known population mean established *a priori*. </span>
<span id="cb3-116"><a href="#cb3-116"></a></span>
<span id="cb3-117"><a href="#cb3-117"></a>In this case, you'll want to use the R function <span class="in">`t.test()`</span>. Since this function can accommodate data with equal or unequal variances<span class="ot">[^5]</span> via the <span class="in">`var.equal`</span> argument, you only need to assure the data are normally distributed. The test can be one-sided or two-sided. Alternatively, consider non-parametric alternatives, such as the Wilcoxon signed-rank test.</span>
<span id="cb3-118"><a href="#cb3-118"></a></span>
<span id="cb3-119"><a href="#cb3-119"></a><span class="ot">[^5]: </span>A *t*-test for equal variances is typically called the Student's *t*-test, while a *t*-test for unequal variances is called Welch's *t*-test. By default, the `t.test()` function in R performs Welch's *t*-test, which is more robust to unequal variances.</span>
<span id="cb3-120"><a href="#cb3-120"></a></span>
<span id="cb3-121"><a href="#cb3-121"></a><span class="fu">#### Two-Sample *t*-Test (Section X.X.X)</span></span>
<span id="cb3-122"><a href="#cb3-122"></a></span>
<span id="cb3-123"><a href="#cb3-123"></a><span class="co">&lt;!-- **Example:** Is the uptake rate of ammonium by *Chlorella* sp. in the presence of a nitrogen-fixing bacteria different from the uptake rate in the absence of the bacteria? --&gt;</span></span>
<span id="cb3-124"><a href="#cb3-124"></a></span>
<span id="cb3-125"><a href="#cb3-125"></a>**Example:** Is the average number of leopard cubs born per female leopard in the Overberg region different from that in the Cederberg region? The dataset is:</span>
<span id="cb3-126"><a href="#cb3-126"></a></span>
<span id="cb3-129"><a href="#cb3-129"></a><span class="in">```{r}</span></span>
<span id="cb3-130"><a href="#cb3-130"></a><span class="co">#| echo: false</span></span>
<span id="cb3-131"><a href="#cb3-131"></a></span>
<span id="cb3-132"><a href="#cb3-132"></a><span class="co"># Create a dataframe with fictitious data for the example</span></span>
<span id="cb3-133"><a href="#cb3-133"></a>Region <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Overberg"</span>, <span class="dv">10</span>), <span class="fu">rep</span>(<span class="st">"Cederberg"</span>, <span class="dv">10</span>))</span>
<span id="cb3-134"><a href="#cb3-134"></a>Cubs_Per_Female <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">2</span>,  <span class="co"># Overberg</span></span>
<span id="cb3-135"><a href="#cb3-135"></a>                     <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="dv">1</span>)  <span class="co"># Cederberg</span></span>
<span id="cb3-136"><a href="#cb3-136"></a></span>
<span id="cb3-137"><a href="#cb3-137"></a><span class="co"># Create the dataframe</span></span>
<span id="cb3-138"><a href="#cb3-138"></a>leopard_cubs_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Region, Cubs_Per_Female)</span>
<span id="cb3-139"><a href="#cb3-139"></a></span>
<span id="cb3-140"><a href="#cb3-140"></a><span class="co"># Display the dataframe</span></span>
<span id="cb3-141"><a href="#cb3-141"></a><span class="fu">ht</span>(leopard_cubs_data)</span>
<span id="cb3-142"><a href="#cb3-142"></a><span class="in">```</span></span>
<span id="cb3-143"><a href="#cb3-143"></a></span>
<span id="cb3-144"><a href="#cb3-144"></a>This requires that we obtain *two samples of continuous, normally-distributed measurements*. In other words, our experiment or sampling campaign will include two groups (sometimes two treatments, other times a treatment and a control) and we collect a sample of measurements of the response in both of them. This is again catered for by the <span class="in">`t.test()`</span> function, and, as before, we don't have to fuss too much about the variances as equal and unequal variances can be accommodated. If the normality assumption is not met, consider a non-parametric alternative such as the Mann-Whitney U test.</span>
<span id="cb3-145"><a href="#cb3-145"></a></span>
<span id="cb3-146"><a href="#cb3-146"></a>A variant of the two-sample *t*-test is the paired *t*-test, which is used when the two samples are related (not independent); for example, the same individuals are measured before and after applying a treatment.</span>
<span id="cb3-147"><a href="#cb3-147"></a></span>
<span id="cb3-148"><a href="#cb3-148"></a><span class="fu">#### Analysis of Variance (ANOVA) for &gt;2 Samples (Section X.X.X)</span></span>
<span id="cb3-149"><a href="#cb3-149"></a></span>
<span id="cb3-150"><a href="#cb3-150"></a><span class="co">&lt;!-- **Example:** Is the average density of kelp plants within a kelp forest the same within a marine protected area compared to areas 2 km and 5 km away from the MPA? --&gt;</span></span>
<span id="cb3-151"><a href="#cb3-151"></a></span>
<span id="cb3-152"><a href="#cb3-152"></a>**Example:** Is the chirp rate of bladder grasshoppers different between the four seasons?</span>
<span id="cb3-153"><a href="#cb3-153"></a></span>
<span id="cb3-156"><a href="#cb3-156"></a><span class="in">```{r}</span></span>
<span id="cb3-157"><a href="#cb3-157"></a><span class="co">#| echo: false</span></span>
<span id="cb3-158"><a href="#cb3-158"></a></span>
<span id="cb3-159"><a href="#cb3-159"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb3-160"><a href="#cb3-160"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb3-161"><a href="#cb3-161"></a></span>
<span id="cb3-162"><a href="#cb3-162"></a><span class="co"># Generate fictitious chirp rate data for bladder grasshoppers across four seasons</span></span>
<span id="cb3-163"><a href="#cb3-163"></a>Season <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Spring"</span>, <span class="dv">15</span>), <span class="fu">rep</span>(<span class="st">"Summer"</span>, <span class="dv">15</span>), <span class="fu">rep</span>(<span class="st">"Autumn"</span>, <span class="dv">15</span>), <span class="fu">rep</span>(<span class="st">"Winter"</span>, <span class="dv">15</span>))</span>
<span id="cb3-164"><a href="#cb3-164"></a>Chirp_Rate <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">15</span>, <span class="at">mean =</span> <span class="dv">15</span>, <span class="at">sd =</span> <span class="dv">2</span>), <span class="dv">1</span>),  <span class="co"># Spring chirp rates</span></span>
<span id="cb3-165"><a href="#cb3-165"></a>                <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">15</span>, <span class="at">mean =</span> <span class="dv">18</span>, <span class="at">sd =</span> <span class="dv">2</span>), <span class="dv">1</span>),  <span class="co"># Summer chirp rates</span></span>
<span id="cb3-166"><a href="#cb3-166"></a>                <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">15</span>, <span class="at">mean =</span> <span class="dv">13</span>, <span class="at">sd =</span> <span class="dv">2</span>), <span class="dv">1</span>),  <span class="co"># Autumn chirp rates</span></span>
<span id="cb3-167"><a href="#cb3-167"></a>                <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">15</span>, <span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">2</span>), <span class="dv">1</span>))  <span class="co"># Winter chirp rates</span></span>
<span id="cb3-168"><a href="#cb3-168"></a></span>
<span id="cb3-169"><a href="#cb3-169"></a><span class="co"># Create the dataframe</span></span>
<span id="cb3-170"><a href="#cb3-170"></a>grasshopper_chirp_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Season, Chirp_Rate) <span class="sc">|&gt;</span> </span>
<span id="cb3-171"><a href="#cb3-171"></a>  <span class="fu">rename</span>(<span class="st">"Chirp Rate"</span> <span class="ot">=</span> Chirp_Rate) <span class="sc">|&gt;</span> </span>
<span id="cb3-172"><a href="#cb3-172"></a>  <span class="fu">ht</span>()</span>
<span id="cb3-173"><a href="#cb3-173"></a></span>
<span id="cb3-174"><a href="#cb3-174"></a><span class="co"># Display the dataframe using kable</span></span>
<span id="cb3-175"><a href="#cb3-175"></a><span class="fu">kable</span>(grasshopper_chirp_data, <span class="at">format =</span> <span class="st">"markdown"</span>, <span class="at">caption =</span> <span class="st">"Chirp Rate Data for Bladder Grasshoppers Across Four Seasons"</span>)</span>
<span id="cb3-176"><a href="#cb3-176"></a><span class="co"># unique(grasshopper_chirp_data$Season)</span></span>
<span id="cb3-177"><a href="#cb3-177"></a><span class="in">```</span></span>
<span id="cb3-178"><a href="#cb3-178"></a>We have *three or more samples of continuous, normally-distributed observations*. These data must also have more-or-less equal variances, so the homoscedasticity assumption is important. The <span class="in">`aov()`</span> function in R is used to perform the ANOVA, which can be one-way, two-way, a repeated measures ANOVA, or an ANCOVA.<span class="ot">[^6]</span> If the normality or homoscedasticity assumptions are not met, consider non-parametric alternatives, such as the Kruskal-Wallis test, or try transforming the data.</span>
<span id="cb3-179"><a href="#cb3-179"></a></span>
<span id="cb3-180"><a href="#cb3-180"></a><span class="ot">[^6]: </span>A repeated measures ANOVA is used when the same subjects are measured at different time points or under different conditions. A two-way ANOVA is used when there are two independent variables (there are also higher-order ANOVAs but they become more of a pain to interpret and require cumbersome experimental designs). An ANCOVA is used when you want to compare the means of groups while controlling for the effect of a continuous covariate. There are many kinds of ANOVA designs and each relates to specific experimental designs well beyond the scope of this book. Tony Underwood provides a pedantic overview of ANOVA designs in his book *Experiments in Ecology* <span class="co">[</span><span class="ot">@underwood1997experiments</span><span class="co">]</span> if you really want to go there.</span>
<span id="cb3-181"><a href="#cb3-181"></a></span>
<span id="cb3-182"><a href="#cb3-182"></a><span class="fu">#### Analysis of Covariance (ANCOVA)* (Section X.X.X)</span></span>
<span id="cb3-183"><a href="#cb3-183"></a></span>
<span id="cb3-184"><a href="#cb3-184"></a>**Example:** We have a set of data about African penguins and we want to determine if there are differences between male and female penguins in terms of their mean foraging time, and if that difference is influenced by their diving depth. The dataset is as follows:</span>
<span id="cb3-185"><a href="#cb3-185"></a></span>
<span id="cb3-188"><a href="#cb3-188"></a><span class="in">```{r}</span></span>
<span id="cb3-189"><a href="#cb3-189"></a><span class="co">#| echo: false</span></span>
<span id="cb3-190"><a href="#cb3-190"></a></span>
<span id="cb3-191"><a href="#cb3-191"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb3-192"><a href="#cb3-192"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb3-193"><a href="#cb3-193"></a></span>
<span id="cb3-194"><a href="#cb3-194"></a><span class="co"># Generate sample data: Foraging time, diving depth, and sex of African penguins</span></span>
<span id="cb3-195"><a href="#cb3-195"></a>foraging_time <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.2</span>, <span class="fl">1.5</span>, <span class="fl">1.8</span>, <span class="fl">2.0</span>, <span class="fl">2.3</span>, <span class="fl">2.5</span>, <span class="fl">2.8</span>, <span class="fl">3.0</span>, <span class="fl">3.3</span>, <span class="fl">3.5</span>)</span>
<span id="cb3-196"><a href="#cb3-196"></a>diving_depth <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">55</span>)</span>
<span id="cb3-197"><a href="#cb3-197"></a></span>
<span id="cb3-198"><a href="#cb3-198"></a><span class="co"># Randomly assign sex to each penguin</span></span>
<span id="cb3-199"><a href="#cb3-199"></a>sex <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">"Male"</span>, <span class="st">"Female"</span>), <span class="at">size =</span> <span class="fu">length</span>(foraging_time), <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-200"><a href="#cb3-200"></a></span>
<span id="cb3-201"><a href="#cb3-201"></a><span class="co"># Create a data frame</span></span>
<span id="cb3-202"><a href="#cb3-202"></a>penguin_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Sex =</span> sex,</span>
<span id="cb3-203"><a href="#cb3-203"></a>                           <span class="at">Foraging_Time =</span> foraging_time,</span>
<span id="cb3-204"><a href="#cb3-204"></a>                           <span class="at">Diving_Depth =</span> diving_depth)</span>
<span id="cb3-205"><a href="#cb3-205"></a></span>
<span id="cb3-206"><a href="#cb3-206"></a><span class="co"># Display the dataframe</span></span>
<span id="cb3-207"><a href="#cb3-207"></a>penguin_data <span class="sc">|&gt;</span> </span>
<span id="cb3-208"><a href="#cb3-208"></a>  <span class="fu">kbl</span>(<span class="at">caption =</span> <span class="st">"Foraging time and diving depth of African penguin."</span>,</span>
<span id="cb3-209"><a href="#cb3-209"></a>      <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"Sex"</span>, <span class="st">"Foraging time</span><span class="sc">\n</span><span class="st">(hr)"</span>, <span class="st">"Diving depth</span><span class="sc">\n</span><span class="st">(m)"</span>),</span>
<span id="cb3-210"><a href="#cb3-210"></a>      <span class="at">align =</span> <span class="st">"c"</span>, <span class="at">booktabs =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span></span>
<span id="cb3-211"><a href="#cb3-211"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>, <span class="at">html_font =</span> <span class="st">"Palatino"</span>)</span>
<span id="cb3-212"><a href="#cb3-212"></a><span class="in">```</span></span>
<span id="cb3-213"><a href="#cb3-213"></a></span>
<span id="cb3-214"><a href="#cb3-214"></a>In this example, we are interested in the mean foraging time of male and female penguins, controlling for their diving depth. An ANCOVA focuses on the differences in means (the categorical variable), and the continuous covariates (diving depth) is specifically controlled for to remove its effect from the dependent variable. This reduces the error variance and so more accurately assesses the comparison of group means. The assumptions of normality and homoscedasticity apply. The functions <span class="in">`aov()`</span> accommodates the categorical and continuous predictors.</span>
<span id="cb3-215"><a href="#cb3-215"></a></span>
<span id="cb3-216"><a href="#cb3-216"></a><span class="fu">#### Multivariate Analysis of Variance (MANOVA)</span></span>
<span id="cb3-217"><a href="#cb3-217"></a></span>
<span id="cb3-218"><a href="#cb3-218"></a>MANOVAs are similar to ANOVAs, except here you have *multiple dependent variables*, all *independent, continuous, and normally-distributed*. This is useful when you want to compare the means of multiple groups across multiple dependent variables. For example, you might want to compare the average foraging time together with diving depth of African penguins in three colonies (two in South Africa and one in Namibia) around the coast. The <span class="in">`manova()`</span> function in R is used to perform a MANOVA and there are similar variants to what we have seen in ANOVA.</span>
<span id="cb3-219"><a href="#cb3-219"></a></span>
<span id="cb3-220"><a href="#cb3-220"></a><span class="fu">### B. Hypotheses About the Proportions of Groups</span></span>
<span id="cb3-221"><a href="#cb3-221"></a></span>
<span id="cb3-222"><a href="#cb3-222"></a>You can compare the proportions of groups using tests for proportions when the outcome variable is binary (e.g., success/failure, presence/absence, up/down, day/night). These tests are used to determine if the proportion of successes differs between groups. Use the following tests to compare group proportions:</span>
<span id="cb3-223"><a href="#cb3-223"></a></span>
<span id="cb3-224"><a href="#cb3-224"></a><span class="fu">#### One-Sample Test for Proportions</span></span>
<span id="cb3-225"><a href="#cb3-225"></a></span>
<span id="cb3-226"><a href="#cb3-226"></a>**Example:** Is the proportion of African penguins foraging in a specific colony different from the known proportion of the same species in the general population? The data might look like this:</span>
<span id="cb3-227"><a href="#cb3-227"></a></span>
<span id="cb3-228"><a href="#cb3-228"></a><span class="ss">- </span><span class="in">`Sample data: 55 of the 100 penguins observed were foraging in a specific colony`</span></span>
<span id="cb3-229"><a href="#cb3-229"></a><span class="ss">- </span><span class="in">`The known proportion of penguins foraging in the general population is 60%`</span></span>
<span id="cb3-230"><a href="#cb3-230"></a></span>
<span id="cb3-231"><a href="#cb3-231"></a>In this scenario, we are comparing the proportion of a single sample (the proportion of foraging African penguins in a specific colony) to a known population proportion. The data must consist of a *binary outcome variable* (e.g., foraging vs. not foraging) and the observations must be independent. The <span class="in">`prop.test()`</span> function in R is used to perform this test, which can be either one-sided or two-sided. If the requirement of independent observations is not met, consider non-parametric alternatives, such as the sign test.</span>
<span id="cb3-232"><a href="#cb3-232"></a></span>
<span id="cb3-233"><a href="#cb3-233"></a><span class="fu">#### Two-Sample Test for Proportions</span></span>
<span id="cb3-234"><a href="#cb3-234"></a></span>
<span id="cb3-235"><a href="#cb3-235"></a>**Example:** Is the proportion of endangered sea turtles successfully reaching the ocean different between two beaches? Here are data:</span>
<span id="cb3-236"><a href="#cb3-236"></a></span>
<span id="cb3-239"><a href="#cb3-239"></a><span class="in">```{r}</span></span>
<span id="cb3-240"><a href="#cb3-240"></a><span class="co">#| echo: false</span></span>
<span id="cb3-241"><a href="#cb3-241"></a></span>
<span id="cb3-242"><a href="#cb3-242"></a><span class="co"># Sample data: Number of sea turtles reaching the ocean on two beaches</span></span>
<span id="cb3-243"><a href="#cb3-243"></a>Beach <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Beach A"</span>, <span class="st">"Beach B"</span>)</span>
<span id="cb3-244"><a href="#cb3-244"></a>Successes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">75</span>, <span class="dv">65</span>)</span>
<span id="cb3-245"><a href="#cb3-245"></a>Observed <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">120</span>)</span>
<span id="cb3-246"><a href="#cb3-246"></a></span>
<span id="cb3-247"><a href="#cb3-247"></a><span class="co"># Create the dataframe</span></span>
<span id="cb3-248"><a href="#cb3-248"></a>sea_turtle_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(Beach, Successes, Observed)</span>
<span id="cb3-249"><a href="#cb3-249"></a></span>
<span id="cb3-250"><a href="#cb3-250"></a><span class="co"># Display the dataframe using kable</span></span>
<span id="cb3-251"><a href="#cb3-251"></a><span class="fu">kable</span>(sea_turtle_data, <span class="at">format =</span> <span class="st">"pipe"</span>, <span class="at">caption =</span> <span class="st">"Number of Sea Turtles Reaching the Ocean on Two Beaches"</span>)</span>
<span id="cb3-252"><a href="#cb3-252"></a><span class="in">```</span></span>
<span id="cb3-253"><a href="#cb3-253"></a></span>
<span id="cb3-254"><a href="#cb3-254"></a>Here we compare the proportions from two independent samples (e.g., the proportion of sea turtles successfully reaching the ocean on Beach A versus Beach B). As before, the data yield *a binary outcome* (e.g., reached the ocean vs. did not reach the ocean) for each group, and the observations within each group are independent. The <span class="in">`prop.test()`</span> function is used it has one-sided or two-sided options. If the sample sizes are small or expected frequencies are low, consider using Fisher's exact test instead of the proportion test. If the assumption of independent observations within groups is violated, you may need to consider methods that account for dependency in the data, such as Generalised Estimating Equations (GEE) or mixed-effects models.</span>
<span id="cb3-255"><a href="#cb3-255"></a></span>
<span id="cb3-256"><a href="#cb3-256"></a><span class="fu">#### Chi-square Test for Count Data</span></span>
<span id="cb3-257"><a href="#cb3-257"></a></span>
<span id="cb3-258"><a href="#cb3-258"></a>**Example:** Is there an association between vegetation type and the presence of leopards in different areas of Kruger National Park? A hypothetical dataset:</span>
<span id="cb3-259"><a href="#cb3-259"></a></span>
<span id="cb3-262"><a href="#cb3-262"></a><span class="in">```{r}</span></span>
<span id="cb3-263"><a href="#cb3-263"></a><span class="co">#| echo: false</span></span>
<span id="cb3-264"><a href="#cb3-264"></a></span>
<span id="cb3-265"><a href="#cb3-265"></a><span class="co"># Sample data: Counts of leopard presence/absence across different vegetation types</span></span>
<span id="cb3-266"><a href="#cb3-266"></a><span class="co"># Vegetation types: Grassland, Woodland, Shrubland</span></span>
<span id="cb3-267"><a href="#cb3-267"></a><span class="co"># Presence/Absence of leopards: Presence, Absence</span></span>
<span id="cb3-268"><a href="#cb3-268"></a></span>
<span id="cb3-269"><a href="#cb3-269"></a><span class="co"># Create a matrix with the counts</span></span>
<span id="cb3-270"><a href="#cb3-270"></a>data_matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">20</span>, <span class="dv">30</span>, <span class="dv">25</span>, <span class="dv">40</span>, <span class="dv">35</span>, <span class="dv">15</span>), </span>
<span id="cb3-271"><a href="#cb3-271"></a>                      <span class="at">nrow =</span> <span class="dv">3</span>, </span>
<span id="cb3-272"><a href="#cb3-272"></a>                      <span class="at">byrow =</span> <span class="cn">TRUE</span>,</span>
<span id="cb3-273"><a href="#cb3-273"></a>                      <span class="at">dimnames =</span> <span class="fu">list</span>(<span class="at">Vegetation_Type =</span> <span class="fu">c</span>(<span class="st">"Grassland"</span>, <span class="st">"Woodland"</span>, <span class="st">"Shrubland"</span>),</span>
<span id="cb3-274"><a href="#cb3-274"></a>                                      <span class="at">Leopard_Presence =</span> <span class="fu">c</span>(<span class="st">"Presence"</span>, <span class="st">"Absence"</span>)))</span>
<span id="cb3-275"><a href="#cb3-275"></a></span>
<span id="cb3-276"><a href="#cb3-276"></a><span class="co"># Convert matrix to a contingency table</span></span>
<span id="cb3-277"><a href="#cb3-277"></a>contingency_table <span class="ot">&lt;-</span> <span class="fu">as.table</span>(data_matrix)</span>
<span id="cb3-278"><a href="#cb3-278"></a></span>
<span id="cb3-279"><a href="#cb3-279"></a><span class="co"># Display the contingency table using kable</span></span>
<span id="cb3-280"><a href="#cb3-280"></a><span class="fu">kable</span>(contingency_table, <span class="at">format =</span> <span class="st">"pipe"</span>, <span class="at">caption =</span> <span class="st">"Contingency Table of Plant Species and Insect Occurrence"</span>)</span>
<span id="cb3-281"><a href="#cb3-281"></a><span class="in">```</span></span>
<span id="cb3-282"><a href="#cb3-282"></a></span>
<span id="cb3-283"><a href="#cb3-283"></a>Here we examine the relationship between two categorical variables (vegetation type and leopard presence) within Kruger National Park. The data are organised into a contingency table, where each cell represents the count or frequency of observations for a specific combination of categories. The chi-square test of independence is used to determine if there's a significant association between the variables.</span>
<span id="cb3-284"><a href="#cb3-284"></a></span>
<span id="cb3-285"><a href="#cb3-285"></a>As with other categorical tests, the data yield *discrete outcomes* (e.g., savanna, woodland, or riverine for vegetation type; present or absent for leopard presence). The observations should be independent, meaning the presence of a leopard in one area should not influence its presence in another.</span>
<span id="cb3-286"><a href="#cb3-286"></a></span>
<span id="cb3-287"><a href="#cb3-287"></a>The <span class="in">`chisq.test()`</span> function in R is commonly used for this analysis. This test compares the observed frequencies in each cell of the contingency table to the frequencies that would be expected if there were no association between vegetation type and leopard presence.</span>
<span id="cb3-288"><a href="#cb3-288"></a></span>
<span id="cb3-289"><a href="#cb3-289"></a>If the sample size is large and the expected frequencies in each cell are adequate (typically &gt; 5), the chi-square test is appropriate. However, if the sample size is small or if there are cells with low expected frequencies, consider using Fisher's exact test instead.</span>
<span id="cb3-290"><a href="#cb3-290"></a></span>
<span id="cb3-291"><a href="#cb3-291"></a>If the assumption of independence is violated (e.g., if the data include multiple observations from the same leopard individuals or territories), you may need to consider more advanced methods that account for dependency in the data, such as log-linear models or Generalised Estimating Equations (GEE).</span>
<span id="cb3-292"><a href="#cb3-292"></a></span>
<span id="cb3-293"><a href="#cb3-293"></a><span class="fu">#### Fisher's Exact Test</span></span>
<span id="cb3-294"><a href="#cb3-294"></a></span>
<span id="cb3-295"><a href="#cb3-295"></a>**Example:** Is there a significant association between the presence of certain plant species and the occurrence of rare fynbos endemic insects in the Cape Floristic Region? Here are the data:</span>
<span id="cb3-296"><a href="#cb3-296"></a></span>
<span id="cb3-299"><a href="#cb3-299"></a><span class="in">```{r}</span></span>
<span id="cb3-300"><a href="#cb3-300"></a><span class="co">#| echo: false</span></span>
<span id="cb3-301"><a href="#cb3-301"></a></span>
<span id="cb3-302"><a href="#cb3-302"></a><span class="co"># Sample data: Counts of insect occurrence across different plant species</span></span>
<span id="cb3-303"><a href="#cb3-303"></a><span class="co"># Plant species: Plant_A, Plant_B</span></span>
<span id="cb3-304"><a href="#cb3-304"></a><span class="co"># Insect occurrence: Present, Absent</span></span>
<span id="cb3-305"><a href="#cb3-305"></a></span>
<span id="cb3-306"><a href="#cb3-306"></a><span class="co"># Create a matrix with the counts</span></span>
<span id="cb3-307"><a href="#cb3-307"></a>data_matrix <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">8</span>, <span class="dv">3</span>, <span class="dv">7</span>), </span>
<span id="cb3-308"><a href="#cb3-308"></a>                      <span class="at">nrow =</span> <span class="dv">2</span>, </span>
<span id="cb3-309"><a href="#cb3-309"></a>                      <span class="at">byrow =</span> <span class="cn">TRUE</span>,</span>
<span id="cb3-310"><a href="#cb3-310"></a>                      <span class="at">dimnames =</span> <span class="fu">list</span>(<span class="at">Plant_Species =</span> <span class="fu">c</span>(<span class="st">"Plant A"</span>, <span class="st">"Plant B"</span>),</span>
<span id="cb3-311"><a href="#cb3-311"></a>                                      <span class="at">Insect_Occurrence =</span> <span class="fu">c</span>(<span class="st">"Present"</span>, <span class="st">"Absent"</span>)))</span>
<span id="cb3-312"><a href="#cb3-312"></a></span>
<span id="cb3-313"><a href="#cb3-313"></a><span class="co"># Convert matrix to a contingency table</span></span>
<span id="cb3-314"><a href="#cb3-314"></a>contingency_table <span class="ot">&lt;-</span> <span class="fu">as.table</span>(data_matrix)</span>
<span id="cb3-315"><a href="#cb3-315"></a></span>
<span id="cb3-316"><a href="#cb3-316"></a><span class="co"># Display the contingency table using kable</span></span>
<span id="cb3-317"><a href="#cb3-317"></a><span class="fu">kable</span>(contingency_table, <span class="at">format =</span> <span class="st">"pipe"</span>, <span class="at">caption =</span> <span class="st">"Contingency Table of Plant Species and Insect Occurrence"</span>)</span>
<span id="cb3-318"><a href="#cb3-318"></a><span class="in">```</span></span>
<span id="cb3-319"><a href="#cb3-319"></a></span>
<span id="cb3-320"><a href="#cb3-320"></a>Fisher's Exact Test is used when we have two categorical variables and want to determine if there's a significant association between them, particularly when sample sizes are small or when we have sparse data in some categories. This test is especially useful in ecological studies where rare species or events are being investigated.</span>
<span id="cb3-321"><a href="#cb3-321"></a></span>
<span id="cb3-322"><a href="#cb3-322"></a>In this example we examine the relationship between the presence of specific plant species and the occurrence of rare fynbos endemic insects. The data are organised into a 2x2 contingency table, where each cell represents the count of observations for a combination of presence/absence of the plant species and the insect species.</span>
<span id="cb3-323"><a href="#cb3-323"></a></span>
<span id="cb3-324"><a href="#cb3-324"></a>The test calculates the exact probability of observing the given set of cell frequencies under the null hypothesis of no association. It does not rely on approximations and it more accurate than the chi-square test for small samples.</span>
<span id="cb3-325"><a href="#cb3-325"></a>Use the <span class="in">`fisher.test()`</span> function to perform this analysis. Like other categorical tests, the observations should be independent, meaning the presence of an insect in one area should not influence its presence in another.</span>
<span id="cb3-326"><a href="#cb3-326"></a></span>
<span id="cb3-327"><a href="#cb3-327"></a>Fisher's Exact Test is particularly appropriate when:</span>
<span id="cb3-328"><a href="#cb3-328"></a></span>
<span id="cb3-329"><a href="#cb3-329"></a><span class="ss">- </span>The total sample size is less than 1000</span>
<span id="cb3-330"><a href="#cb3-330"></a><span class="ss">- </span>The expected frequency in any cell of the contingency table is less than 5</span>
<span id="cb3-331"><a href="#cb3-331"></a><span class="ss">- </span>You're dealing with rare events or species</span>
<span id="cb3-332"><a href="#cb3-332"></a></span>
<span id="cb3-333"><a href="#cb3-333"></a>If the sample size becomes very large, Fisher's Exact Test can become computationally intensive, and the chi-square test may be more practical.</span>
<span id="cb3-334"><a href="#cb3-334"></a></span>
<span id="cb3-335"><a href="#cb3-335"></a>If the assumption of independence is violated (e.g., if the data include multiple observations from the same locations over time), you may need to consider more advanced methods that account for dependency in the data, such as mixed-effects models or Generalised Estimating Equations (GEE).</span>
<span id="cb3-336"><a href="#cb3-336"></a></span>
<span id="cb3-337"><a href="#cb3-337"></a><span class="fu">### C. Hypotheses About the Strength of Association {#sec-pearson}</span></span>
<span id="cb3-338"><a href="#cb3-338"></a></span>
<span id="cb3-339"><a href="#cb3-339"></a>**Example:** Is there a relationship between the foraging time and diving depth of African penguins? </span>
<span id="cb3-340"><a href="#cb3-340"></a></span>
<span id="cb3-343"><a href="#cb3-343"></a><span class="in">```{r}</span></span>
<span id="cb3-344"><a href="#cb3-344"></a><span class="co">#| echo: false</span></span>
<span id="cb3-345"><a href="#cb3-345"></a></span>
<span id="cb3-346"><a href="#cb3-346"></a><span class="co"># Sample data: Foraging time and diving depth of African penguins</span></span>
<span id="cb3-347"><a href="#cb3-347"></a>foraging_time <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.2</span>, <span class="fl">1.5</span>, <span class="fl">1.8</span>, <span class="fl">2.0</span>, <span class="fl">2.3</span>, <span class="fl">2.5</span>, <span class="fl">2.8</span>, <span class="fl">3.0</span>, <span class="fl">3.3</span>, <span class="fl">3.5</span>)</span>
<span id="cb3-348"><a href="#cb3-348"></a>diving_depth <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">55</span>)</span>
<span id="cb3-349"><a href="#cb3-349"></a></span>
<span id="cb3-350"><a href="#cb3-350"></a><span class="co"># Create a data frame</span></span>
<span id="cb3-351"><a href="#cb3-351"></a>penguin_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Foraging_Time =</span> foraging_time, <span class="at">Diving_Depth =</span> diving_depth)</span>
<span id="cb3-352"><a href="#cb3-352"></a></span>
<span id="cb3-353"><a href="#cb3-353"></a>penguin_data <span class="sc">|&gt;</span> </span>
<span id="cb3-354"><a href="#cb3-354"></a>  <span class="fu">kbl</span>(<span class="at">caption =</span> <span class="st">"Foraging time and diving depth of African penguin."</span>,</span>
<span id="cb3-355"><a href="#cb3-355"></a>      <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"Foraging time</span><span class="sc">\n</span><span class="st">(hr)"</span>, <span class="st">"Diving depth</span><span class="sc">\n</span><span class="st">(m)"</span>),</span>
<span id="cb3-356"><a href="#cb3-356"></a>      <span class="at">align =</span> <span class="st">"c"</span>, <span class="at">booktabs =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span></span>
<span id="cb3-357"><a href="#cb3-357"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>, <span class="at">html_font =</span> <span class="st">"Palatino"</span>)</span>
<span id="cb3-358"><a href="#cb3-358"></a>  </span>
<span id="cb3-359"><a href="#cb3-359"></a></span>
<span id="cb3-360"><a href="#cb3-360"></a><span class="co"># Display the data frame</span></span>
<span id="cb3-361"><a href="#cb3-361"></a><span class="co"># ht(penguin_data)</span></span>
<span id="cb3-362"><a href="#cb3-362"></a><span class="in">```</span></span>
<span id="cb3-363"><a href="#cb3-363"></a></span>
<span id="cb3-364"><a href="#cb3-364"></a>You'll want to use a Pearson's correlation to determine if there is a linear relationship between *two continuous variables*, both of them normally distributed and homoscedastic. A correlation analysis does not presume causation and does not provide a predictive model, both of which are the domain of regression. The strength of the relationship is quantified by the correlation coefficient called Pearson's rho, which ranges from -1 to 1. Use the <span class="in">`cor.test(..., method = "pearson")`</span> function in R to perform this analysis. </span>
<span id="cb3-365"><a href="#cb3-365"></a></span>
<span id="cb3-366"><a href="#cb3-366"></a>Non-parametric alternatives such as the Spearman's rank correlation or Kendall's tau correlation (see 'II. Non-Parametric Methods') are available and implemented with the same R function.</span>
<span id="cb3-367"><a href="#cb3-367"></a></span>
<span id="cb3-368"><a href="#cb3-368"></a><span class="fu">### D. Modelling and Predicting Causal Relationships</span></span>
<span id="cb3-369"><a href="#cb3-369"></a></span>
<span id="cb3-370"><a href="#cb3-370"></a>The relationship between one or a few predictors and an outcome can be represented by a function, which is a model that reconstructs part of the 'reality' of the observed phenomenon. Regression analysis helps you understand how changes in the continuous predictor variable(s) drive changes in a continuous outcome variable. The model quantifies the strength of the associations and makes predictions for new data points. You may use regression models for hypothesis testing and for identifying which predictor variables have the most substantial impact on the outcome.</span>
<span id="cb3-371"><a href="#cb3-371"></a></span>
<span id="cb3-372"><a href="#cb3-372"></a><span class="fu">#### Simple Linear Regression</span></span>
<span id="cb3-373"><a href="#cb3-373"></a></span>
<span id="cb3-374"><a href="#cb3-374"></a>**Example:** The same dataset of <span class="co">[</span><span class="ot">foraging time and diving depth of African penguins</span><span class="co">](#sec-pearson)</span> can be used to model the relationship between these two variables. Does diving depth depend on foraging time?</span>
<span id="cb3-375"><a href="#cb3-375"></a></span>
<span id="cb3-376"><a href="#cb3-376"></a>What is different now is that we are interested in *predicting the diving depth* (response) of penguins based on their foraging time (predictor). Assuming there is a linear response, we can use a simple linear regression model to quantify the relationship between these two continuous variables. The model provides an equation that describes how the diving depth changes as the foraging time increases. The assumptions of normality and homoscedasticity apply to the residuals, and are accessed after having fit the model.</span>
<span id="cb3-377"><a href="#cb3-377"></a></span>
<span id="cb3-378"><a href="#cb3-378"></a>This calls for a simple linear regression model and you can fit it using the <span class="in">`lm()`</span> function in R. The model can also be specified as a generalised linear model (GLM) with <span class="in">`glm(..., family = gaussian)`</span>.</span>
<span id="cb3-379"><a href="#cb3-379"></a></span>
<span id="cb3-380"><a href="#cb3-380"></a>If assumptions fail, apply data transformations (e.g., log, square root), robust regression (<span class="in">`rlm()`</span> in **MASS** package), or consider non-linear models.</span>
<span id="cb3-381"><a href="#cb3-381"></a></span>
<span id="cb3-382"><a href="#cb3-382"></a><span class="fu">#### Polynomial Regression</span></span>
<span id="cb3-383"><a href="#cb3-383"></a></span>
<span id="cb3-384"><a href="#cb3-384"></a>I'll not provide an example here. It suffices to say that a polynomial regression is effectively a simple linear regression that allows for a curvilinear relationship between the predictor and the outcome. To accomplish this, the model includes polynomial terms (e.g., quadratic, cubic, which are simply powers of the predictor) to capture the non-linear patterns in the data. The model can be fit using the <span class="in">`lm()`</span> function in R.</span>
<span id="cb3-385"><a href="#cb3-385"></a></span>
<span id="cb3-386"><a href="#cb3-386"></a>Assess the relationship between $x$ vs. $y$ by making a scatterplot of the data and eye balling a best fit curve through the scatter of points. Is the line curvy or bendy? Do you know in advance if a more complicated model describes the response? If the answer is 'yes' to the first and 'no' to the second question, then a polynomial regression might be just the thing for you.</span>
<span id="cb3-387"><a href="#cb3-387"></a></span>
<span id="cb3-388"><a href="#cb3-388"></a><span class="fu">#### Multiple Linear Regression (MLR) {#sec-mlr}</span></span>
<span id="cb3-389"><a href="#cb3-389"></a></span>
<span id="cb3-390"><a href="#cb3-390"></a>**Example:** I've added a second predictor to the dataset of <span class="co">[</span><span class="ot">foraging time and diving depth of African penguins</span><span class="co">](#sec-pearson)</span>. Does diving depth depend on the penguins' body mass index (BMI) and foraging time?</span>
<span id="cb3-391"><a href="#cb3-391"></a></span>
<span id="cb3-394"><a href="#cb3-394"></a><span class="in">```{r}</span></span>
<span id="cb3-395"><a href="#cb3-395"></a><span class="co">#| echo: false</span></span>
<span id="cb3-396"><a href="#cb3-396"></a></span>
<span id="cb3-397"><a href="#cb3-397"></a><span class="co"># Sample data: Foraging time, diving depth, and body mass index of African penguins</span></span>
<span id="cb3-398"><a href="#cb3-398"></a>body_mass_index <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.2</span>, <span class="fl">1.5</span>, <span class="fl">1.8</span>, <span class="fl">2.0</span>, <span class="fl">2.3</span>, <span class="fl">2.5</span>, <span class="fl">2.8</span>, <span class="fl">3.0</span>, <span class="fl">3.3</span>, <span class="fl">3.5</span>)</span>
<span id="cb3-399"><a href="#cb3-399"></a>foraging_time <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.2</span>, <span class="fl">1.5</span>, <span class="fl">1.8</span>, <span class="fl">2.0</span>, <span class="fl">2.3</span>, <span class="fl">2.5</span>, <span class="fl">2.8</span>, <span class="fl">3.0</span>, <span class="fl">3.3</span>, <span class="fl">3.5</span>)</span>
<span id="cb3-400"><a href="#cb3-400"></a>diving_depth <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>, <span class="dv">40</span>, <span class="dv">45</span>, <span class="dv">50</span>, <span class="dv">55</span>)</span>
<span id="cb3-401"><a href="#cb3-401"></a></span>
<span id="cb3-402"><a href="#cb3-402"></a><span class="co"># Create a data frame</span></span>
<span id="cb3-403"><a href="#cb3-403"></a>penguin_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">BMI =</span> body_mass_index,</span>
<span id="cb3-404"><a href="#cb3-404"></a>                           <span class="at">Foraging_Time =</span> foraging_time,</span>
<span id="cb3-405"><a href="#cb3-405"></a>                           <span class="at">Diving_Depth =</span> diving_depth)</span>
<span id="cb3-406"><a href="#cb3-406"></a></span>
<span id="cb3-407"><a href="#cb3-407"></a><span class="co"># Display the data frame</span></span>
<span id="cb3-408"><a href="#cb3-408"></a>penguin_data <span class="sc">|&gt;</span> </span>
<span id="cb3-409"><a href="#cb3-409"></a>  <span class="fu">kbl</span>(<span class="at">caption =</span> <span class="st">"Foraging time and diving depth of African penguin."</span>,</span>
<span id="cb3-410"><a href="#cb3-410"></a>      <span class="at">col.names =</span> <span class="fu">c</span>(<span class="st">"BMI"</span>, <span class="st">"Foraging time</span><span class="sc">\n</span><span class="st">(hr)"</span>, <span class="st">"Diving depth</span><span class="sc">\n</span><span class="st">(m)"</span>),</span>
<span id="cb3-411"><a href="#cb3-411"></a>      <span class="at">align =</span> <span class="st">"c"</span>, <span class="at">booktabs =</span> <span class="cn">TRUE</span>) <span class="sc">|&gt;</span></span>
<span id="cb3-412"><a href="#cb3-412"></a>  <span class="fu">kable_classic</span>(<span class="at">full_width =</span> <span class="cn">FALSE</span>, <span class="at">html_font =</span> <span class="st">"Palatino"</span>)</span>
<span id="cb3-413"><a href="#cb3-413"></a><span class="in">```</span></span>
<span id="cb3-414"><a href="#cb3-414"></a></span>
<span id="cb3-415"><a href="#cb3-415"></a>The only difference between this example and the simple linear regression is that we now have two predictors (foraging time and BMI) instead of one. The predictors can be *continuous* (as in the example) *and/or categorical*. If you are more concerned with the means of the categorical variables, consider an ANCOVA as an alternative option. The multiple linear regression model can be extended to include interaction terms between predictors. You can quantify the relationship between both predictors and the outcome simultaneously, and ask which of the two best predicts the response. The same assumptions apply as in the simple linear regression and we hope for a linear relationship between $x_1$ and $x_2$ vs. $y$. Other considerations are provided in the chapter on <span class="co">[</span><span class="ot">MLR</span><span class="co">](multiple_linear_regression.qmd)</span>.</span>
<span id="cb3-416"><a href="#cb3-416"></a></span>
<span id="cb3-417"><a href="#cb3-417"></a>The R functions <span class="in">`lm()`</span> and <span class="in">`glm(..., family = gaussian)`</span> accommodate situations such as these where we have multiple predictors.</span>
<span id="cb3-418"><a href="#cb3-418"></a></span>
<span id="cb3-419"><a href="#cb3-419"></a></span>
<span id="cb3-420"><a href="#cb3-420"></a></span>
<span id="cb3-421"><a href="#cb3-421"></a><span class="fu">#### Generalised Linear Models (GLM)</span></span>
<span id="cb3-422"><a href="#cb3-422"></a></span>
<span id="cb3-423"><a href="#cb3-423"></a>GLMs are a class of regression models that extend the simple linear regression framework to accommodate various types of response distributions. As such, they can accommodate data that violate the assumptions of normality and homoscedasticity, as well as situations where the response variable is not continuous.</span>
<span id="cb3-424"><a href="#cb3-424"></a></span>
<span id="cb3-425"><a href="#cb3-425"></a>Use GLMs to model count data (e.g., number of occurrences), binary outcomes (e.g., success/failure), and other non-continuous response variables that cannot be adequately represented by a normal distribution. Unlike linear models, which assume a normal error distribution, GLMs specify the distribution of the response variable using a probability distribution from the exponential family, such as the Gaussian (normal), binomial, Poisson, or negative binomial distributions.</span>
<span id="cb3-426"><a href="#cb3-426"></a></span>
<span id="cb3-427"><a href="#cb3-427"></a>GLMs incorporate a link function that relates the linear predictor (a linear combination of the predictor variables) to the expected value of the response variable. This link function can take various forms, including the identity (linear), logit (for binary data), probit, or other transformations, depending on the nature of the response variable and the desired relationship between the predictors and the outcome.</span>
<span id="cb3-428"><a href="#cb3-428"></a></span>
<span id="cb3-429"><a href="#cb3-429"></a>The <span class="in">`glm()`</span> function is a staple for fitting GLMs. It is designed to handle the exponential family distributions and will allow you to specify the appropriate distribution and link function for your data and research question. A few common types of GLMs are presented next.</span>
<span id="cb3-430"><a href="#cb3-430"></a></span>
<span id="cb3-431"><a href="#cb3-431"></a>*Logistic Regression* (@sec-generalised-linear-model)</span>
<span id="cb3-432"><a href="#cb3-432"></a></span>
<span id="cb3-433"><a href="#cb3-433"></a>You'll encounter binomial data in experiments or processes with binary outcomes, such as presence/absence, success/failure, or alive/dead. To model this type of data, you will want to use logistic regression. Logistic regression estimates the log-odds of the outcome as a linear combination of the predictor variables. The logistic function is then used to convert these log-odds into probabilities, which range from 0 to 1, so it is suitable for predicting the likelihood of the binary outcomes.</span>
<span id="cb3-434"><a href="#cb3-434"></a></span>
<span id="cb3-435"><a href="#cb3-435"></a><span class="ss">-   </span>**Use When:** You have a binary outcome variable and want to model the relationship between predictors and the probability of the outcome.</span>
<span id="cb3-436"><a href="#cb3-436"></a><span class="ss">-   </span>**Data Requirements:** Binary outcome, continuous or categorical predictors.</span>
<span id="cb3-437"><a href="#cb3-437"></a><span class="ss">-   </span>**Assumptions:** Linear relationship between the log-odds of the outcome and predictors.</span>
<span id="cb3-438"><a href="#cb3-438"></a><span class="ss">-   </span>**Diagnostics:** Check for influential observations, multicollinearity, and overall model fit.</span>
<span id="cb3-439"><a href="#cb3-439"></a><span class="ss">-   </span>**If Assumptions Fail:** Consider interactions, alternative link functions (probit, complementary log-log) in <span class="in">`glm()`</span>, or non-linear logistic regression, zero-inflated models when excess zeroes.</span>
<span id="cb3-440"><a href="#cb3-440"></a><span class="ss">-   </span>**R Function:** <span class="in">`glm(..., family = binomial)`</span></span>
<span id="cb3-441"><a href="#cb3-441"></a><span class="ss">-   </span>**Model Selection:** Stepwise regression, regularisation techniques, information criteria (AIC, BIC).</span>
<span id="cb3-442"><a href="#cb3-442"></a></span>
<span id="cb3-443"><a href="#cb3-443"></a>*Poisson Regression* (@sec-generalised-linear-model)</span>
<span id="cb3-444"><a href="#cb3-444"></a></span>
<span id="cb3-445"><a href="#cb3-445"></a>Typical examples of count data include the number of offspring, parasites, or seeds. Poisson regression is used to model the relationship between predictors and the count outcome. The model assumes that the count data follow a Poisson distribution, where the mean and variance are equal. Poisson regression is suitable for data with a single count outcome.</span>
<span id="cb3-446"><a href="#cb3-446"></a></span>
<span id="cb3-447"><a href="#cb3-447"></a><span class="ss">-   </span>**Use When:** You have count data and want to model the relationship between predictors and the count outcome.</span>
<span id="cb3-448"><a href="#cb3-448"></a><span class="ss">-   </span>**Data Requirements:** Count outcome, continuous or categorical predictors.</span>
<span id="cb3-449"><a href="#cb3-449"></a><span class="ss">-   </span>**Assumptions:** Equidispersion (variance equals the mean).</span>
<span id="cb3-450"><a href="#cb3-450"></a><span class="ss">-   </span>**Diagnostics:** Check for overdispersion, excess zeros, and overall model fit.</span>
<span id="cb3-451"><a href="#cb3-451"></a><span class="ss">-   </span>**If Assumptions Fail:** Negative binomial regression (`glm.nb()` in the **MASS** package, overdispersion), zero-inflated models (`zeroinfl()` in the **pscl** package, excess zeros).</span>
<span id="cb3-452"><a href="#cb3-452"></a><span class="ss">-   </span>**R Function:** <span class="in">`glm(..., family = poisson)`</span></span>
<span id="cb3-453"><a href="#cb3-453"></a></span>
<span id="cb3-454"><a href="#cb3-454"></a>*Negative Binomial Regression*</span>
<span id="cb3-455"><a href="#cb3-455"></a></span>
<span id="cb3-456"><a href="#cb3-456"></a>Negative binomial regression is an extension of Poisson regression that accommodates overdispersion, where the variance exceeds the mean. It is used when the count data exhibit more variability than expected under a Poisson distribution. The model assumes that the count data follow a negative binomial distribution, which has an additional parameter to account for overdispersion. Biological and ecological processes such as species abundance, parasite counts, and gene expression often exhibit overdispersion.</span>
<span id="cb3-457"><a href="#cb3-457"></a></span>
<span id="cb3-458"><a href="#cb3-458"></a><span class="ss">-   </span>**Use When:** You have count data with overdispersion and want to model the relationship between predictors and the count outcome.</span>
<span id="cb3-459"><a href="#cb3-459"></a><span class="ss">-   </span>**Data Requirements:** Count outcome, continuous or categorical</span>
<span id="cb3-460"><a href="#cb3-460"></a><span class="ss">-   </span>**Assumptions:** Overdispersion (variance exceeds the mean).</span>
<span id="cb3-461"><a href="#cb3-461"></a><span class="ss">-   </span>**Diagnostics:** Check for overdispersion, excess zeros, and overall model fit.</span>
<span id="cb3-462"><a href="#cb3-462"></a><span class="ss">-   </span>**R Function:** `glm.nb()` in **MASS** package</span>
<span id="cb3-463"><a href="#cb3-463"></a></span>
<span id="cb3-464"><a href="#cb3-464"></a>*Gamma Regression*</span>
<span id="cb3-465"><a href="#cb3-465"></a></span>
<span id="cb3-466"><a href="#cb3-466"></a>Gamma regression is for modelling continuous, positive outcomes that exhibit a right-skewed distribution and possibly also a non-constant variance (heteroscedasticity). The gamma distribution is well suited for continuous measurements where the variability increases as the mean increases. You might encounter this kind of distribution in growth rates, enzyme activity levels, species abundance data, and other phenomena or processes characterised by positive, skewed data.</span>
<span id="cb3-467"><a href="#cb3-467"></a></span>
<span id="cb3-468"><a href="#cb3-468"></a><span class="ss">-   </span>**Use When:** You have a continuous, positive outcome and want to model the relationship between predictors and the outcome.</span>
<span id="cb3-469"><a href="#cb3-469"></a><span class="ss">-   </span>**Data Requirements:** Continuous, positive outcome, continuous or categorical predictors.</span>
<span id="cb3-470"><a href="#cb3-470"></a><span class="ss">-   </span>**Assumptions:** Outcome values are positive, potentially non-constant variance.</span>
<span id="cb3-471"><a href="#cb3-471"></a><span class="ss">-   </span>**Diagnostics:** Check for overall model fit, influential observations, and residual</span>
<span id="cb3-472"><a href="#cb3-472"></a><span class="ss">-   </span>**R Function:** <span class="in">`glm(..., family = Gamma)`</span></span>
<span id="cb3-473"><a href="#cb3-473"></a></span>
<span id="cb3-474"><a href="#cb3-474"></a>*Beta Regression*</span>
<span id="cb3-475"><a href="#cb3-475"></a></span>
<span id="cb3-476"><a href="#cb3-476"></a>Beta regression is a statistical technique appropriate when the response variable is a continuous proportion or rate bounded between 0 and 1. These types of data might, for example, arise in ecology where one might study the proportions of time animals spend exhibiting different behaviours, the relative abundances of species in a community, or the proportions of habitat patches comprising a landscape. Proportional data inherently exhibit heteroscedasticity (non-constant variance).</span>
<span id="cb3-477"><a href="#cb3-477"></a></span>
<span id="cb3-478"><a href="#cb3-478"></a><span class="ss">-   </span>**Use When:** You have a proportional outcome ($0 &lt; y &lt; 1$) and want to model the relationship between predictors and the outcome.</span>
<span id="cb3-479"><a href="#cb3-479"></a><span class="ss">-   </span>**Data Requirements:** Proportional outcome ($0 &lt; y &lt; 1$), continuous or categorical predictors.</span>
<span id="cb3-480"><a href="#cb3-480"></a><span class="ss">-   </span>**Assumptions:** Outcome values within ($0,1$), potentially non-constant variance.</span>
<span id="cb3-481"><a href="#cb3-481"></a><span class="ss">-   </span>**Diagnostics:** Check for overall model fit, influential observations, and residual analysis.</span>
<span id="cb3-482"><a href="#cb3-482"></a><span class="ss">-   </span>**If Assumptions Fail:** Transformations, consider alternative link functions, or zero/one-inflated beta regression.</span>
<span id="cb3-483"><a href="#cb3-483"></a><span class="ss">-   </span>**R Function:** `betareg()` in the **betareg** package</span>
<span id="cb3-484"><a href="#cb3-484"></a></span>
<span id="cb3-485"><a href="#cb3-485"></a>**Modelling Non-Linear Relationships**</span>
<span id="cb3-486"><a href="#cb3-486"></a></span>
<span id="cb3-487"><a href="#cb3-487"></a>We use non-linear models when the relationship between predictor variables and the outcome variable is not linear. This non-linearity arises from the predictor variables themselves being non-linearly related to the outcome or from the model's parameters (coefficients) appearing non-linearly in the functional form. The visualised response curve is typically curved, rather than a straight line. These models are often derived from theoretical understanding or prior knowledge about the underlying mechanisms governing the relationship between the predictors and the outcome variables.</span>
<span id="cb3-488"><a href="#cb3-488"></a></span>
<span id="cb3-489"><a href="#cb3-489"></a>*Non-Linear Least Squares (NLS) Regression* (@sec-nonlinear-regression)</span>
<span id="cb3-490"><a href="#cb3-490"></a></span>
<span id="cb3-491"><a href="#cb3-491"></a><span class="ss">-   </span>**Use When:** The relationship between the predictors and the outcome is non-linear.</span>
<span id="cb3-492"><a href="#cb3-492"></a><span class="ss">-   </span>**Data Requirements:** Continuous outcome, continuous predictors.</span>
<span id="cb3-493"><a href="#cb3-493"></a><span class="ss">-   </span>**Assumptions:** Appropriate functional form, normality, and homoscedasticity of residuals.</span>
<span id="cb3-494"><a href="#cb3-494"></a><span class="ss">-   </span>**Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points.</span>
<span id="cb3-495"><a href="#cb3-495"></a><span class="ss">-   </span>**R Function:** <span class="in">`nls()`</span> (for non-linear regression models with user-specified functions)</span>
<span id="cb3-496"><a href="#cb3-496"></a></span>
<span id="cb3-497"><a href="#cb3-497"></a>**Generalised Non-Linear Models (GNLMs)**</span>
<span id="cb3-498"><a href="#cb3-498"></a></span>
<span id="cb3-499"><a href="#cb3-499"></a>GNLMs are an extension of generalised linear models (GLMs) that allow for non-linear relationships between the predictors and the outcome variable. GNLMs are used when the relationship between the predictors and the outcome is non-linear, and the outcome variable follows a non-normal distribution. GNLMs are particularly useful for count data, binary outcomes, and other non-continuous response variables that exhibit non-linear relationships with the predictors.</span>
<span id="cb3-500"><a href="#cb3-500"></a></span>
<span id="cb3-501"><a href="#cb3-501"></a>**Linear and Non-Linear Hierarchical Models (Mixed-Effects Models)**</span>
<span id="cb3-502"><a href="#cb3-502"></a></span>
<span id="cb3-503"><a href="#cb3-503"></a>Hierarchical models are used when data are structured hierarchically, such as when multiple observations are nested within higher-level units (e.g., plants within fields, sheep within rangelands). These models account for the correlation between observations within the same group and allow for the estimation of both fixed effects (population-level parameters) and random effects (group-level parameters). Hierarchical models are also known as multilevel models or mixed-effects models.</span>
<span id="cb3-504"><a href="#cb3-504"></a></span>
<span id="cb3-505"><a href="#cb3-505"></a>*Linear Mixed-Effects Models (LMMs)* (Section X.X.X)</span>
<span id="cb3-506"><a href="#cb3-506"></a></span>
<span id="cb3-507"><a href="#cb3-507"></a><span class="ss">-   </span>**Use When:** You have nested or hierarchical data structures and the relationship between the predictors and the outcome is linear.</span>
<span id="cb3-508"><a href="#cb3-508"></a><span class="ss">-   </span>**Data Requirements:** Continuous outcome, continuous predictors, potentially with nested or hierarchical data structures.</span>
<span id="cb3-509"><a href="#cb3-509"></a><span class="ss">-   </span>**Assumptions:** Normality, homoscedasticity of residuals, correct specification of random effects structure.</span>
<span id="cb3-510"><a href="#cb3-510"></a><span class="ss">-   </span>**If Assumptions Fail:** Consider transformations, robust regression, or non-linear mixed-effects models.</span>
<span id="cb3-511"><a href="#cb3-511"></a><span class="ss">-   </span>**Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.</span>
<span id="cb3-512"><a href="#cb3-512"></a><span class="ss">-   </span>**R Function:** `lmer()` in the **lme4** package (for linear mixed-effects models with user-specified functions)</span>
<span id="cb3-513"><a href="#cb3-513"></a></span>
<span id="cb3-514"><a href="#cb3-514"></a>*Non-Linear Mixed-Effects Models (NLMMs)* (@sec-nonlinear-regression)</span>
<span id="cb3-515"><a href="#cb3-515"></a></span>
<span id="cb3-516"><a href="#cb3-516"></a><span class="ss">-   </span>**Use When:** You have nested or hierarchical data structures and the relationship between the predictors and the outcome is non-linear.</span>
<span id="cb3-517"><a href="#cb3-517"></a><span class="ss">-   </span>**Data Requirements:** Continuous outcome, continuous predictors, potentially with nested or hierarchical data structures.</span>
<span id="cb3-518"><a href="#cb3-518"></a><span class="ss">-   </span>**Assumptions:** Appropriate functional form, normality, and homoscedasticity of residuals, correct specification of random effects structure.</span>
<span id="cb3-519"><a href="#cb3-519"></a><span class="ss">-   </span>**If Assumptions Fail:** Generalised non-linear mixed models (GNLMMs) and generalised additive mixed models (GAMMs) can be used when the assumptions of non-linear mixed models (NLMMs) are violated. Else, consult a statistician.</span>
<span id="cb3-520"><a href="#cb3-520"></a><span class="ss">-   </span>**Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.</span>
<span id="cb3-521"><a href="#cb3-521"></a><span class="ss">-   </span>**R Function:** `nlme()` in the **nlme** package (for non-linear mixed-effects models with user-specified functions)</span>
<span id="cb3-522"><a href="#cb3-522"></a></span>
<span id="cb3-523"><a href="#cb3-523"></a>**Generalised Linear and Non-Linear Mixed-Effects Models (GLMMs and GNLMMs)**</span>
<span id="cb3-524"><a href="#cb3-524"></a></span>
<span id="cb3-525"><a href="#cb3-525"></a>GLMMs and GNLMMs combine the flexibility of regression model generalisation (i.e. by accommodating non-Gaussian distribution families) with the ability to account for nested or hierarchical data structures. GLMMs are used when the outcome variable is not normally distributed (a different, known distribution) and the data are structured hierarchically. GLMMs include both fixed effects (population-level parameters) and random effects (group-level parameters) and can accommodate a wide range of outcome distributions, including binary, count, and continuous outcomes.</span>
<span id="cb3-526"><a href="#cb3-526"></a></span>
<span id="cb3-527"><a href="#cb3-527"></a><span class="ss">-   </span>**Use When:** You have non-normally distributed outcome data and nested or hierarchical data structures.</span>
<span id="cb3-528"><a href="#cb3-528"></a><span class="ss">-   </span>**Data Requirements:** Binary outcome, continuous or categorical predictors, potentially with nested or hierarchical data structures.</span>
<span id="cb3-529"><a href="#cb3-529"></a><span class="ss">-   </span>**Assumptions:** Linear relationship between the log-odds of the outcome and predictors, correct specification of random effects structure.</span>
<span id="cb3-530"><a href="#cb3-530"></a><span class="ss">-   </span>**Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.</span>
<span id="cb3-531"><a href="#cb3-531"></a><span class="ss">-   </span>**R Function:** `glmer()` in the **lme4** package</span>
<span id="cb3-532"><a href="#cb3-532"></a></span>
<span id="cb3-533"><a href="#cb3-533"></a>**Other Regression Models**</span>
<span id="cb3-534"><a href="#cb3-534"></a></span>
<span id="cb3-535"><a href="#cb3-535"></a>*Zero-Inflated Models*</span>
<span id="cb3-536"><a href="#cb3-536"></a></span>
<span id="cb3-537"><a href="#cb3-537"></a><span class="ss">-   </span>**Use When:** You have count data with an excess of zeros and want to model the zero-inflation separately from the count process.</span>
<span id="cb3-538"><a href="#cb3-538"></a><span class="ss">-   </span>**Data Requirements:** Count outcome, continuous or categorical</span>
<span id="cb3-539"><a href="#cb3-539"></a><span class="ss">-   </span>**Assumptions:** Correct specification of zero-inflation and count processes, no omitted variables.</span>
<span id="cb3-540"><a href="#cb3-540"></a><span class="ss">-   </span>**Diagnostics:** Check zero-inflation and count process, overall model fit.</span>
<span id="cb3-541"><a href="#cb3-541"></a><span class="ss">-   </span>**R Function:** `zeroinfl()` in the **pscl** package</span>
<span id="cb3-542"><a href="#cb3-542"></a></span>
<span id="cb3-543"><a href="#cb3-543"></a>*Survival Analysis*</span>
<span id="cb3-544"><a href="#cb3-544"></a></span>
<span id="cb3-545"><a href="#cb3-545"></a><span class="ss">-   </span>**Data Requirements:** Time-to-event outcome, continuous or categorical predictors.</span>
<span id="cb3-546"><a href="#cb3-546"></a><span class="ss">-   </span>**Assumptions:** Proportional hazards, non-informative censoring.</span>
<span id="cb3-547"><a href="#cb3-547"></a><span class="ss">-   </span>**Diagnostics:** Check proportional hazards assumption, influential observations, and overall model fit.</span>
<span id="cb3-548"><a href="#cb3-548"></a><span class="ss">-   </span>**R Function:** <span class="in">`survival::coxph()`</span></span>
<span id="cb3-549"><a href="#cb3-549"></a></span>
<span id="cb3-550"><a href="#cb3-550"></a>*Time Series Analysis*</span>
<span id="cb3-551"><a href="#cb3-551"></a></span>
<span id="cb3-552"><a href="#cb3-552"></a><span class="ss">-   </span>**Data Requirements:** Time-ordered data, potentially with autocorrelation.</span>
<span id="cb3-553"><a href="#cb3-553"></a><span class="ss">-   </span>**Assumptions:** Stationarity, no autocorrelation in residuals.</span>
<span id="cb3-554"><a href="#cb3-554"></a><span class="ss">-   </span>**Diagnostics:** Check autocorrelation, stationarity, and overall model fit.</span>
<span id="cb3-555"><a href="#cb3-555"></a><span class="ss">-   </span>**R Function:** `arima()`, `auto.arima()` in the **forecast** package</span>
<span id="cb3-556"><a href="#cb3-556"></a></span>
<span id="cb3-557"><a href="#cb3-557"></a>*Structural Equation Modelling (SEM)*</span>
<span id="cb3-558"><a href="#cb3-558"></a></span>
<span id="cb3-559"><a href="#cb3-559"></a><span class="ss">-   </span>**Data Requirements:** Continuous outcome, continuous</span>
<span id="cb3-560"><a href="#cb3-560"></a><span class="ss">-   </span>**Assumptions:** Correct specification of the structural model, no omitted variables, no measurement error.</span>
<span id="cb3-561"><a href="#cb3-561"></a><span class="ss">-   </span>**Diagnostics:** Check model fit, parameter estimates, and overall model validity.</span>
<span id="cb3-562"><a href="#cb3-562"></a><span class="ss">-   </span>**R Function:** `sem()` in the **lavaan** package</span>
<span id="cb3-563"><a href="#cb3-563"></a></span>
<span id="cb3-564"><a href="#cb3-564"></a>*Bayesian Regression*</span>
<span id="cb3-565"><a href="#cb3-565"></a></span>
<span id="cb3-566"><a href="#cb3-566"></a><span class="ss">-   </span>**Data Requirements:** Continuous outcome, continuous or categorical predictors.</span>
<span id="cb3-567"><a href="#cb3-567"></a><span class="ss">-   </span>**Assumptions:** Correct specification of priors, likelihood, and model structure.</span>
<span id="cb3-568"><a href="#cb3-568"></a><span class="ss">-   </span>**Diagnostics:** Check for convergence, posterior predictive checks, and overall model fit.</span>
<span id="cb3-569"><a href="#cb3-569"></a><span class="ss">-   </span>**R Function:** <span class="in">`brms::brm()`</span></span>
<span id="cb3-570"><a href="#cb3-570"></a></span>
<span id="cb3-571"><a href="#cb3-571"></a><span class="fu">## II. Non-Parametric Methods (Distribution-Free)</span></span>
<span id="cb3-572"><a href="#cb3-572"></a></span>
<span id="cb3-573"><a href="#cb3-573"></a>Non-parametric statistics are statistical methods that do not rely on assumptions about the specific form or parameters of the population distribution. They are also referred to as *distribution-free methods*. These methods often use ranks or other order statistics of the data rather than the actual data values themselves.</span>
<span id="cb3-574"><a href="#cb3-574"></a></span>
<span id="cb3-575"><a href="#cb3-575"></a></span>
<span id="cb3-576"><a href="#cb3-576"></a><span class="fu">### A. Hypotheses About Groups</span></span>
<span id="cb3-577"><a href="#cb3-577"></a></span>
<span id="cb3-578"><a href="#cb3-578"></a>*One-Sample Tests for Medians*</span>
<span id="cb3-579"><a href="#cb3-579"></a></span>
<span id="cb3-580"><a href="#cb3-580"></a>Use a one-sample test to compare the median of a single sample to a known population median. It is as an alternative to one-sample *t*-tests when the data do not meet the assumptions of parametric tests.</span>
<span id="cb3-581"><a href="#cb3-581"></a></span>
<span id="cb3-582"><a href="#cb3-582"></a><span class="ss">-   </span>Wilcoxon signed-rank test</span>
<span id="cb3-583"><a href="#cb3-583"></a><span class="ss">-   </span>Sign test</span>
<span id="cb3-584"><a href="#cb3-584"></a></span>
<span id="cb3-585"><a href="#cb3-585"></a>*Two-Sample Tests for Medians* (Section X.X.X)</span>
<span id="cb3-586"><a href="#cb3-586"></a></span>
<span id="cb3-587"><a href="#cb3-587"></a>Use two-sample tests to compare the medians of two independent or related samples. Use it when the assumptions of parametric two-sample tests are violated.</span>
<span id="cb3-588"><a href="#cb3-588"></a></span>
<span id="cb3-589"><a href="#cb3-589"></a><span class="ss">-   </span>Mann-Whitney U test (two independent groups)</span>
<span id="cb3-590"><a href="#cb3-590"></a><span class="ss">-   </span>Wilcoxon rank-sum test (two independent groups)</span>
<span id="cb3-591"><a href="#cb3-591"></a><span class="ss">-   </span>Kruskal-Wallis test (multiple groups)</span>
<span id="cb3-592"><a href="#cb3-592"></a><span class="ss">-   </span>Friedman test (related samples)</span>
<span id="cb3-593"><a href="#cb3-593"></a></span>
<span id="cb3-594"><a href="#cb3-594"></a></span>
<span id="cb3-595"><a href="#cb3-595"></a><span class="fu">### B. Hypotheses About Proportions</span></span>
<span id="cb3-596"><a href="#cb3-596"></a></span>
<span id="cb3-597"><a href="#cb3-597"></a><span class="ss">-   </span>*Chi-Square Test for Independence:* Comparing proportions of two groups</span>
<span id="cb3-598"><a href="#cb3-598"></a></span>
<span id="cb3-599"><a href="#cb3-599"></a></span>
<span id="cb3-600"><a href="#cb3-600"></a><span class="fu">### C. Correlation Analysis for Tests of Association</span></span>
<span id="cb3-601"><a href="#cb3-601"></a></span>
<span id="cb3-602"><a href="#cb3-602"></a>Use non-parametric correlation to assess the strength and direction of a relationship between two continuous (or ordinal) variables when the assumptions of parametric correlation tests cannot be met.</span>
<span id="cb3-603"><a href="#cb3-603"></a></span>
<span id="cb3-604"><a href="#cb3-604"></a>*Spearman's Rank Correlation* (@sec-correlation)</span>
<span id="cb3-605"><a href="#cb3-605"></a></span>
<span id="cb3-606"><a href="#cb3-606"></a>A non-parametric measure of the strength and direction of association between two variables.</span>
<span id="cb3-607"><a href="#cb3-607"></a></span>
<span id="cb3-608"><a href="#cb3-608"></a>*Kendall's Tau Correlation* (@sec-correlation)</span>
<span id="cb3-609"><a href="#cb3-609"></a></span>
<span id="cb3-610"><a href="#cb3-610"></a>A non-parametric measure of the strength and direction of association between two variables.</span>
<span id="cb3-611"><a href="#cb3-611"></a></span>
<span id="cb3-612"><a href="#cb3-612"></a></span>
<span id="cb3-613"><a href="#cb3-613"></a><span class="fu">### D. Regression Analysis</span></span>
<span id="cb3-614"><a href="#cb3-614"></a></span>
<span id="cb3-615"><a href="#cb3-615"></a>*Quantile Regression* (Section X.X.X)</span>
<span id="cb3-616"><a href="#cb3-616"></a></span>
<span id="cb3-617"><a href="#cb3-617"></a>Models different quantiles of the response distribution.</span>
<span id="cb3-618"><a href="#cb3-618"></a></span>
<span id="cb3-619"><a href="#cb3-619"></a>*Robust Regression* (Section X.X.X)</span>
<span id="cb3-620"><a href="#cb3-620"></a></span>
<span id="cb3-621"><a href="#cb3-621"></a>Less sensitive to outliers than ordinary least squares regression.</span>
<span id="cb3-622"><a href="#cb3-622"></a></span>
<span id="cb3-623"><a href="#cb3-623"></a>*Kernel Density Estimation*</span>
<span id="cb3-624"><a href="#cb3-624"></a></span>
<span id="cb3-625"><a href="#cb3-625"></a>KDE is a non-parametric method for visualising the distribution of a continuous variable. Unlike histograms, which bin data into discrete intervals, KDE creates a smooth curve that represents the estimated probability density function (PDF) of the underlying data. It does this by placing a kernel function (often a symmetric curve like a Gaussian or Epanechnikov) at each data point and summing up the contributions of these kernels across the entire range of the variable.  The bandwidth of the kernel controls the smoothness of the resulting density estimate. Wider bandwidths lead to smoother curves but may obscure finer details, while narrower bandwidths reveal more local fluctuations but can be noisy. KDE is useful when the underlying distribution of the data is unknown or non-standard and it offers a convenient way to visualise and understand the shape and spread of the data without being constrained by parametric assumptions.</span>
<span id="cb3-626"><a href="#cb3-626"></a></span>
<span id="cb3-627"><a href="#cb3-627"></a>*Local Regression (LOESS)*</span>
<span id="cb3-628"><a href="#cb3-628"></a></span>
<span id="cb3-629"><a href="#cb3-629"></a>LOESS (Locally Estimated Scatterplot Smoothing) is a non-parametric regression technique that produces a smooth curve through a set of data points by fitting simple models to localised subsets of the data. It achieves this by weighting the data points in each subset, with higher weights assigned to points closer to the point being estimated. The model used for local fitting is typically a low-degree polynomial, although other choices are possible.</span>
<span id="cb3-630"><a href="#cb3-630"></a></span>
<span id="cb3-631"><a href="#cb3-631"></a>LOESS is primarily used for data exploration and visualisation. It is best known for smoothing scatterplots and revealing underlying trends or patterns in the data. It is advantageous because it doesn't assume any particular functional form for the relationship between the predictors and the response variable, so it to adapts to various data shapes. But LOESS does not provide a single, easily interpretable equation for the entire dataset, making it less suitable for making predictions or drawing global inferences. It can also be computationally demanding with large datasets as it fits separate models in the vicinity of locally-selected points.</span>
<span id="cb3-632"><a href="#cb3-632"></a></span>
<span id="cb3-633"><a href="#cb3-633"></a>*Penalised Regression*</span>
<span id="cb3-634"><a href="#cb3-634"></a></span>
<span id="cb3-635"><a href="#cb3-635"></a>Penalised regression (also known as regularisation) is used to enhance the performance of regression models. This might be desirable when dealing with high-dimensional data or when the predictor variables are highly collinear. It introduces a penalty to the regression objective function which discourages the model from having overly complex or large coefficients. This effectively prevents overfitting. Common types of penalised regression include Ridge regression (L2 regularisation), which adds the sum of the squared coefficients as a penalty term, and Lasso regression (L1 regularisation), which adds the sum of the absolute values of the coefficients. The penalty terms encourage simpler models by shrinking some coefficients towards zero, with Lasso potentially setting some coefficients exactly to zero, thus performing variable selection. The balance between fitting the data well and maintaining model simplicity helps in improving the modelâ€™s generalisation to new data. Penalised regression methods can achieve a trade-off between bias and variance and result in more robust and interpretable models.</span>
<span id="cb3-636"><a href="#cb3-636"></a></span>
<span id="cb3-637"><a href="#cb3-637"></a></span>
<span id="cb3-638"><a href="#cb3-638"></a><span class="fu">## III. Semi-Parametric Methods</span></span>
<span id="cb3-639"><a href="#cb3-639"></a></span>
<span id="cb3-640"><a href="#cb3-640"></a>Semi-parametric methods combine parametric and non-parametric techniques to provide a balance between flexibility and efficiency. These methods are useful when the assumptions of parametric tests are violated, but the data do not meet the requirements for non-parametric tests. Semi-parametric methods are often more powerful than non-parametric tests, as they make fewer assumptions about the data distribution. These methods are particularly useful when the sample size is small or when the data are skewed or have outliers.</span>
<span id="cb3-641"><a href="#cb3-641"></a></span>
<span id="cb3-642"><a href="#cb3-642"></a>*Generalised Additive Models (GAMs)* (@sec-generalised-additive-models)</span>
<span id="cb3-643"><a href="#cb3-643"></a></span>
<span id="cb3-644"><a href="#cb3-644"></a><span class="ss">-   </span>**Use When:** You have non-linear relationships between predictors and outcome.</span>
<span id="cb3-645"><a href="#cb3-645"></a><span class="ss">-   </span>**R Function:** `gam()` in the **mgcv** package; also `gamm4()` in the **gamm4** package</span>
<span id="cb3-646"><a href="#cb3-646"></a><span class="ss">-   </span>**Data Requirements:** Continuous, binary, or categorical outcome, continuous or categorical predictors, potentially with nested or hierarchical data structures.</span>
<span id="cb3-647"><a href="#cb3-647"></a><span class="ss">-   </span>**Advantages:** Flexible modelling of non-linear relationships using smoothing functions, can handle mixed-effects structures.</span>
<span id="cb3-648"><a href="#cb3-648"></a><span class="ss">-   </span>**Limitations:** Interpretation can be challenging, potential overfitting.</span>
<span id="cb3-649"><a href="#cb3-649"></a></span>
<span id="cb3-650"><a href="#cb3-650"></a>*Generalised Estimating Equations (GEEs)*</span>
<span id="cb3-651"><a href="#cb3-651"></a></span>
<span id="cb3-652"><a href="#cb3-652"></a><span class="ss">-   </span>**Use When:** You have correlated data and non-normally distributed outcomes.</span>
<span id="cb3-653"><a href="#cb3-653"></a><span class="ss">-   </span>**R Function:** `geeglm()` in the **geepack** package; also functions in the **gee** package</span>
<span id="cb3-654"><a href="#cb3-654"></a><span class="ss">-   </span>**Data Requirements:** Correlated data, non-normal outcomes, continuous or categorical predictors.</span>
<span id="cb3-655"><a href="#cb3-655"></a><span class="ss">-   </span>**Advantages:** Robust to misspecification of the correlation structure, can handle non-normal outcomes, flexible in handling missing data.</span>
<span id="cb3-656"><a href="#cb3-656"></a><span class="ss">-   </span>**Limitations:** Assumes correct specification of the correlation structure, may be less efficient than mixed-effects models.</span>
<span id="cb3-657"><a href="#cb3-657"></a></span>
<span id="cb3-658"><a href="#cb3-658"></a>*Semi-Parametric Survival Models*</span>
<span id="cb3-659"><a href="#cb3-659"></a></span>
<span id="cb3-660"><a href="#cb3-660"></a><span class="ss">-   </span>**Use When:** You have time-to-event data and want to model the hazard function.</span>
<span id="cb3-661"><a href="#cb3-661"></a><span class="ss">-   </span>**R Function:** `coxph()` in the **survival** package</span>
<span id="cb3-662"><a href="#cb3-662"></a><span class="ss">-   </span>**Data Requirements:** Time-to-event data, censoring, continuous or categorical predictors.</span>
<span id="cb3-663"><a href="#cb3-663"></a><span class="ss">-   </span>**Assumptions:** Proportional hazards assumption, independence of censoring.</span>
<span id="cb3-664"><a href="#cb3-664"></a><span class="ss">-   </span>**Diagnostics:** Check proportional hazards assumption, influential observations, goodness</span>
<span id="cb3-665"><a href="#cb3-665"></a></span>
<span id="cb3-666"><a href="#cb3-666"></a>*Spline Regression*</span>
<span id="cb3-667"><a href="#cb3-667"></a></span>
<span id="cb3-668"><a href="#cb3-668"></a><span class="ss">-   </span>**Use When:** You have non-linear relationships between predictors and outcome.</span>
<span id="cb3-669"><a href="#cb3-669"></a><span class="ss">-   </span>**R Function:** `lm()` with splines, `gam()` in the **mgcv** package</span>
<span id="cb3-670"><a href="#cb3-670"></a><span class="ss">-   </span>**Data Requirements:** Continuous outcome, continuous predictors.</span>
<span id="cb3-671"><a href="#cb3-671"></a><span class="ss">-   </span>**Assumptions:** Linearity within each spline, potentially non-constant variance.</span>
<span id="cb3-672"><a href="#cb3-672"></a><span class="ss">-   </span>**Diagnostics:** Check for overall model fit, influential observations, and residual analysis.</span>
<span id="cb3-673"><a href="#cb3-673"></a><span class="ss">-   </span>**If Assumptions Fail:** Transformations, consider alternative link functions, or penalised regression.</span>
<span id="cb3-674"><a href="#cb3-674"></a></span>
<span id="cb3-675"><a href="#cb3-675"></a></span>
<span id="cb3-676"><a href="#cb3-676"></a><span class="fu">## IV. Machine Learning Methods</span></span>
<span id="cb3-677"><a href="#cb3-677"></a></span>
<span id="cb3-678"><a href="#cb3-678"></a>Machine learning methods are a set of algorithms that can learn patterns from data without being explicitly programmed. These methods are particularly useful for prediction, classification, and clustering tasks. Machine learning models can handle complex relationships in the data and are often more flexible than traditional statistical models. However, they can be more computationally intensive and may require more data to train effectively.</span>
<span id="cb3-679"><a href="#cb3-679"></a></span>
<span id="cb3-680"><a href="#cb3-680"></a>*Random Forests*</span>
<span id="cb3-681"><a href="#cb3-681"></a></span>
<span id="cb3-682"><a href="#cb3-682"></a>A machine learning method that uses an ensemble of decision trees to predict an outcome.</span>
<span id="cb3-683"><a href="#cb3-683"></a></span>
<span id="cb3-684"><a href="#cb3-684"></a>*Support Vector Machines*</span>
<span id="cb3-685"><a href="#cb3-685"></a></span>
<span id="cb3-686"><a href="#cb3-686"></a>A machine learning method that finds the optimal hyperplane to separate two classes of data.</span>
<span id="cb3-687"><a href="#cb3-687"></a></span>
<span id="cb3-688"><a href="#cb3-688"></a>*Ensemble Methods*</span>
<span id="cb3-689"><a href="#cb3-689"></a></span>
<span id="cb3-690"><a href="#cb3-690"></a>A machine learning technique that combines the predictions of multiple models to improve accuracy.</span>
<span id="cb3-691"><a href="#cb3-691"></a></span>
<span id="cb3-692"><a href="#cb3-692"></a>*Neural Networks*</span>
<span id="cb3-693"><a href="#cb3-693"></a></span>
<span id="cb3-694"><a href="#cb3-694"></a>A machine learning method that uses interconnected nodes to model complex relationships in data.</span>
<span id="cb3-695"><a href="#cb3-695"></a></span>
<span id="cb3-696"><a href="#cb3-696"></a>*Deep Learning*</span>
<span id="cb3-697"><a href="#cb3-697"></a></span>
<span id="cb3-698"><a href="#cb3-698"></a>A subset of machine learning that uses neural networks with multiple layers to model complex relationships in data.</span>
<span id="cb3-699"><a href="#cb3-699"></a></span>
<span id="cb3-700"><a href="#cb3-700"></a></span>
<span id="cb3-701"><a href="#cb3-701"></a><span class="fu">## V. Miscellaneous Methods</span></span>
<span id="cb3-702"><a href="#cb3-702"></a></span>
<span id="cb3-703"><a href="#cb3-703"></a>*Bootstrapping*</span>
<span id="cb3-704"><a href="#cb3-704"></a></span>
<span id="cb3-705"><a href="#cb3-705"></a>A resampling method for estimating the sampling distribution of a statistic.</span>
<span id="cb3-706"><a href="#cb3-706"></a></span>
<span id="cb3-707"><a href="#cb3-707"></a>*Permutation Tests*</span>
<span id="cb3-708"><a href="#cb3-708"></a></span>
<span id="cb3-709"><a href="#cb3-709"></a>A non-parametric method for testing hypotheses by randomly permuting the data.</span>
<span id="cb3-710"><a href="#cb3-710"></a></span>
<span id="cb3-711"><a href="#cb3-711"></a>*Monte Carlo Simulation*</span>
<span id="cb3-712"><a href="#cb3-712"></a></span>
<span id="cb3-713"><a href="#cb3-713"></a>A method for estimating the distribution of a statistic by generating random samples from a known distribution.</span>
<span id="cb3-714"><a href="#cb3-714"></a></span>
<span id="cb3-715"><a href="#cb3-715"></a>*Bayesian Methods*</span>
<span id="cb3-716"><a href="#cb3-716"></a></span>
<span id="cb3-717"><a href="#cb3-717"></a>A statistical approach that uses Bayes' theorem to update prior beliefs based on observed data.</span>
<span id="cb3-718"><a href="#cb3-718"></a></span>
<span id="cb3-719"><a href="#cb3-719"></a>*Dimensionality Reduction*</span>
<span id="cb3-720"><a href="#cb3-720"></a></span>
<span id="cb3-721"><a href="#cb3-721"></a>Also called muitvariate analyses. A set of techniques for reducing the number of variables in a dataset while preserving important information.</span>
<span id="cb3-722"><a href="#cb3-722"></a></span>
<span id="cb3-723"><a href="#cb3-723"></a>*Clustering*</span>
<span id="cb3-724"><a href="#cb3-724"></a></span>
<span id="cb3-725"><a href="#cb3-725"></a>A set of unsupervised learning techniques for grouping similar data points together.</span>
<span id="cb3-726"><a href="#cb3-726"></a></span>
<span id="cb3-727"><a href="#cb3-727"></a>*Feature Selection*</span>
<span id="cb3-728"><a href="#cb3-728"></a></span>
<span id="cb3-729"><a href="#cb3-729"></a>A process for identifying the most important variables in a dataset for predicting an outcome.</span>
<span id="cb3-730"><a href="#cb3-730"></a></span>
<span id="cb3-731"><a href="#cb3-731"></a>*Regularisation*</span>
<span id="cb3-732"><a href="#cb3-732"></a></span>
<span id="cb3-733"><a href="#cb3-733"></a>See penalised regression. A technique for preventing overfitting by adding a penalty term to the model coefficients.</span>
<span id="cb3-734"><a href="#cb3-734"></a></span>
<span id="cb3-735"><a href="#cb3-735"></a>*Cross-Validation*</span>
<span id="cb3-736"><a href="#cb3-736"></a></span>
<span id="cb3-737"><a href="#cb3-737"></a>A method for estimating the performance of a model by splitting the data into training and test sets.</span>
<span id="cb3-738"><a href="#cb3-738"></a></span>
<span id="cb3-739"><a href="#cb3-739"></a>*Hyperparameter Tuning*</span>
<span id="cb3-740"><a href="#cb3-740"></a></span>
<span id="cb3-741"><a href="#cb3-741"></a>The process of selecting the optimal values for the parameters of a machine learning model.</span>
<span id="cb3-742"><a href="#cb3-742"></a></span>
<span id="cb3-743"><a href="#cb3-743"></a>*Model Evaluation*</span>
<span id="cb3-744"><a href="#cb3-744"></a></span>
<span id="cb3-745"><a href="#cb3-745"></a>The process of assessing the performance of a model using metrics such as accuracy, precision, recall, and F1 score.</span>
<span id="cb3-746"><a href="#cb3-746"></a></span>
<span id="cb3-747"><a href="#cb3-747"></a>*Model Interpretation*</span>
<span id="cb3-748"><a href="#cb3-748"></a></span>
<span id="cb3-749"><a href="#cb3-749"></a>The process of understanding how a model makes predictions by examining the relationship between the input variables and the output.</span>
<span id="cb3-750"><a href="#cb3-750"></a></span>
<span id="cb3-751"><a href="#cb3-751"></a>*Model Deployment*</span>
<span id="cb3-752"><a href="#cb3-752"></a></span>
<span id="cb3-753"><a href="#cb3-753"></a>The process of putting a trained model into production so that it can be used to make predictions on new data.</span>
<span id="cb3-754"><a href="#cb3-754"></a></span>
<span id="cb3-755"><a href="#cb3-755"></a>*Model Monitoring*</span>
<span id="cb3-756"><a href="#cb3-756"></a></span>
<span id="cb3-757"><a href="#cb3-757"></a>The process of tracking the performance of a deployed model over time to ensure that it continues to make accurate predictions.</span>
<span id="cb3-758"><a href="#cb3-758"></a></span>
<span id="cb3-759"><a href="#cb3-759"></a>*Model Explainability*</span>
<span id="cb3-760"><a href="#cb3-760"></a></span>
<span id="cb3-761"><a href="#cb3-761"></a>The process of explaining how a model makes predictions in a way that is understandable to humans.</span>
<span id="cb3-762"><a href="#cb3-762"></a></span>
<span id="cb3-763"><a href="#cb3-763"></a>*Model Fairness*</span>
<span id="cb3-764"><a href="#cb3-764"></a></span>
<span id="cb3-765"><a href="#cb3-765"></a>The process of ensuring that a model does not discriminate against certain groups of people based on sensitive attributes.</span>
<span id="cb3-766"><a href="#cb3-766"></a></span>
<span id="cb3-767"><a href="#cb3-767"></a>*Model Robustness*</span>
<span id="cb3-768"><a href="#cb3-768"></a></span>
<span id="cb3-769"><a href="#cb3-769"></a>The process of ensuring that a model performs well on new data that is different from the training data.</span>
<span id="cb3-770"><a href="#cb3-770"></a></span>
<span id="cb3-771"><a href="#cb3-771"></a></span>
<span id="cb3-772"><a href="#cb3-772"></a></span>
<span id="cb3-773"><a href="#cb3-773"></a><span class="co">&lt;!-- The basic high-level decision that would cause a person to decide between any inferential statistical method excluding regressions, and regressions (including all various types) primarily revolves around the research question and the type of relationship or effect they are interested in analysing, namely *describing relationships* vs. *predicting and modelling outcomes*. --&gt;</span></span>
<span id="cb3-774"><a href="#cb3-774"></a></span>
<span id="cb3-775"><a href="#cb3-775"></a><span class="co">&lt;!-- **Inferential Statistical Methods (Excluding Regressions):** --&gt;</span></span>
<span id="cb3-776"><a href="#cb3-776"></a></span>
<span id="cb3-777"><a href="#cb3-777"></a><span class="co">&lt;!-- - **Purpose:** Often used to test hypotheses, compare groups, and determine if there are significant differences or associations between variables. --&gt;</span></span>
<span id="cb3-778"><a href="#cb3-778"></a></span>
<span id="cb3-779"><a href="#cb3-779"></a><span class="co">&lt;!-- - **Example Methods:** *t*-tests, ANOVA, chi-square tests, correlation analysis. --&gt;</span></span>
<span id="cb3-780"><a href="#cb3-780"></a></span>
<span id="cb3-781"><a href="#cb3-781"></a><span class="co">&lt;!-- - **Research Questions:** These methods are used when the primary goal is to determine if there is a significant effect, difference, or association without necessarily predicting outcomes. For example: --&gt;</span></span>
<span id="cb3-782"><a href="#cb3-782"></a></span>
<span id="cb3-783"><a href="#cb3-783"></a><span class="co">&lt;!--     - Is there a significant difference in mean test scores between two groups? --&gt;</span></span>
<span id="cb3-784"><a href="#cb3-784"></a><span class="co">&lt;!--     - Is there an association between two categorical variables? --&gt;</span></span>
<span id="cb3-785"><a href="#cb3-785"></a><span class="co">&lt;!--     - Are two variables correlated? --&gt;</span></span>
<span id="cb3-786"><a href="#cb3-786"></a></span>
<span id="cb3-787"><a href="#cb3-787"></a><span class="co">&lt;!-- **Regressions (All Various Types):** --&gt;</span></span>
<span id="cb3-788"><a href="#cb3-788"></a></span>
<span id="cb3-789"><a href="#cb3-789"></a><span class="co">&lt;!-- - **Purpose:** Used to model relationships between a dependent (response) variable and one or more independent (predictor) variables, often with the goal of predicting the outcome variable or understanding the effect of predictors. --&gt;</span></span>
<span id="cb3-790"><a href="#cb3-790"></a></span>
<span id="cb3-791"><a href="#cb3-791"></a><span class="co">&lt;!-- - **Example Methods:** Linear regression, logistic regression, Poisson regression, mixed-effects models, generalised additive models (GAMs), etc. --&gt;</span></span>
<span id="cb3-792"><a href="#cb3-792"></a></span>
<span id="cb3-793"><a href="#cb3-793"></a><span class="co">&lt;!-- - **Research Questions:** These methods are used when the primary goal is to predict an outcome variable based on one or more predictors or to understand the magnitude and direction of the effect of predictors on an outcome. For example: --&gt;</span></span>
<span id="cb3-794"><a href="#cb3-794"></a></span>
<span id="cb3-795"><a href="#cb3-795"></a><span class="co">&lt;!--     - How does the amount of study time predict test scores? --&gt;</span></span>
<span id="cb3-796"><a href="#cb3-796"></a><span class="co">&lt;!--     - What factors influence the probability of disease presence? --&gt;</span></span>
<span id="cb3-797"><a href="#cb3-797"></a><span class="co">&lt;!--     - How do multiple environmental variables affect species abundance? --&gt;</span></span>
<span id="cb3-798"><a href="#cb3-798"></a></span>
<span id="cb3-799"><a href="#cb3-799"></a><span class="co">&lt;!-- **Decision Point:** --&gt;</span></span>
<span id="cb3-800"><a href="#cb3-800"></a></span>
<span id="cb3-801"><a href="#cb3-801"></a><span class="co">&lt;!-- - **If the goal is to understand and quantify the relationship between variables by constructing models that can be used to predict or assess the impact of predictors on an outcome variable, regression methods are appropriate.** --&gt;</span></span>
<span id="cb3-802"><a href="#cb3-802"></a></span>
<span id="cb3-803"><a href="#cb3-803"></a><span class="co">&lt;!-- - **If the goal is to test for differences between groups, associations between categorical variables, or simple relationships without prediction or complex modelling, other inferential statistical methods are appropriate.** --&gt;</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>