{"title":"Nonlinear Models","markdown":{"yaml":{"knitr":{"opts_chunk":{"dev":["svg","pdf"]}}},"headingText":"Nonlinear Models","headingAttr":{"id":"sec-nonlinear-regression","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n```{r echo = FALSE, cache = FALSE}\nsource(\"utils.R\", local = TRUE)\n```\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| include: true\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(gt)\nlibrary(nlme)\nlibrary(mgcv)\nlibrary(emmeans) # For post-hoc comparisons\nlibrary(ggsci) # For color palettes\nlibrary(latex2exp) # For figure titles with LaTeX expressions\n```\n\n\n**In This Chapter**\n\n- [Nonlinear Regression](@sec-nonlinear-regression)\n\n**Elsewhere in the Book**\n\n- [Simple Linear Regression](@sec-simple-linear-regression)\n- [Polynomial Regression](@sec-polynomial-regression)\n- [Multiple Linear Regression](@sec-multiple-linear-regression)\n- [Generalised Linear Models](@sec-generalised-linear-models)\n- [Generalised Additive Models](@sec-generalised-additive-models)\n\nNonlinear regression models\\index{nonlinear regression} are used when the relationship between the response variable (dependent variable, $Y$) and the predictor variables (independent variables, $X$) is not linear. In other words, they are employed when a straight line is not an appropriate representation of the relationship between the variables.\n\nAs we have seen in @sec-simple-linear-regression, polynomial regressions provide a nonlinear relationship between the response and predictor variables (as seen in the regression line fit to the data, @fig-plts A), but they are considered linear models because the parameters are estimated using linear least squares. Another type of nonlinear model is a semi-parametric model where the relationship between the response and predictor variables is described by a function that includes both parametric and non-parametric components. An example of a semi-parametric model is the generalised additive model (GAM) that includes a non-parametric component in the form of a spline function (@sec-generalised-additive-models; @fig-plts B).\n\nThe type of nonlinear model I cover in this chapter is a parametric model where the relationship between the response and predictor variables is described by a specific nonlinear function (@fig-plts C). The model still assumes that the residuals are normally distributed and exhibit homoscedasticity. The model parameters are estimated by minimising the sum of squared differences between the observed and predicted values, a method commonly referred to as nonlinear least squares (NLS) regression. This is the term I will adopt.\n\nThe primary purpose of nonlinear regression is to derive a formula (model), analyse data, and predict new values where the phenomenon exhibits a nonlinear causal\\index{causal} pattern or behaviour. Nonlinear models include a variety of response forms, such as exponential growth models, logistic growth models, and other mechanistic models derived from physical, chemical, or biological processes. Examples of such models include trigonometric, logarithmic, and user-defined functions like the von Bertalanffy model or seasonal cycle represented by a sine curve (@fig-plts C). These models are explicitly nonlinear in both their form and parameters. Unlike polynomial regression, where only the terms of $X$ are transformed, nonlinear models involve an entirely nonlinear function relating $X$ and $Y$. They are often used when there is a theoretical basis for the specific form of the relationship, providing interpretable parameters that carry specific meanings based on the underlying theory, making them useful for detailed applications where the dynamics of the system are well-understood.\n\nA general formula for a nonlinear regression model is:\n\n$$Y_i = f(X_i; \\theta) + \\epsilon_i$$ {#eq-nonlin}\n\nWhere:\n  \n- $Y_i$ is the response variable for the $i$-th observation,\n- $X_i$ is the predictor variable for the $i$-th observation,\n- $f(X_i; \\theta)$ is a nonlinear function of $X_i$ parameterised by the vector $\\theta$,\n- $\\theta$ is the vector of parameters to be estimated, and\n- $\\epsilon_i$ is the error term for the $i$-th observation and is assumed to be i.i.d. with a normal distribution.\n\nAn example of a specific nonlinear regression model is the exponential growth model:\n  \n  $$Y_i = \\alpha e^{\\beta X_i} + \\epsilon_i$$ {#eq-exp}\n\nWhere:\n  \n- $\\alpha$ and $\\beta$ are the parameters to be estimated,\n- $e$ is the base of the natural logarithm, and\n- $\\epsilon_i$ is the error term for the $i$-th observation.\n\nThis model is nonlinear in the parameters $\\alpha$ and $\\beta$, and it describes an exponential relationship between the predictor $X$ and the response $Y$.\n\n```{r, fig.width=c(9,6),fig.asp=c(0.65,0.65),out.width=list(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Nonlinear regression models fitted to simulated data. A) a cubic polynomial model, B) a GAM with a thin plate regression spline, and C) a NLS sine curve as a seasonal cycle.\"\n#| label: fig-plts\n#| fig.align: center\n#| fig-pos: \"t\"\n\n# Load necessary libraries\n# Set seed for reproducibility\nset.seed(13)\n\n# Generate synthetic data for polynomial fit\nx <- seq(-10, 10, length.out = 30)\ny <- 1 - 2*x + 3*x^2 - 0.5*x^3 + rnorm(30, sd = 40)  # cubic equation with noise\n\ndat_poly <- data.frame(x, y)\n\n# Fit a cubic polynomial model\nmod_poly <- lm(y ~ poly(x, 3, raw = FALSE), data = dat_poly)\n\n# Create a data frame for predictions\nx_grid <- seq(min(x), max(x), length.out = 300)\npred_poly <- data.frame(x = x_grid)\npred_poly$y <- predict(mod_poly, newdata = pred_poly)\n\n# Plot the data and the fitted model\nplt_poly <- ggplot(dat_poly, aes(x, y)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = pred_poly, aes(x, y), color = \"black\") +\n  xlab(\"Predictor, X\") +\n  ylab(\"Response, Y\")\n\n# Simulate data for a seasonal cycle\nx <- seq(0, 365, by = 7)  # Days of the year\namplitude <- 6  # Amplitude (half the difference between longest and shortest day)\noffset <- 12   # Average day length\ny <- amplitude * sin(2 * pi * (x / 365 - 0.25)) + offset + rnorm(length(x), sd = 0.55)  # Sine curve with noise\n\n# Create data frame\ndat_sin <- data.frame(Day = x, DayLength = y)\n\n# Fit nonlinear regression model (using nls)\nmod_sin <- nls(DayLength ~ A * sin(2 * pi * (Day / 365 - phi)) + C, data = dat_sin, \n             start = list(A = 6, phi = 0.25, C = 12))\n\n# Get predicted values\ndat_sin$Predicted <- predict(mod_sin)\n\n# Visualise results\nplt_sin <- ggplot(dat_sin, aes(x = Day)) +\n  geom_point(aes(y = DayLength), size = 2, shape = 1, color = \"royalblue2\") +\n  geom_line(aes(y = Predicted), color = \"black\") +\n  labs(x = \"Day of the Year\", y = \"Response, Y\")\n\n# Parameters for the Michaelis-Menten model\nV_max <- 100  # maximum rate of the enzyme reaction\nK_m <- 25     # Michaelis constant\n\n# Generate substrate concentrations\nS <- seq(0, 100, length.out = 30)\n\n# Generate reaction rates using the Michaelis-Menten equation with added noise\nV <- (V_max * S) / (K_m + S) + rnorm(30, mean = 0, sd = 5)\n\n# Create a data frame\ndat_mm <- data.frame(S, V)\n\n# Fit the Michaelis-Menten model\nmod_mm <- nls(V ~ (V_max * S) / (K_m + S), data = dat_mm, start = list(V_max = 90, K_m = 40))\n\n# Create a grid for predictions\nS_grid <- seq(min(S), max(S), length.out = 300)\npred_mm <- data.frame(S = S_grid)\npred_mm$V <- predict(mod_mm, newdata = pred_mm)\n\n# Plot the data and the fitted model\nplt_mic <- ggplot(dat_mm, aes(S, V)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = pred_mm, aes(S, V), color = \"black\") +\n  xlab(\"Substrate Concentration [S]\") +\n  ylab(\"Uptake Rate V\")\n\n# Generate synthetic data\nx <- seq(-3, 3, length.out = 30)\ny <- x^2 * sin(x) + rnorm(30, sd = 0.5)  # Complex nonlinear relationship\n\ndat_gam <- data.frame(x, y)\n\n# Fit a Generalized Additive Model using thin plate regression spline\nmod_gam <- gam(y ~ s(x, bs = \"tp\"), data = dat_gam)  # 'tp' specifies thin plate spline\n\n# Create a grid for predictions\nx_grid <- seq(min(x), max(x), length.out = 300)\npred_gam <- data.frame(x = x_grid)\npred_gam$y <- predict(mod_gam, newdata = pred_gam)\n\n# Plot the data and the fitted GAM\nplt_gam <- ggplot(dat_gam, aes(x, y)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = pred_gam, aes(x, y), color = \"black\") +\n  xlab(\"Predictor, X\") +\n  ylab(\"Response, Y\")\n\nggarrange(plt_poly, plt_gam, plt_sin, ncol = 2, nrow = 2,\n          labels = \"AUTO\")\n```\n\n\n## Extension of Nonlinear Models\n\nLike linear models, nonlinear models have also been extended to include multiple predictors, interactions, and other terms to capture complex relationships between the variables. The first type of more complex nonlinear models accommodates a wider range of data distributions by generalising to non-normal error distributions through link functions. These models are called generalised nonlinear models (GNLMs). The examples of GLMs in @sec-generalised-linear-model should prepare you sufficiently to handle nonlinear models too. The other type deals with hierarchical data structures and incorporates fixed and random effects. As such, you can also correctly model repeated measures and longitudinal, and nested (grouped) designs. These hierarchical models are called nonlinear mixed models (NLMMs). Examples of NLMMs are provided in @sec-mf-treatments and @sec-perturbation.\n\n\n## Considerations for Model Selection\n\n```{r, fig.width=c(6,5),fig.asp=0.5,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of growth rate data fitted with a von Bertalanffy model, a first- (straight line), second- and third-order polynomial, and a GAM.\"\n#| label: fig-combo\n#| fig.align: center\n#| fig-pos: \"t\"\n\nset.seed(13)\n\n# Parameters for the von Bertalanffy model\nL_inf <- 100  # theoretical maximum length\nk <- 0.2      # growth rate\nt0 <- -1      # hypothetical age at length zero\n\n# Generate time points\nt <- 0:20\n\n# Generate lengths using the von Bertalanffy equation with some added noise\nL_t <- L_inf * (1 - exp(-k * (t - t0))) + rnorm(21, mean = 0, sd = 5)\n\n# Create a data frame\ndat_vb <- data.frame(t, L_t)\n\n# Fit the von Bertalanffy model\nmod_vb <- nls(L_t ~ L_inf * (1 - exp(-k * (t - t0))), data = dat_vb, start = list(L_inf = 80, k = 0.1, t0 = 0))\n\n# Fit polynomial model2\nmod_poly1 <- lm(L_t ~ poly(t, 1, raw = FALSE), data = dat_vb)\nmod_poly2 <- lm(L_t ~ poly(t, 2, raw = FALSE), data = dat_vb)\nmod_poly3 <- lm(L_t ~ poly(t, 3, raw = FALSE), data = dat_vb)\n\n# Fit the GAM\nmod_gam <- gam(L_t ~ s(t), data = dat_vb)\n\n# Create a grid for predictions\nt_grid <- seq(min(t), max(t), length.out = 21)\npred_vb <- data.frame(t = t_grid)\nL_t_pred <- predict(mod_vb, newdata = pred_vb)\ny1_pred <- predict(mod_poly1, newdata = pred_vb)\ny2_pred <- predict(mod_poly2, newdata = pred_vb)\ny3_pred <- predict(mod_poly3, newdata = pred_vb)\ny_gam_pred <- predict(mod_gam, newdata = pred_vb)\ndat_vb <- cbind(dat_vb, L_t_pred, y1_pred, y2_pred, y3_pred, y_gam_pred)\n\n# Combine the original data and predictions for consistent aes mapping\nplot_data <- data.frame(\n  t = rep(t_grid, 5),\n  Length = c(dat_vb$L_t_pred, dat_vb$y1_pred, dat_vb$y2_pred, dat_vb$y3_pred, dat_vb$y_gam_pred),\n  Model = rep(c(\"von Bertalanffy\", \"poly1\", \"poly2\", \"poly3\", \"GAM\"), each = length(t_grid))\n)\n\n# Plot the data and the fitted model\nggplot(dat_vb, aes(t, L_t)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = plot_data, aes(t, Length, colour = Model), alpha = 0.6) +\n  scale_color_manual(name = \"Model\",\n                     values = c(\"von Bertalanffy\" = \"black\", \"poly1\" = \"coral3\", \"poly2\" = \"deepskyblue3\", \"poly3\" = \"deeppink3\", \"GAM\" = \"seagreen3\")) +\n  xlab(\"Time (years)\") +\n  ylab(\"Length (cm)\") +\n  theme(legend.position = \"right\")\n```\n\nThere are a few practical considerations to keep in mind when choosing a suitable nonlinear (in shape) model. Sometimes different models can provide similar fits to the same data, but they may have different implications for the interpretation of the relationship between the variables. See for example @fig-combo. The plot shows growth rate data fitted with a first-, second- and third-order polynomial, a GAM, and a NLS von Bertalanffy model. To the untrained eye and inexperienced biologist, all models seem to provide a good fit to the data, but they do differ subtly in the shape of the fitted curve. The von Bertalanffy model is a saturating growth model (it reaches a plateau), while the polynomial models and the GAM are more flexible and can capture a wider range of shapes. The choice of model should be guided by the underlying biological or physical processes that generated the data and the research question you are trying to answer.\n\nSince you will often have to decide among polynomial regressions, nonlinear models, and GAMs, I'll outline some general guidelines to help you make an informed decision.\n\n-   **Linearity vs. Nonlinearity:** If the relationship between the variables is linear or can be adequately approximated by a polynomial function, polynomial regression is a suitable choice. Nonlinear models or GAMs may be more appropriate if the relationship is nonlinear and does not follow a specific polynomial form. In @fig-combo, it is obvious that the straight line model is not a good fit for the data, but the second- and third-order polynomial models, the GAM, and the von Bertalanffy model all provide better fits.\n\n-   **Complexity of the Relationship:** Polynomial regression is limited in its ability to capture complex nonlinear relationships, especially those with more bends, peaks, or valleys than a polynomial of order <3 (or even 4 at a push) can capture. Another consideration is the process the data represent: if it is inherently nonlinear according to a known function such as exponential growth or decay, seasonal sinusoidal patterns, or logistic growth, then nonlinear models or GAMs are more flexible and can capture a wider range of nonlinear responses. In @fig-combo, the von Bertalanffy model is a saturating growth model, which is a known biological process that can be captured by a nonlinear model. The 3rd-order polynomial model also seems to capture a saturating growth pattern, but it also somewhat influenced by the dip in the raw data around 12.5 years (in addition to some other nuances), but this is likely due to some random variation and is not part of the growth response.\n\n-   **Interpretability vs. Flexibility:** Polynomial regression provides coefficients that relate to the powers of the predictor variables, but the interpretation of the $\\beta$ parameters is not as intuitive as in a linear model of order 1. In contrast, nonlinear models and GAMs offer greater flexibility in capturing complex patterns. GAMs may lack direct interpretability of the coefficients, but the nonlinear model offers coefficients that can be interpreted in the context of the model's structure. In @fig-combo, the von Bertalanffy model has a clear biological interpretation (see @sec-vonbertalanffy), while the 3rd-order polynomial model and the GAM are more flexible and can capture a wider range of shapes (it follows the dips and peaks in the raw data closer). The 2nd-order polynomial does not fit the data as well at very low ages at 20 year, but it is still a better fit than the linear model.\n\n-   **Overfitting Concerns:** Polynomial regression with high-degree polynomials can lead to overfitting, especially when the model complexity exceeds the underlying data patterns. Nonlinear models and GAMs can also overfit if not properly regularised or constrained. These insights can be seen when we examine the summaries of the regression fits, and can be formally assessed using cross-validation or information criteria. In @fig-combo, the 3rd-order polynomial model seems to capture some of the random variation in the data, which may be an indication of overfitting. The GAM also seems to capture some of the random variation, but it is less pronounced than in the 3rd-order polynomial model.\n\n-   **Data Size and Complexity:** For small to moderate-sized datasets with complex nonlinear relationships, GAMs may be more suitable due to their flexibility and ability to capture intricate patterns. For simpler relationships or when interpretability is important, nonlinear regression (with mechanistically-informed parameters) may be preferred. These are not of concern in @fig-combo.\n\n-   **Model Complexity and Assumptions:** Polynomial regression assumes a specific polynomial form for the relationship, which may not hold in practice. Nonlinear models and GAMs are more flexible and do not always impose strict parametric assumptions (see @sec-assumptions), making them more robust to deviations from the assumed form. A detailed assessment of the model assumptions and the complexity of the relationship can help guide the choice of model. We need to add to this our biologist specialist knowledge to make the best choice.\n\n-   **Computational Considerations:** Polynomial regression is relatively simple to implement and computationally efficient, especially for low-degree polynomials. Nonlinear models and GAMs may require more computational resources, especially for large datasets or complex models. Not a concern for the models represented in @fig-combo.\n\n## Requirements and Assumptions {#sec-assumptions}\n\nPolynomial regression, nonlinear regression, and GAMs are built upon the principles of linear regression; therefore, the fundamental assumptions of normality and homoscedasticity of residuals usually still apply. Specifically, these models assume that the residuals are independent and identically distributed (i.i.d.), which implies that they are normally distributed with a constant variance (homoscedasticity). However, the specifics can vary depending on the model and the distribution of the response variable. Of course, there is also the requirement for the response variable to be continuous and independent. These assumptions help ensure that the error terms (residuals) in the model are well-behaved so that reliable inference and predictions can be obtained.\n\nNuances:\n\n-   **Polynomial Regression:** While a type of nonlinear regression,\n    polynomial models are still linear in their parameters. This means\n    that they are more bound to the classic regression assumptions and\n    can be more sensitive to violations.\n-   **GAMs:** Offer more flexibility in handling nonlinear\n    relationships. Depending on the distributions used for the outcome\n    variable and the link functions employed, GAMs can potentially relax\n    some of the strict normality assumptions.\n-   **Nonlinear Models in General:** Some truly nonlinear models (like\n    those based on exponential or logarithmic functions) may have\n    inherently different error structures and may not strictly require\n    the same assumptions of normality and homoscedasticity. However,\n    these models come with their own set of assumptions and\n    considerations.\n\nImportant considerations:\n\n-   **Diagnostic Checks:** Regardless of the model type, it's\n    *essential* to perform residual diagnostics to assess if assumptions\n    are met. Visualisations (e.g., histograms, Q-Q plots, residuals vs.\n    fitted plots) are well-known tools.\n-   **Transformations:** If violations of assumptions\n    are found, data transformation techniques (e.g., Box-Cox, log)\n    could be considered to improve model validity.\n-   **Generalised Linear Models (GLMs):** An important class of models\n    designed to handle various non-normal responses (e.g., count,\n    binary) while extending the linear modeling framework. GLMs are good alternative to both polynomial regression and GAMs in\n    certain contexts.\n-   **Mixed models:** Linear Mixed Models (LLMs), Generalised Linear Mixed Models (GLMMs), and Generalised Nonlinear Models (GNLMs) can be used to account for dependencies in the data, such as repeated measures or hierarchical\n    structures. GAMs also accommodate mixed data structures.\n\nThe rest of this chapter will focus on the practical aspects of fitting\npolynomial regression models and nonlinear regressions in R. GAMs will\nbe covered in a separate chapter due to their unique characteristics and\nimplementation details.\n\n## R Functions and Packages\n\n### Polynomial Regression\n\nTo fit a polynomial model in R, use the simple linear regression function `lm()` to fit the model. The purpose of `poly()` is to generate polynomial terms of a specified degree. The basic form is:\n\n```{r}\n#| eval: FALSE\n#| echo: TRUE\n\npoly_model <- lm(y ~ poly(x, degree = 2), data = data)\n```\n\nGLMs are a generalisation of ordinary linear regression that allows for the response variable to have\nnon-Gaussian error distributions such as one of the exponential family\ndistributions (e.g., binomial, Poisson, gamma). These distributions are\naccommodated via so-called link functions within the GLM framework. The\nmost common R function for fitting GLMs is `glm()`.\n\nMixed models that include random and fixed effects (see box 'Fixed and\nRandom Effects') are also available. These are necessary for the\nanalysis of data that have correlations within groups or hierarchies\n(e.g., repeated measures[^2] or the inclusion of grouped variables).\nCommonly used are `lmer()` for LLMs and `glmer()` for GLMMs. Both functions are in the\n**lme4** package. Another package that accommodates LLMs is **nlme** and\nits `lme()` function. It has somewhat different capabilities and syntax\ncompared to **lme4**.\n\n[^2]: Repeated measures are multiple observations taken on the same\n    subject or unit over time or under different conditions. Sometimes\n    this is called longitudinal data.\n\n::: callout-note\n## Fixed and Random Effects\n\nRandom effects and fixed effects are used in regression models to\naccount for different sources of variation in the data.\n\n*Fixed effects* are variables or factors that represent\nsources of variation that are of primary interest in the study or that\nhave a finite and fixed number of levels or categories. These effects\nare assumed to have an influence on the mean response.\nExamples of fixed effects include:\n\n-   Treatment groups in an experiment (e.g., fertiliser A, fertiliser B, control)\n-   Categorical variables (e.g., sex, age group, species)\n-   Continuous variables (e.g., time, temperature, concentration)\n\nThe coefficients associated with fixed effects are estimated and\ninterpreted as the primary effects of interest in the model.\n\n*Random effects* are variables or factors that represent\nsources of variation that are not of primary interest but need to be\naccounted for in the model. These effects are assumed to be randomly\nsampled from a larger population, and their levels are theoretically\ninfinite or too numerous to be modeled as fixed effects. Examples of\nrandom effects include:\n\n-   Subjects or individuals in a study (e.g., individual plants or animals)\n-   Clusters or groups (e.g., plots, aquaria, transects)\n-   Repeated measures or time points within subjects\n\nRandom effects are used to model the correlation or dependence among\nobservations within the same cluster, subject, or time series. They allow for\nsubject-specific or cluster-specific adjustments to the overall model,\naccounting for the fact that observations within the same group are more\nsimilar than observations from different groups.\n\nIn LMMs and GLMMs, both fixed and random effects are included. The fixed\neffects represent the primary effects of interest and the random\neffects account for the correlation or dependence within clusters or\nsubjects.\n:::\n\n### Nonlinear Regression\n\nIn R, nonlinear regressions can be performed using the `nls()` function\nin the **base** package. It uses iterative algorithms to minimise the\nresidual sum of squares and find the best-fit parameters for the\nuser-specified nonlinear model.\n\nThe `nls()` function is most frequently used to fit user-specified\nnonlinear functions. The basic syntax is:\n\n```{r}\n#| eval: FALSE\n#| echo: TRUE\n\nnls_model <- nls(y ~ f(x, theta1, theta2, ...), data = data,\n                 start = list(theta1 = value1, theta2 = value2, ...))\n```\n\nGNLMs extend nonlinear models by\nallowing the response variable to follow one of the exponential family\ndistributions, such as binomial, Poisson, or gamma, etc. This is done\nthrough a link function that relates the mean of the distribution to the\npredictors through the nonlinear model. GNLMs are fit using maximum\nlikelihood estimation, which is flexible enough to handle various types\nof error distribution and link functions. The **gnm** package rovides\nthe `gnm()` function designed for this purpose.\n\nFor data with dependencies within groups or hierarchies (such as in\nlongitudinal studies), NLMMs are available\nwithin `nlme()`. NLMMs incorporate fixed effects (associated with the\nnonlinear terms) and random effects (to account for correlation and\nvariation within groups).\n\n## Example: Algal Nutrient Uptake Kinetcis {#sec-ex1}\n\nWe can measure algal nutrient uptake rates using two types of experiments: multiple flask experiments and perturbation experiments. The fundamental concept underlying both methods is to introduce a known quantity of nutrients (termed the substrate) into a flask or a series of flasks and then measure the rate of nutrient uptake ($V$) at different substrate concentrations ($[S]$). We calculate the nutrient uptake rate as the change in nutrient concentration in the flask over a predefined time interval ($V = \\Delta [S]/\\Delta t$). Consequently, both experiments generate data that relate the nutrient uptake rate to the corresponding substrate concentration. The primary difference between the two methods lies in the experimental setup and the data analysis.\n\nIn the **multiple flask method**, we prepare a series of flasks, each containing a different initial concentration of the substrate nutrient to span the range typically encountered by the specimen in its natural environment. We then measure the nutrient uptake rate in *each individual flask* over a specific time period, for example by taking measurements at the start ($t=0$) and end ($t=30$ minutes) of the incubation. We calculate the change in substrate concentration over this time interval in each flask to determine the corresponding nutrient uptake rate. The resulting data from this method therefore consists of the different initial substrate concentrations used in each flask, paired with their respective measured nutrient uptake rates over the incubation period.\n\n<!-- ChatGPT query to simulate data for the experiment -->\n\n<!-- Please refer to the above text about the multiple flask experiment. Develop R code that will simulate data for seven replicate flasks participating in a multiple flask experiment. These are the conditions per each set of multiple flasks: -->\n\n<!--   - the concentrations of nutrient at $t=0$ are 50, 40, 30, 25, 20, 15, 12.5, 10, 7.5, 5, 2.5, and 0 $\\mu M$ nitrate -->\n<!--   - the disappearance of nitrate is measured at $t=0$ and $t=30$ minutes -->\n<!--   - there is ~1.5 g of seaweed per 150 ml incubation medium per flask -->\n<!--   - there are 7 replicate flasks per each concentration of nutrients -->\n\n<!-- Produce R code to simulate random data from the Michaelis-Menten relationship with a $V_{max} = 35.0 \\pm 1.8 \\, \\mu \\text{M} \\, N \\, g^{-1} \\, hr^{-1}$ and a $K_m = 5.6 \\pm 1.3 \\mu \\text{M} N$. The data should be normally distributed. Present this data in a table of $[S]$, which is the nutrient concentration at $t=0$ and the corresponding $V$. -->\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n\n# Define the model function\nmm_fun <- function(S, Vmax, Km) {\n  Vmax * S / (Km + S)\n}\n\ngenerate_data <- function(n_trt, n_rep, conc_vec, Km_vec,\n                          Vmax_vec, Km_vec_sd, Vmax_vec_sd) {\n  # Define the substrate concentrations\n  concentrations <- conc_vec\n  \n  # Create a dataframe with the specified structure\n  data <- expand.grid(\n    trt = paste(\"Treatment\", 1:n_trt),\n    S = concentrations,\n    rep = 1:n_rep\n  ) |> \n    arrange(trt, S, rep)\n  \n  # Add Km and Vmax values\n  set.seed(13)\n  data <- data |> \n    group_by(trt)  |> \n    mutate(\n      Km = rnorm(n(), mean = Km_vec[as.numeric(str_extract(trt, \"\\\\d+\"))], \n                 sd = Km_vec_sd[as.numeric(str_extract(trt, \"\\\\d+\"))]),\n      Vmax = rnorm(n(), mean = Vmax_vec[as.numeric(str_extract(trt, \"\\\\d+\"))], \n                   sd = Vmax_vec_sd[as.numeric(str_extract(trt, \"\\\\d+\"))])\n    ) |> \n    ungroup() |> \n    mutate(V = mm_fun(S, Vmax, Km),\n           rep = as.factor(rep),\n           trt = as.factor(trt)) |> \n    select(-Km, -Vmax)\n  \n  return(data)\n}\n\n# Example usage\nconc_vec <- c(0, 0.1, 0.5, 2, 5, 7.5, 10, 12.5, 15, 17.5, 20, 25, 30)\nn_trt <- 3  # Number of treatment levels\nn_rep <- 5  # Number of replicates per treatment\nKm_vec <- c(10, 8, 7)  # Km means for each treatment\nVmax_vec <- c(50, 40, 20)  # Vmax means for each treatment\nKm_vec_sd <- c(1.2, 1.3, 1.2)  # Km SD for each treatment\nVmax_vec_sd <- c(0.7, 1.3, 0.9)  # Vmax SD for each treatment\n\n# Generate the data for one treatment\nmf_data <- generate_data(n_trt = 1, n_rep, conc_vec, Km_vec,\n                         Vmax_vec, Km_vec_sd, Vmax_vec_sd)\n```\n\nThe **perturbation method** uses a single flask to which we add a high initial concentration of the substrate nutrient, set at a level that is ecologically meaningful and relevant to the study system. Instead of using multiple flasks, we measure the change in the remaining substrate concentration at multiple time points within this *same flask*, for example by taking samples every 10 or 20 minutes until all the substrate is depleted, say at 120 minutes. We calculate the change in substrate concentration between each successive time point to determine the corresponding nutrient uptake rate over that time interval. The resulting data, therefore, consist of a time series of substrate concentrations at each measurement time point, paired with the nutrient uptake rates calculated over the periods between those time points.\n\nThe important differences between the multiple flask and perturbation experiments are summarised in @tbl-diffs.\n\n| Feature            | Multiple Flask Experiments                 | Perturbation Experiments                       |\n|--------------------|--------------------------------------------|------------------------------------------------|\n| Experimental Setup | Multiple flasks, each with different $[S]$ | Single flask with initial high $[S]$           |\n| Data Independence  | Data points are independent                | Data points are correlated (repeated measures) |\n| Analysis           | Nonlinear least squares regression (NLS)  | Nonlinear mixed model (NLMM)                  |\n| R Function         | `nls()`                                    | `nlme::nlme()`                                 |\n\n: Key differences between multiple flask and perturbation experiments. {#tbl-diffs}\n\nOur choice between multiple flask and perturbation experiments depends on our research questions and experimental constraints. In both methods, we must consider all sources of error and variability, such as measurement error, the type of nutrient, the physiological state of the alga, the light intensity, the experimental temperature, and other variables that might affect the uptake response.\n\nWe apply the Michaelis-Menten model (@eq-mm) to data from multiple flask and perturbation experiments to characterise nutrient uptake. Applied to algae, this model assumes an irreversible uptake process that saturates at high substrate concentrations. It effectively quantifies key characteristics of the nutrient uptake system, including the maximum uptake rate and the algae's affinity for the nutrient.\n\nWe use the `nls()` function to fit the Michaelis-Menten model to the data from multiple flask experiments. For the perturbation experiment, things are a bit more complicated. This method includes dependent data points because the measurements are taken from the same flask at different times, introducing a correlation between observations. This violates the independence assumption required for standard regression models. To accurately analyse these data, I recommend a *nonlinear mixed-effects model* implemented in the `nlme()` function. Mixed-effects models account for fixed effects (overall trends across all observations) and random effects (variations specific to individual experimental units, in this case, time points within the same flask). This helps handle the correlation between repeated measures and produces reliable estimates of the uptake dynamics within the flask. \n\nThe Michaelis-Menten equation is given by:\n\n$$V_i = \\frac{V_{max} \\cdot [S_i]}{K_m + [S_i]} + \\epsilon_i$$ {#eq-mm}\n\nWhere:\n\n-   $V_i$ is the uptake rate at the $i$-th observation,\n-   $V_{max}$ is the maximum nutrient uptake rate achieved,\n-   $[S_i]$ is the substrate concentration at the $i$-th observation,\n-   $K_m$ is the Michaelis constant, which represents the substrate concentration at which the uptake rate is half of $V_{max}$, and\n-   $\\epsilon_i$ is the error term at the $i$-th observation. and\n\nThe two parameters of the Michaelis-Menten model are rooted in theory and have ecophysiological interpretations. $K_m$ is a measure of the alga's affinity for the nutrient and is determined by the kinetic constants governing the formation and dissociation of the enzyme-substrate complex responsible for taking up the nutrient; lower values indicate a higher affinity. $V_{max}$ represents the maximum capacity of the alga to utilise the nutrient.\n\n### Hypothesis Testing and the Michaelis-Menten Model\n\n#### Linear vs. Michaelis-Menten Model {#sec-linear-vs-mm}\n\nOften, we aim to understand the relationship between two variables but we may not yet know which model best describes this relationship. For instance, in algal nutrient uptake kinetics, both a linear model and a nonlinear Michaelis-Menten model can be used to describe the relationship between nutrient uptake rate and substrate concentration. Both models are valid but they have different interpretations and unique ecophysiological implications. The choice between the two models depends on the biological system.\n\n- **Linear models** indicate that the uptake process is inherently unsaturated, such as with the uptake of ammonium. In this case, the uptake rate continues to increase linearly with substrate concentration.\n- The **Michaelis-Menten model** suggests that the uptake rate eventually saturates as the substrate concentration increases, which is often the case with nitrate.\n\nThe key question is: How do we decide which model fits our data best?\n\nThe simplest way is to visually inspect the scatter of points on a plot of the $V$ vs. $[S]$ data, which would be part of any exploratory data analysis. If the data exhibit a clear saturation pattern, where the uptake rate levels off at high substrate concentrations, the Michaelis-Menten model is likely to provide a better fit. Conversely, if the data show a linear relationship over the observed range of substrate concentrations, the linear model may be more appropriate.\n\nIt is also important to consider the biological plausibility of the models. If there is prior knowledge or theoretical reasons to expect a saturating relationship between the uptake rate and substrate concentration, the Michaelis-Menten model may be more appropriate, even if both models provide a similar fit to the data.\n\nConfirmation can be obtained by fitting both models to our data and comparing their performance using statistical measures such as the sum of squared residuals (SSR), Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), or log-likelihood test.\n\nTo proceed with the statistical approach, we must first set hypotheses such as these to compare the models:\n\n**$H_0$:** The Michaelis-Menten model does not provide a better fit to the data than a simple linear model.\n\nIn other words, we suggest with the null hypothesis that the relationship between nutrient uptake rate and the substrate concentration is adequately described by a linear model rather than the Michaelis-Menten nonlinear model. The implication is that the uptake rate increases linearly with substrate concentration, without saturation.\n\n**$H_a$:** The Michaelis-Menten model provides a significantly better fit to the data than a simple linear model.\n\nWith the alternative hypothesis we propose that the relationship between the nutrient uptake rate and the substrate concentration is best described by the nonlinear Michaelis-Menten model, so the uptake rate initially increases with substrate concentration but eventually levels off, indicating saturation.\n\nTo test these hypotheses, we can:\n\n1. Fit both the Michaelis-Menten model and a linear model to the data.\n2. Compare the goodness-of-fit of both models using statistical measures such as the SSR, AIC, or BIC.\n3. Perform a model comparison test (such as an *F*-test or likelihood ratio test) to determine if the improvement in fit provided by the Michaelis-Menten model is statistically significant compared to the linear model.\n\nIn the above scenario, which is to decide among the linear and Michaelis-Menten models, hypotheses concerning the parameters of the models are not directly tested as they are not really of interest (except for estimating their magnitude, perhaps). Instead, the focus is on the overall goodness-of-fit of the models to the data.\n\n#### Comparing Two Michaelis-Menten Models {#sec-mm-comparison}\n\nHere, we may be interested in testing whether the parameters $V_\\text{max}$ and $K_m$ differ from some hypothesised values or across different experimental conditions.\n\nIn the first instance, we can set up the hypotheses as follows:\n\n**$H_0:$** $V_\\text{max} = V_\\text{max}^*$ and $K_m = K_m^*$\n\nwhere $V_\\text{max}^*$ and $K_m^*$ are the hypothesised values (or values from a reference condition) for the maximum uptake rate and Michaelis constant, respectively.\n\n**$H_a:$** $V_\\text{max} \\neq V_\\text{max}^*$ or $K_m \\neq K_m^*$\n\nThis alternative hypothesis states that at least one of the parameters ($V_\\text{max}$ or $K_m$) differs from the hypothesised value.\n\nIf the experiment involves different experimental conditions or treatments, we can modify the hypotheses accordingly. For example, if we want to test whether the parameters differ between two experimental conditions (A and B), the hypotheses could be:\n\n$H_0: V_\\text{max}^A = V_\\text{max}^B$ and $K_m^A = K_m^B$\n\n$H_a: V_\\text{max}^A \\neq V_\\text{max}^B$ or $K_m^A \\neq K_m^B$\n\nIn this case, the null hypothesis states that the maximum uptake rate and Michaelis constant are the same for both experimental conditions, while the alternative hypothesis states that at least one of the parameters differs between the two conditions.\n\nAfter fitting the Michaelis-Menten model to the data using the `nls()` or `nlme()` functions in R, appropriate statistical tests (e.g., likelihood ratio tests, Wald tests, or other model comparison techniques) can be performed to evaluate the hypotheses and determine whether the parameter estimates significantly differ from the hypothesised values or across experimental conditions.\n\n### Multiple Flask Experiment\n\n#### Fitting a single model (NLS) {#sec-mf-single}\n\nTo demonstrate fitting a nonlinear model to $V$ vs $[S]$ data produced from a multiple flask experiment, I simulate data across a range of substrate concentrations. We then fit the model to the data using the `nls()` function in R. The dataset consists of five replicate flask sets ($n=5$) for each of 13 substrate concentrations. Each set therefore results in independently estimated uptake rates for the initial nutrient concentrations. The dataset is shown in @tbl-mf1, and a plot of $V$ as a function of $[S]$ is shown in @fig-mf1. \n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"Simulated data for a multiple flask experiment on an alga (showing only the top and bottom three rows).\"\n#| label: tbl-mf1\n\nmf_data |> \n  select(rep, S, V) |>\n  mutate(V = round(V, 2)) |>\n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n  cols_align(\n    align = \"center\",\n    columns = \"rep\") |> \n  cols_label(rep = html(\"Replicate flask\"),\n             S = html(\"[S]\"),\n             V = html(\"V\"))\n```\n\n<!-- ```{r} -->\n<!-- #| echo: true -->\n\n<!-- # html only -->\n<!-- DT::datatable(mf_data, rownames = FALSE, options = list(pageLength = 5)) -->\n<!-- ``` -->\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of $V$ as a function of $[S]$ for a multiple flask experiment involving seven replicate flask sets.\"\n#| label: fig-mf1\n#| fig.align: center\n#| fig-pos: \"t\"\n\nggplot(mf_data, aes(x = S, y = V, group = rep)) +\n  geom_jitter(size = 2, shape = 1, colour = \"royalblue2\", width = 0.08) +\n  labs(x = TeX(\"S [$\\\\mu$M]\"),\n       y = TeX(\"V [$\\\\mu$M $g^{-1}_{dry}$ $h^{-1}$]\")) +\n  theme(legend.position = \"none\")\n```\n\nIn @fig-mf1, there is a clear indication that the uptake rates plateau at higher substrate concentrations, suggesting that fitting a Michaelis-Menten model is advisable. Later, I will compare this with a linear model for completeness. A central feature of this dataset is that the data were collected independently, with each flask set representing a separate experimental unit. There is no correlation between flasks within a set, and no correlation across the initial substrate concentrations. Consequently, the assumption of independence is fully met, allowing the simplest expression of the `nls()` function to be used to fit the Michaelis-Menten model to the data.\n\nThe Michaelis-Menten model is fit to the data using the `nls()` function in R. It is specified as:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Define the model function\nmm_fun <- function(S, Vmax, Km) {\n  Vmax * S / (Km + S)\n}\n\n# Fit the nonlinear model Michaelis-Menten model\nnls_mod <- nls(V ~ mm_fun(S, Vmax, Km), # <1>\n            data = mf_data,\n            start = c(Vmax = 30, Km = 5)) # <2>\n```\n1. The model formula specifies the Michaelis-Menten equation, with `V` as the dependent variable on the left-hand side and `S` as the independent variable on the right. The model parameters `Vmax` and `Km` will be estimated when fitting the model.\n2. The `start` argument provides initial values for the model parameters. The `Vmax` and `Km` parameters are estimated by minimising the sum of squared residuals between the observed and predicted values of `V`. The `nls()` function uses an iterative process to find the best-fitting values for these parameters, and the starting values improve the success of model convergence.\n\nHere is the model summary:\n\n```{r}\nsummary(nls_mod)\n```\n\nThe above output provides the estimates for $V_{\\max}$ and $K_m$, along with their standard errors, *t*-values, and *p*-values:\n\n-   The estimated maximum uptake rate ($V_{\\max}$) is approximately 49.24 $\\mu M N g^{-1} hr^{-1}$ and the small standard error associated with this parameter (0.89) indicates a precise estimate. The *t*-value (55.18) is very high, and the corresponding *p*-value is extremely small (<0.0001), indicating that $V_{\\max}$ is highly significantly different from zero.\n-   The estimated Michaelis constant ($K_m$) is approximately 9.50 $\\mu M$ and its standard error (0.45) is also small, suggesting a precise estimate. The *t*-value (21.22) and the very small *p*-value (<0.0001) indicate that $K_m$ is also highly significantly different from zero.\n-   The residual standard error is 1.10 on 63 degrees of freedom, indicating the average deviation of the observed uptake rates from the fitted model values.\n-   The model converged in 4 iterations with a very small convergence tolerance, indicating a good fit and stability of the model.\n\n::: {.callout-tip}\n## Results\n\nThe Michaelis-Menten parameters, maximum uptake rate ($V_{\\max}$) and half-saturation constant ($K_m$), were estimated using nonlinear regression (@fig-mf2). The estimated $V_{\\max}$ was 49.24 $\\mu$M N g$^{-1}$ hr$^{-1}$ (SE = 0.89, $t = 55.18$, $p < 0.0001$), and the estimated $K_m$ was 9.50 $\\mu$M (SE = 0.45, $t = 21.22$, $p < 0.0001$). Both parameters were significantly different from zero. The model fit was good, converging in 3 iterations with a residual standard error of 1.10 (63 degrees of freedom).\n:::\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of the Michaelis-Menten model fitted to the data in @fig-mf1. The vertical and horizontal dashed lines indicate the estimated $K_m$ and $V_{max}$ values, respectively.\"\n#| label: fig-mf2\n#| fig-align: center\n\n# Extract coefficients\ncoefficients <- coef(nls_mod)\nVmax_est <- coefficients[\"Vmax\"]\nKm_est <- coefficients[\"Km\"]\n\n# Creating a sequence for smooth curve\nconc_seq <- seq(min(mf_data$S), max(mf_data$S), length.out = 100)\npredicted_V <- (Vmax_est * conc_seq) / (Km_est + conc_seq)\n\n# Plot\nggplot(mf_data, aes(x = S, y = V)) +\n  geom_jitter(aes(colour = \"Data Points\", width = 0.08),\n    shape = 1, size = 2, colour = \"royalblue2\") +\n  geom_line(aes(x = conc_seq, y = predicted_V),\n            data = data.frame(S = conc_seq, V = predicted_V),\n            color = \"black\", size = 0.8) +\n  geom_vline(xintercept = Km_est, linetype = \"dashed\",\n             color = \"hotpink1\", size = 0.4, show.legend = TRUE) +\n  geom_hline(yintercept = Vmax_est, linetype = \"dashed\",\n             color = \"hotpink1\", size = 0.4, show.legend = TRUE) +\n  labs(x = TeX(\"S [$\\\\mu$M]\"),\n       y = TeX(\"V [$\\\\mu$M $g^{-1}_{dry}$ $h^{-1}$]\")) +\n  # theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\nThe text is clear and concise, but here are a few minor changes for improved readability and precision:\n\n**Assumption tests** Since these data are simulated and drawn from a normal distribution with equal variances across the range of substrate concentrations, the assumptions of homoscedasticity and normality of residuals are inherently met. In this example, we fit the model solely to obtain estimates of the Michaelis-Menten parameters, rather than to make predictions, inferences, or calculate confidence intervals. Therefore, assumption tests are not critical at this stage. We will formally test assumptions in @sec-mf-treatments when comparing the effects of experimental treatments on kinetic parameters.\n\n#### Is the Michaelis-Menten model a better fit than a linear model?\n\nIn @sec-linear-vs-mm, we pose a hypothesis that requires comparing a linear model to a Michaelis-Menten model fitted to the same data. @fig-mf2 indicates the nonlinear model indeed provides a very good fit but in some situations this distinction may be less clear and require verification. Let us fit a linear model to the above data and compare it to the Michaelis-Menten model.\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Fit the linear model\nlm_mod <- lm(V ~ S, data = mf_data)\n\nsummary(lm_mod)\n```\n\nThe linear model summary shows that the slope and intercept are significantly different from zero, indicating a good fit. The $R^2$ value is 0.86, which is very high, suggesting that the linear model explains 86% of the variance in the data. The residual standard error is 5.13, which is higher than the Michaelis-Menten model, indicating a worse fit. We can test the difference between the models formally by examining the AIC, BIC, or SSR, and the likelihood ratio test.\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nAIC(lm_mod, nls_mod)\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nBIC(lm_mod, nls_mod)\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Calculate the sum of squared residuals (SSR)\nsum(residuals(lm_mod)^2)\nsum(residuals(nls_mod)^2)\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nanova(lm_mod, nls_mod)\n```\n\nThe AIC, BIC, and SSR values for the Michaelis-Menten model are lower than those for the linear model. Low is good, and we conclude that the Michaelis-Menten model is a better fit. The likelihood ratio test also shows that the Michaelis-Menten model is significantly better than the linear model (d.f. = 1, $F=375.43$, $p<0.0001$). Therefore, we can conclude that the Michaelis-Menten model is the most appropriate model for these data and that the rate of nutrient uptake by the seaweed (in this example) is saturated at high nutrient concentrations.\n\n#### Comparing treatment effects (NLS and NLMM) {#sec-mf-treatments}\n\nExperiments are seldom as simple as the one above. To develop our example further, consider an experiment designed to assess whether an experimental treatment, such as light intensity or seawater temperature, affects the nutrient uptake rate of a seaweed. It is biologically plausible to expect that each treatment will result in unique $V_{max}$ and/or $K_m$ values. For example, we know that the uptake rate of nitrate (\\ce{NO3-}) might increase at higher light intensities and higher temperatures. Therefore, our hypothesis for this experiment is that the nutrient uptake kinetics of the seaweed is influenced by the treatment, as more formally stated in @sec-mm-comparison. To test this hypothesis, we fit a Michaelis-Menten model so that it allows estimates of $V_{max}$ and $K_m$ to vary among treatment groups.\n\nThe data for a multiple flask experiment with a treatment effect comprised of three levels are provided in @tbl-mf2. Except for a new variable (treatment), the data are in all other respects identical to those in @sec-mf-single. \n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"Simulated data with three treatment levels for a multiple flask experiment on a seaweed species.\"\n#| label: tbl-mf2\n\nset.seed(13)\nmf_data2 <- generate_data(n_trt = 3, n_rep, conc_vec, Km_vec,\n                          Vmax_vec, Km_vec_sd, Vmax_vec_sd)\n\nmf_data2 |> \n  select(trt, rep, S, V) |>\n  mutate(V = round(V, 2)) |>\n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n  cols_align(\n    align = \"center\",\n    columns = c(\"trt\", \"rep\")) |> \n  cols_label(trt = html(\"Treatment\"),\n             S = html(\"[S]\"),\n             rep = html(\"Replicate flask\"),\n             V = html(\"V\"))\n```\n\n**Option 1** The `nls()` function in R does not handle factor variables directly, which means we cannot include the treatment variable as a factor in the model formula. To address this limitation, we fit the `nls()` model separately for each treatment group. This approach allows each treatment to have its own $V_{\\max}$ and $K_m$ values, effectively accommodating the variability in the Michaelis-Menten parameters across treatments.\n\nIn addition to fitting separate models for each treatment, we also fit a global model (a null model) to all the data. The global model assumes that the effect of the experimental treatment is negligible, meaning that all treatments share the same $V_{\\max}$ and $K_m$. This global fit serves as a baseline for comparison.\n\nTo determine whether the Michaelis-Menten parameters significantly differ among the treatment groups, we perform a likelihood ratio test. The likelihood ratio test compares the fit of the global model (where parameters are shared across treatments) to the combined fit of the separate models (where parameters vary by treatment). The test statistic is the difference in the log-likelihoods of the two models, which follows a $\\chi^2$ distribution with degrees of freedom equal to the difference in the number of parameters between the two models.\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Fit separate models\nseparate_models <- mf_data2 |>\n  group_by(trt) |>\n  nest() |>\n  mutate(model = map(data, ~nls(V ~ mm_fun(S, Vmax, Km),\n                                data = .x,\n                                start = list(Vmax = 40, Km = 10))))\n\n# Extract model summaries of separate models\nmodel_summaries <- separate_models|>\n  mutate(summary = map(model, broom::tidy))\n\n# Display summaries of separate models\nmodel_summaries |>\n  select(trt, summary) |>\n  unnest(summary)\n\n# Fit the global model\nglobal_model <- nls(V ~ mm_fun(S, Vmax, Km),\n                    data = mf_data2,\n                    start = list(Vmax = 45, Km = 9))\n\n# Extract log-likelihoods and degrees of freedom\nlogLik_global <- logLik(global_model)\ndf_global <- attr(logLik_global, \"df\")\n\n# Combined log-likelihoods and degrees of freedom\nlogLik_separate <- sum(sapply(separate_models$model, logLik))\ndf_separate <- sum(sapply(separate_models$model,\n                          function(m) attr(logLik(m), \"df\")))\n\n# Perform the likelihood ratio test\nlrt_stat <- 2 * (logLik_separate - logLik_global)\np_value <- pchisq(lrt_stat, df = df_separate - df_global,\n                  lower.tail = FALSE)\n\n# Display results\ncat(\"Global model log-likelihood:\", logLik_global, \"\\n\")\ncat(\"Separate models log-likelihood:\", logLik_separate, \"\\n\")\ncat(\"Degree of freedom:\", df_separate - df_global, \"\\n\")\ncat(\"Likelihood ratio test statistic:\", lrt_stat, \"\\n\")\ncat(\"p-value:\", p_value, \"\\n\")\n```\n\nThe results of the likelihood ratio test indicate whether the variation in $V_{\\max}$ and $K_m$ among the treatments is statistically significant. If the test is significant, it suggests that the Michaelis-Menten parameters differ across treatments. We interpret the results as follows:\n\n- The log-likelihood value (-620.7498) for the global model, indicating the fit of the model with shared parameters.\n- The combined log-likelihood value (-313.1862) for the separate models, indicating the fit of the models with parameters varying by treatment.\n- The calculated test statistic (615.1273) for the likelihood ratio test on 6 degrees of freedom.\n- The *p*-value of the test is less than 0.0001 and provides strong evidence that $V_{\\max}$ and $K_m$ differ significantly among the treatment groups.\n\n::: {.callout-tip}\n## Results\n\nThe analysis aimed to determine if the Michaelis-Menten parameters $V_{\\max}$ and $K_m$ significantly differed among the three experimental treatments. This was evaluated by fitting a global model with shared $V_{\\max}$ and $K_m$ values across all treatments and comparing it to a model allowing separate $V_{\\max}$ and $K_m$ estimates for each treatment. The log-likelihood value for the global model, which assumes shared $V_{\\max}$ and $K_m$ values across all treatments, was -620.75, indicating the fit of the model with common parameters. In contrast, the combined log-likelihood value for the separate models, which allow $V_{\\max}$ and $K_m$ to vary by treatment, was -313.19, indicating the fit of the models with treatment-specific parameters. The calculated test statistic for the likelihood ratio test was 615.13 (d.f. = 6, *p* < 0.001), providing strong evidence that the Michaelis-Menten parameters $V_{\\max}$ and $K_m$ differ significantly among the treatment groups. Consequently we estimate a $V_{max}$ of 49.2 ± 0.96, 39.4 ± 0.87 $\\mu$M N g$^{-1}$ hr$^{-1}$ and 18.9 ± 0.65 and a $K_m$ of 9.55 ± 0.48, 7.54 ± 0.48 and 5.50 ± 0.64 $\\mu$M for treatments 1, 2 and 3 respectively.\n:::\n\n**Option 2** If Option 1 seems cumbersome, we can fit a NLMM using the **nlme** package instead. This package allows us to fit a mixed model with random effects for each treatment group. In this model, the fixed effects are the Michaelis-Menten parameters $V_{\\max}$ and $K_m$, which vary by treatment, while the random effects are the replicate-specific intercepts. Thus, the cumbersome `nls()` formulation is replaced by the compact but more fiddly `nlme()` model specification. Pick your poison. The model is specified as follows:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Fit the model with the same parameters for both treatments\n# Starting values for Vmax and Km\nstart_vals <- c(Vmax = 50, Km = 10)\nglobal_model <- nlme(\n  V ~ mm_fun(S, Vmax, Km),\n  data = mf_data2,\n  fixed = Vmax + Km ~ 1, # <1>\n  random = Vmax ~ 1 | trt/rep, # <2>\n  start = start_vals\n)\n\n# Fit the model with parameters varying by treatment\n# Starting values for Vmax and Km for each treatment\nstart_vals <- c(Vmax1 = 50, Vmax2 = 40, Vmax3 = 30,\n                Km1 = 10, Km2 = 10, Km3 = 5) # <3>\nseparate_models <- nlme(\n  V ~ mm_fun(S, Vmax, Km),\n  data = mf_data2,\n  fixed = list(Vmax ~ trt, Km ~ trt), # <4>\n  random = Vmax ~ 1 | trt/rep,\n  start = start_vals\n)\n```\n1. The fixed effects indicate that both $V_{\\max}$ and $K_m$ are fixed (do not vary) across treatments.\n2. The random effects indicate that the $V_{\\max}$ parameter varies by treatment and replicate.\n3. The starting values for the $V_{\\max}$ and $K_m$ parameters are specified for each treatment group. Because we are now fitting a separate model for each treatment, we need to provide starting values for each treatment.\n4. The fixed effects now indicate that both $V_{\\max}$ and $K_m$ vary by treatment.\n\nThe estimated parameters for the global model and the separate models can be extracted using the `summary()` function:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Extract the estimated parameters (abbreviated output)\n# summary(global_model) # for verbose output\nsummary(global_model)$tTable\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Extract the estimated parameters (abbreviated output)\n# summary(separate_models) # for verbose output\nsummary(separate_models)$tTable\n```\n\nThe log-likelihood ratio test can then easily be performed using the `anova()` function, which compares the global model with the separate models:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nanova(global_model, separate_models)\n```\n\nAgain, the results of the likelihood ratio test indicate that the variation in $V_{\\max}$ and $K_m$ among the treatments is statistically significant (log-likelihood = 45.20, *p* < 0.0001). The AIC values can also be used to compare the models, with lower AIC values indicating a better fit. In this case, the separate models have a lower AIC value (644.28), suggesting that they provide a better fit to the data than the global model (681.479). The data fitted with the global and separate models is presented in @fig-mf3.\n\n**Assumption tests** To complete our example comparing the Michaelis-Menten parameters among treatments, let's confirm the assumptions by examining the residuals. Residuals in nonlinear regression models have the same interpretation as in linear models, and therefore, the assumption tests available for linear models can be applied here as well. For instance, we can use the `shapiro.test()` function to check the normality of residuals, as shown below, and the `hist()` and `plot()` functions for diagnostic plots. In real-world data, it is advised to verify these assumptions before accepting the analysis and drawing conclusions from the nonlinear regression model. Let's check the normality of residuals for each treatment and plot the residuals to check for normality and homoscedasticity (@fig-mf-assump).\n\n```{r}\n#| echo: true\n#| eval: true\n#| messages: false\n#| warning: false\n\n# Add residuals and fitted information to the data frame\nmf_data2$residuals_separate <- residuals(separate_models)\nmf_data2$fitted_values_separate <- fitted(separate_models)\n\n# Perform the Shapiro-Wilk test for each treatment\nshapiro.test(mf_data2$residuals_separate[mf_data2$trt == \"Treatment 1\"])\nshapiro.test(mf_data2$residuals_separate[mf_data2$trt == \"Treatment 2\"])\nshapiro.test(mf_data2$residuals_separate[mf_data2$trt == \"Treatment 3\"])\n```\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| eval: true\n#| messages: false\n#| warning: false\n#| fig.cap: \"Histograms (A) of residuals and plots of residuals vs. the fitted values (B) for residuals for the three treatments in the multiple-flask experiment.\"\n#| label: fig-mf-assump\n#| fig-align: center\n\n# Make histograms with frequency polygons overlain\n# for visual comfirmation (optional)\nplt1 <- ggplot(mf_data2, aes(x = residuals_separate)) +\n  geom_histogram(aes(y = ..density..), bins = 10,\n                 fill = \"lightblue\", colour = \"lightblue\") +\n  geom_density(alpha = 0.5) +\n  facet_wrap(~ trt) +\n  labs(x = \"Residuals\", y = \"Density\")\n\nplt2 <- ggplot(mf_data2, aes(x = fitted_values_separate, y = residuals_separate)) +\n  geom_point(colour = \"royalblue2\", shape = 1) +\n  geom_smooth(method = \"gam\", se = FALSE,\n              linewidth = 0.6, colour = \"indianred2\") +\n  facet_wrap(~trt) +\n  theme(legend.position = \"none\") +  # Turn off the legend\n  labs(x = \"Fitted Values\",\n       y = \"Residuals\")\n\nggarrange(plt1, plt2, nrow = 2, labels = c(\"A\", \"B\"))\n```\n\nThe Shapiro-Wilk test results indicate that the residuals are normally distributed for Treatments 1 and 2 (*p* > 0.05) but not for Treatment 3 (*p* < 0.05). However, the histograms in @fig-mf-assump show that the residuals are approximately normally distributed for all treatment groups, with the median roughly in the middle of the distribution in each case. This apparent discrepancy can be explained by the sensitivity of the Shapiro-Wilk test to sample size. With large sample sizes, even minor deviations from normality can be detected as statistically significant. In situations such as this one, I suggest that it is important to consider the sample size and visual inspection of the data when interpreting the results of normality tests. Here, given the relatively large sample size and the visual assessment of the histograms, we can reasonably conclude that the residuals are approximately normally distributed for all treatment groups. \n\nAnother normality tests such as the Kolmogorov-Smirnov (K-S) test might be less sensitive to sample size and could be considered for comparison. The K-S test is a non-parametric statistical test that is used to determine if a sample comes from a specific probability distribution. Here I use it to test if a sample follows a normal distribution (`pnorm`), but it can also be used to test against other theoretical distributions or to compare two empirical distributions. The K-S test can be performed using the `ks.test()`, as shown below.\n\n```{r}\n#| echo: true\n#| eval: true\n#| messages: false\n#| warning: false\n\nperform_ks_test <- function(data, treatment) {\n  ks.test(data$residuals_separate[data$trt == treatment], \"pnorm\", \n          mean = mean(data$residuals_separate[data$trt == treatment]), \n          sd = sd(data$residuals_separate[data$trt == treatment]))\n}\n\n# Perform the test for each treatment group\nperform_ks_test(mf_data2, \"Treatment 1\")\nperform_ks_test(mf_data2, \"Treatment 2\")\nperform_ks_test(mf_data2, \"Treatment 3\")\n```\n\nWe see that the K-S test indicates that the residuals are normally distributed for all treatment groups (*p* > 0.05). As already noted, this test is less sensitive to sample size than the Shapiro-Wilk test, and the results are consistent with the visual assessment of the histograms.\n\nWe should also check for homoscedasticity (here I use the Levene test) and a plot of residuals versus fitted values. \n\n```{r}\n#| echo: true\n#| eval: true\n#| messages: false\n#| warning: false\n\n# Perform the Levene test\ncar::leveneTest(residuals_separate ~ trt, data = mf_data2)\n```\n\nThe Levene test shows that the variances are the same across the three treatments and this is confirmed by the plot of residuals against the fitted values in @fig-mf-assump. \n\n::: {.callout-tip}\n## Results\n\nMichaelis-Menten models were fitted to nutrient uptake data across three experimental treatments to investigate the effects of the treatments on seaweed nutrient kinetics. A global model, assuming shared kinetic parameters ($V_{max}$ and $K_m$) across all treatments, was compared to a model with separate parameters for each treatment. The model allowing treatment-specific parameters (AIC = 644.3) provided a significantly better fit to the data than the global model (AIC = 681.5), a finding confirmed by the log-likelihood test (log-likelihood ratio = 45.20, d.f. = 4, *p* < 0.0001). As the assumption tests do not indicate any cause for concern regarding the distribution of residuals, we conclude that the experimental treatments significantly influenced the nutrient uptake kinetics of the seaweed (@fig-mf3).\n\nSpecifically, all three treatments exhibited unique combinations of $V_{max}$ and $K_m$ values (Treatment 1: $V_{max}$ = 49.2, $K_m$ = 9.5; Treatment 2: $V_{max}$ = 39.3, $K_m$ = 7.5; Treatment 3: $V_{max}$ = 19.0, $K_m$ = 5.5). These findings support the hypothesis that nutrient uptake kinetics in this seaweed species are sensitive to environmental perturbations.\n:::\n\n```{r, fig.width=c(6,5),fig.asp=0.5,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of the Michaelis-Menten model fitted to the data in @tbl-mf2. Fits are provided for the separate models and the global model.\"\n#| label: fig-mf3\n#| fig-align: center\n#| fig-pos: \"t\"\n\n# Extract coefficients for shared model\nVmax_est_shared <- global_model$coefficients$fixed[\"Vmax\"]\nKm_est_shared <- global_model$coefficients$fixed[\"Km\"]\n\n# Extract coefficients for separate models\ncoeffs <- separate_models$coefficients$fixed\nVmax_est_separate <- coeffs[\"Vmax.(Intercept)\"] +\n  c(0, coeffs[paste0(\"Vmax.trtTreatment \", 2:3)])\nKm_est_separate <- coeffs[\"Km.(Intercept)\"] +\n  c(0, coeffs[paste0(\"Km.trtTreatment \", 2:3)])\n\n# Assign individual variables for clarity\nVmax_est_separate_1 <- Vmax_est_separate[1]\nVmax_est_separate_2 <- Vmax_est_separate[2]\nVmax_est_separate_3 <- Vmax_est_separate[3]\nKm_est_separate_1 <- Km_est_separate[1]\nKm_est_separate_2 <- Km_est_separate[2]\nKm_est_separate_3 <- Km_est_separate[3]\n\n# Creating a sequence for smooth curve\nconc_seq <- seq(min(mf_data2$S), max(mf_data2$S), length.out = 100)\n\n# Predicting V values for shared and separate models\npredicted_V <- lapply(\n  list(shared = list(Vmax = Vmax_est_shared, Km = Km_est_shared),\n       trt1 = list(Vmax = Vmax_est_separate_1, Km = Km_est_separate_1),\n       trt2 = list(Vmax = Vmax_est_separate_2, Km = Km_est_separate_2),\n       trt3 = list(Vmax = Vmax_est_separate_3, Km = Km_est_separate_3)),\n  function(params) {\n    (params$Vmax * conc_seq) / (params$Km + conc_seq)\n  }\n)\n\n# Creating the dataframe\npred_df <- data.frame(\n  S = rep(conc_seq, 4),\n  V = unlist(predicted_V),\n  trt = rep(c(\"Global\", \"Treatment 1\", \"Treatment 2\", \"Treatment 3\"),\n            each = 100)\n)\n\n# Plot the data and model fits\nmf_data2 %>%\n  ggplot(aes(x = S, y = V, colour = trt)) +\n  geom_jitter(shape = 1, width = 0.08) +\n  geom_line(data = pred_df, aes(y = V, colour = trt, linewidth = trt)) +\n  scale_colour_manual(values = c(\"#804145\", \"#51728E\",\n                                 \"#5D995C\", \"#EE915C\"),\n                      name = NULL) +\n  scale_linewidth_manual(values = c(1.0, 0.6, 0.6, 0.6)) +\n  labs(x = \"Substrate Concentration\",\n       y = \"Reaction Velocity\") +\n  labs(x = TeX(\"S [$\\\\mu$M]\"),\n       y = TeX(\"V [$\\\\mu$M $g^{-1}_{dry}$ $h^{-1}$]\")) +\n  guides(linewidth = \"none\")\n```\n\n### The Perturbation Method (NLMM) {#sec-perturbation}\n\n```{r}\n#| eval: TRUE\n#| echo: FALSE\n#| messages: false\n#| warning: false\n\nmm_data <- read.csv(\"data/flow_rates.txt\", sep = \"\")\n\nmm_data <- mm_data|>\n  mutate(flask = as.factor(rep(c(1, 2, 3), 44)),\n         trt = as.factor(trt))\n```\n\nThe data for this example is by @smit2002nitrogen. A perturbation experiment was conducted to determine the nutrient uptake rate versus nutrient concentration of the red seaweed, *Gracilaria* sp. The experiment involved flasks, initially enriched to approximately 55 μM nitrate, sampled 16 times over approximately 2.5 hours. The uptake rates were measured under three rates of water movement (treatments): low, medium, and high. Each treatment had three replicate flasks (@tbl-mm1). The primary objective was to determine if the Michaelis-Menten parameters significantly differ among the three levels of water movement, and we must state a hypothesis similar to those in @sec-mm-comparison.\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"Simulated data for a multiple flask experiment on an alga (showing only the top and bottom three rows).\"\n#| label: tbl-mm1\n\nmm_data |> \n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n  cols_align(\n    align = \"center\",\n    columns = c(\"flask\", \"trt\")) |> \n  cols_label(flask = html(\"Replicate flask\"),\n             trt = html(\"Treatment\"),\n             V = html(\"V\"),\n             S = html(\"[S]\"))\n```\n\nFor the reasons discussed in @sec-ex1, we will use a nonlinear mixed effects model, `nlme()`, to analyse these data. Models such as these can be quite challenging to fit. There are several things we have to deal with. First and most obviously is the fact that the data are repeated measures, and the residuals may be correlated. Second, the flasks are nested within the treatment levels, and we need to account for this in the model. Finally, we need to account for the possibility that the Michaelis-Menten parameters may vary among the treatment levels---in fact, we want to test this! Here is the model:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Determine the number of levels in the factor 'trt'\nnum_levels <- length(levels(mm_data$trt))\n\n# Starting values for the fixed parameters\n# (one set for each level of 'trt')\nstart_vals <- list(fixed = c(Vmax = rep(max(mm_data$V), num_levels),\n                             Km = rep(median(mm_data$S), num_levels)))\n\nnlme_mod2 <- nlme(V ~ mm_fun(S, Vmax, Km),\n                  data = mm_data,\n                  fixed = Vmax + Km ~ trt, # <1>\n                  random = Vmax + Km ~ 1 | flask, # <2>\n                  start = start_vals,\n                  method = \"REML\")\n```\n\n1. The `fixed` argument specifies that the Michaelis-Menten parameters `Vmax` and `Km` are fixed effects that vary among the treatment levels, and a grouping variable (`trt`) is used to specify the levels of the treatment factor.\n2. The `random` argument specifies that the Michaelis-Menten parameters `Vmax` and `Km` are random effects that vary among the replicate flasks.\n\nThis model brings us closer to our goal, but there are some notable omissions. The specification allows the Michaelis-Menten parameters to vary among the treatment levels, which is central to our hypothesis. We have also accounted for the replication structure of the data, recognising that random variations may arise not due to the treatment levels but due to the replicate flasks. \n\nHowever, we have not accounted for the central feature of a perturbation experiment, which is the correlation structure of the residuals. We must deal with the fact that the residuals may be correlated due to the repeated measures nature of the data. Additionally, we have omitted the nesting of the flasks within the treatment levels. \n\nLet's update our model accordingly:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nnlme_mod3 <- nlme(V ~ mm_fun(S, Vmax, Km),\n                  data = mm_data,\n                  fixed = list(Vmax ~ trt, Km ~ trt),\n                  random = Vmax ~ 1 | trt/flask, # <1>\n                  groups = ~ trt/flask, # <2>\n                  correlation = corAR1(form = ~ 1 | trt/flask), # <3>\n                  start = start_vals,\n                  method = \"REML\")\n```\n1. The `random` argument specifies that the Michaelis-Menten parameter `Vmax` is a random effect that varies among the replicate flasks nested within the treatment levels.\n2. The `groups` argument specifies that the replicate flasks are nested within the treatment levels.\n3. The `correlation` argument specifies that the residuals have a first-order autoregressive correlation structure. This structure assumes that the correlation between residuals decreases exponentially with the time lag between observations. Flask is nested *within* treatment.\n\nIf we are not convinced that `nlme_mod3` is the best model, we can compare it to `nlme_mod2` using a likelihood ratio test. It is used to compare the fit of two models, where one model is a special case of the other. The test statistic is the difference in the log-likelihoods of the two models, and the null hypothesis is that the simpler model is the best fit. \n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n#| eval: true\n\nanova(nlme_mod2, nlme_mod3)\n\n# Likelihood ratio test\nlrt_stat <- -2 * (logLik(nlme_mod2) - logLik(nlme_mod3))\n\n# Determine degrees of freedom and p-value\ndf_diff <- attr(logLik(nlme_mod3), \"df\") - attr(logLik(nlme_mod2), \"df\") \np_value <- pchisq(lrt_stat, df = df_diff, lower.tail = FALSE) \n\nprint(paste(\"LRT statistic:\", lrt_stat))\nprint(paste(\"Degrees of freedom:\", df_diff))\nprint(paste(\"P-value:\", p_value))\n```\n\nThe likelihood ratio test indicates that `nlme_mod3` is a better fit than `nlme_mod2` (*p* < 0.001). This result suggests that the Michaelis-Menten parameters vary among the treatment levels, and the residuals have a first-order autoregressive correlation structure.\n\n```{r}\nsummary(nlme_mod3)\n```\n\n\n## Example: The Growth Rate of Fish (NLMM) {#sec-vonbertalanffy}\n\nThe von Bertalanffy model (@eq-vb) is used to describe the growth patterns of animals over time. For example, in a fish growth study, we measure the length of individual fish at regular intervals as the fish ages. We can estimate growth parameters specific to the fish species by fitting the von Bertalanffy model to these length-at-age data\n\nThe model is given by:\n\n$$L(t) = L_{\\infty} \\left(1 - e^{-k(t-t_0)}\\right)$$ {#eq-vb}\n\nWhere:\n\n- $L(t)$ is the length of the fish at time $t$.\n- $L_{\\infty}$ is the asymptotic length, representing the theoretical maximum length that the individual would reach if it grew indefinitely.\n- $k$ is the growth coefficient, indicating the rate at which the growth of the fish approaches its maximum size. A higher $k$ value means it reaches its asymptotic length more quickly.\n- $t_0$ is the hypothetical age at which the individual's length would be zero according to the model.\n\n$L_{\\infty}$ (the asymptotic length) represents the length towards which the individual grows as time ($t$) approaches infinity. The concept behind $L_{\\infty}$ is that as the fish ages, its growth rate slows down and eventually approaches zero, with its length nearing the asymptotic value $L_{\\infty}$. $k$ (the growth rate coefficient) determines how quickly the fish reaches its asymptotic length. Physiologically, $k$ reflects the metabolic rates and general fitness of the fish, while ecologically, it can be influenced by environmental factors such as food availability and temperature. Lastly, $t_0$ (the theoretical age at zero length) is not directly observable in practice but provides a useful way to shift the growth curve along the time axis to provide a better fit to the data, especially in the early developmental stages.\n\nConsider a study where the lengths of 30 Atlantic Cod, *Gadus morua*, in captivity are measured twice a year from hatching to 15 years. This creates a longitudinal dataset with repeated length measurements for each fish over time. In this experiment, we will focus on the growth patterns of individual fish, assuming they were raised under identical conditions. This allows us to attribute any growth differences to inherent biological variation among the fish. Apart from the repeated measures on individual fish, we will assume that the data are independent in all other respects.\n\nThe longitudinal nature of the data requires that we use appropriate statistical methods that account for the correlation among the repeated measures. We will use a nonlinear mixed-effects regression for the data in Table 1. \n\n```{r}\n#| echo: false\n#| messages: true\n#| warning: true\n\n# Set up parameters for the von Bertalanffy growth model\nset.seed(13)\n\n# Define parameters\nn_fish <- 30\nn_years <- 15\nn_measurements_per_year <- 2\ntotal_measurements <- n_years * n_measurements_per_year\nages <- seq(0, n_years, by = 1/n_measurements_per_year)\n\n# Initial lengths at hatching (small variation)\ninitial_lengths <- rnorm(n_fish, mean = 5, sd = 0.5)\n\n# von Bertalanffy growth parameters\nL_inf <- 120  # Asymptotic length\nL_inf_sd <- 1\nk_mean <- 0.2\nk_sd <- 0.01\n\n# Generate growth curves for each fish\nvb_data <- data.frame()\nfor (i in 1:n_fish) {\n  k <- rnorm(1, mean = k_mean, sd = k_sd)\n  L_inf <- rnorm(1, mean = L_inf, sd = L_inf_sd)\n  length_at_age <- L_inf * (1 - exp(-k * ages))\n  length_at_age <- initial_lengths[i] + (length_at_age - min(length_at_age))\n  \n  fish_data <- data.frame(\n    Fish_ID = as.factor(rep(i, length(ages))),\n    Age = ages,\n    Length = round(length_at_age, 1)\n  )\n  \n  vb_data <- bind_rows(vb_data, fish_data)\n}\n```\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"The Atlantic Cod data set with 30 fish and 15 years of growth data (showing only the top and bottom three rows).\"\n\nvb_data |> \n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n    cols_align(\n    align = \"center\",\n    columns = c(\"Age\", \"Length\")) |> \n  cols_label(\n    Fish_ID = html(\"Fish ID\"),\n    Age = html(\"Age (yr)\"),\n    Length = html(\"Length (cm)\")\n  )\n```\n\nA plot of the data is shown in @fig-vb1; here, each line represents the growth trajectory of an individual fish over time.\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of growth data measured in 30 Atlantic cod, *Gadus morua*.\"\n#| label: fig-vb1\n#| fig.align: center\n\n# Plot the simulated data\nggplot(vb_data, aes(x = Age, y = Length, group = Fish_ID)) +\n  geom_jitter(alpha = 0.6, size = 2, shape = 1,\n              colour = \"black\", width = 0.08) +\n  geom_line(alpha = 0.6, linesize = 0.1,\n            colour = \"red\", linetype = \"dashed\") +\n  labs(x = \"Age (years)\",\n       y = \"Length (cm)\")\n  theme(legend.position = \"none\")\n```\n\nWe will fit the von Bertalanffy growth model to the data using `nlme::nlme()` as follows, and the output is provided: \n\n```{r}\n#| messages: false\n#| warning: false\n\n# von Bertalanffy growth function\nvb_growth <- function(age, L_inf, k, t0) {\n  L_inf * (1 - exp(-k * (age - t0)))\n}\n\n# Define the nonlinear mixed-effects model\nnlme_model <- nlme(Length ~ vb_growth(Age, L_inf, k, t0),\n                   data = vb_data,\n                   fixed = L_inf + k + t0 ~ 1, # <1>\n                   random = L_inf + k ~ 1 | Fish_ID, # <2>\n                   groups = ~ Fish_ID, # <3>\n                   correlation = corAR1(form = ~ 1), # <4>\n                   start = c(L_inf = 100, k = 0.2, t0 = -0.5))\n\n# Print the summary of the model\nsummary(nlme_model)\n```\n1. The fixed effects are the parameters of the von Bertalanffy growth model which are invariant among fish.\n2. The random effects are the asymptotic length and growth rate to account for the intrinsic differences among fish.\n3. The grouping variable is the fish ID.\n4. The correlation structure is autoregressive of order 1 to account for the correlation among repeated measures within the same fish, the `~ 1` indicates that the order of the observations in the data must be used along which measurements are serially correlated, and since no grouping variable is provided, all fish will have the same correlation structure.\n\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Fit of the von Bertalanffy model to experimental data obtained from 30 Atlantic Cod individuals.\"\n#| label: fig-vb2\n#| fig.align: center\n\n# Extract fixed effect coefficients\ncoef_fixed <- fixed.effects(nlme_model)\n\n# Generate fitted values for the plot\nvb_data$Fitted_Length <- vb_growth(vb_data$Age, coef_fixed[\"L_inf\"], coef_fixed[\"k\"], coef_fixed[\"t0\"])\n\n# Create the plot\nggplot(vb_data, aes(x = Age, y = Length, group = Fish_ID)) +\n  geom_jitter(size = 2, shape = 1, colour = \"royalblue2\", alpha = 0.4, width = 0.08) +\n  geom_line(aes(y = Fitted_Length), colour = \"indianred2\", linewidth = 0.8) +\n  labs(x = \"Age (years)\",\n       y = \"Length (cm)\")\n```\n\n\n## Scrathpad\n\n### To include in the article\n\n-   **Assumptions:** Not necessary for simply estimating model parameters, but if the model is used for prediction or inference, it is important to state the assumptions of the model (e.g., linearity, homoscedasticity, independence of residuals) and test them.\n-   **i.i.d:** The residuals are assumed to be independent and identically distributed (i.i.d.), which is a common assumption in linear regression models. For a normal distribution, this is written as $\\epsilon_i \\sim N(0, \\sigma^2)$, where $\\sigma^2$ is the variance of the residuals.\n\n\n### Contuinuing the MM model\n\n\n\n\n\n\n\n","srcMarkdownNoYaml":"\n\n```{r echo = FALSE, cache = FALSE}\nsource(\"utils.R\", local = TRUE)\n```\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| include: true\n\nlibrary(tidyverse)\nlibrary(ggpubr)\nlibrary(gt)\nlibrary(nlme)\nlibrary(mgcv)\nlibrary(emmeans) # For post-hoc comparisons\nlibrary(ggsci) # For color palettes\nlibrary(latex2exp) # For figure titles with LaTeX expressions\n```\n\n# Nonlinear Models {#sec-nonlinear-regression}\n\n**In This Chapter**\n\n- [Nonlinear Regression](@sec-nonlinear-regression)\n\n**Elsewhere in the Book**\n\n- [Simple Linear Regression](@sec-simple-linear-regression)\n- [Polynomial Regression](@sec-polynomial-regression)\n- [Multiple Linear Regression](@sec-multiple-linear-regression)\n- [Generalised Linear Models](@sec-generalised-linear-models)\n- [Generalised Additive Models](@sec-generalised-additive-models)\n\nNonlinear regression models\\index{nonlinear regression} are used when the relationship between the response variable (dependent variable, $Y$) and the predictor variables (independent variables, $X$) is not linear. In other words, they are employed when a straight line is not an appropriate representation of the relationship between the variables.\n\nAs we have seen in @sec-simple-linear-regression, polynomial regressions provide a nonlinear relationship between the response and predictor variables (as seen in the regression line fit to the data, @fig-plts A), but they are considered linear models because the parameters are estimated using linear least squares. Another type of nonlinear model is a semi-parametric model where the relationship between the response and predictor variables is described by a function that includes both parametric and non-parametric components. An example of a semi-parametric model is the generalised additive model (GAM) that includes a non-parametric component in the form of a spline function (@sec-generalised-additive-models; @fig-plts B).\n\nThe type of nonlinear model I cover in this chapter is a parametric model where the relationship between the response and predictor variables is described by a specific nonlinear function (@fig-plts C). The model still assumes that the residuals are normally distributed and exhibit homoscedasticity. The model parameters are estimated by minimising the sum of squared differences between the observed and predicted values, a method commonly referred to as nonlinear least squares (NLS) regression. This is the term I will adopt.\n\nThe primary purpose of nonlinear regression is to derive a formula (model), analyse data, and predict new values where the phenomenon exhibits a nonlinear causal\\index{causal} pattern or behaviour. Nonlinear models include a variety of response forms, such as exponential growth models, logistic growth models, and other mechanistic models derived from physical, chemical, or biological processes. Examples of such models include trigonometric, logarithmic, and user-defined functions like the von Bertalanffy model or seasonal cycle represented by a sine curve (@fig-plts C). These models are explicitly nonlinear in both their form and parameters. Unlike polynomial regression, where only the terms of $X$ are transformed, nonlinear models involve an entirely nonlinear function relating $X$ and $Y$. They are often used when there is a theoretical basis for the specific form of the relationship, providing interpretable parameters that carry specific meanings based on the underlying theory, making them useful for detailed applications where the dynamics of the system are well-understood.\n\nA general formula for a nonlinear regression model is:\n\n$$Y_i = f(X_i; \\theta) + \\epsilon_i$$ {#eq-nonlin}\n\nWhere:\n  \n- $Y_i$ is the response variable for the $i$-th observation,\n- $X_i$ is the predictor variable for the $i$-th observation,\n- $f(X_i; \\theta)$ is a nonlinear function of $X_i$ parameterised by the vector $\\theta$,\n- $\\theta$ is the vector of parameters to be estimated, and\n- $\\epsilon_i$ is the error term for the $i$-th observation and is assumed to be i.i.d. with a normal distribution.\n\nAn example of a specific nonlinear regression model is the exponential growth model:\n  \n  $$Y_i = \\alpha e^{\\beta X_i} + \\epsilon_i$$ {#eq-exp}\n\nWhere:\n  \n- $\\alpha$ and $\\beta$ are the parameters to be estimated,\n- $e$ is the base of the natural logarithm, and\n- $\\epsilon_i$ is the error term for the $i$-th observation.\n\nThis model is nonlinear in the parameters $\\alpha$ and $\\beta$, and it describes an exponential relationship between the predictor $X$ and the response $Y$.\n\n```{r, fig.width=c(9,6),fig.asp=c(0.65,0.65),out.width=list(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Nonlinear regression models fitted to simulated data. A) a cubic polynomial model, B) a GAM with a thin plate regression spline, and C) a NLS sine curve as a seasonal cycle.\"\n#| label: fig-plts\n#| fig.align: center\n#| fig-pos: \"t\"\n\n# Load necessary libraries\n# Set seed for reproducibility\nset.seed(13)\n\n# Generate synthetic data for polynomial fit\nx <- seq(-10, 10, length.out = 30)\ny <- 1 - 2*x + 3*x^2 - 0.5*x^3 + rnorm(30, sd = 40)  # cubic equation with noise\n\ndat_poly <- data.frame(x, y)\n\n# Fit a cubic polynomial model\nmod_poly <- lm(y ~ poly(x, 3, raw = FALSE), data = dat_poly)\n\n# Create a data frame for predictions\nx_grid <- seq(min(x), max(x), length.out = 300)\npred_poly <- data.frame(x = x_grid)\npred_poly$y <- predict(mod_poly, newdata = pred_poly)\n\n# Plot the data and the fitted model\nplt_poly <- ggplot(dat_poly, aes(x, y)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = pred_poly, aes(x, y), color = \"black\") +\n  xlab(\"Predictor, X\") +\n  ylab(\"Response, Y\")\n\n# Simulate data for a seasonal cycle\nx <- seq(0, 365, by = 7)  # Days of the year\namplitude <- 6  # Amplitude (half the difference between longest and shortest day)\noffset <- 12   # Average day length\ny <- amplitude * sin(2 * pi * (x / 365 - 0.25)) + offset + rnorm(length(x), sd = 0.55)  # Sine curve with noise\n\n# Create data frame\ndat_sin <- data.frame(Day = x, DayLength = y)\n\n# Fit nonlinear regression model (using nls)\nmod_sin <- nls(DayLength ~ A * sin(2 * pi * (Day / 365 - phi)) + C, data = dat_sin, \n             start = list(A = 6, phi = 0.25, C = 12))\n\n# Get predicted values\ndat_sin$Predicted <- predict(mod_sin)\n\n# Visualise results\nplt_sin <- ggplot(dat_sin, aes(x = Day)) +\n  geom_point(aes(y = DayLength), size = 2, shape = 1, color = \"royalblue2\") +\n  geom_line(aes(y = Predicted), color = \"black\") +\n  labs(x = \"Day of the Year\", y = \"Response, Y\")\n\n# Parameters for the Michaelis-Menten model\nV_max <- 100  # maximum rate of the enzyme reaction\nK_m <- 25     # Michaelis constant\n\n# Generate substrate concentrations\nS <- seq(0, 100, length.out = 30)\n\n# Generate reaction rates using the Michaelis-Menten equation with added noise\nV <- (V_max * S) / (K_m + S) + rnorm(30, mean = 0, sd = 5)\n\n# Create a data frame\ndat_mm <- data.frame(S, V)\n\n# Fit the Michaelis-Menten model\nmod_mm <- nls(V ~ (V_max * S) / (K_m + S), data = dat_mm, start = list(V_max = 90, K_m = 40))\n\n# Create a grid for predictions\nS_grid <- seq(min(S), max(S), length.out = 300)\npred_mm <- data.frame(S = S_grid)\npred_mm$V <- predict(mod_mm, newdata = pred_mm)\n\n# Plot the data and the fitted model\nplt_mic <- ggplot(dat_mm, aes(S, V)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = pred_mm, aes(S, V), color = \"black\") +\n  xlab(\"Substrate Concentration [S]\") +\n  ylab(\"Uptake Rate V\")\n\n# Generate synthetic data\nx <- seq(-3, 3, length.out = 30)\ny <- x^2 * sin(x) + rnorm(30, sd = 0.5)  # Complex nonlinear relationship\n\ndat_gam <- data.frame(x, y)\n\n# Fit a Generalized Additive Model using thin plate regression spline\nmod_gam <- gam(y ~ s(x, bs = \"tp\"), data = dat_gam)  # 'tp' specifies thin plate spline\n\n# Create a grid for predictions\nx_grid <- seq(min(x), max(x), length.out = 300)\npred_gam <- data.frame(x = x_grid)\npred_gam$y <- predict(mod_gam, newdata = pred_gam)\n\n# Plot the data and the fitted GAM\nplt_gam <- ggplot(dat_gam, aes(x, y)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = pred_gam, aes(x, y), color = \"black\") +\n  xlab(\"Predictor, X\") +\n  ylab(\"Response, Y\")\n\nggarrange(plt_poly, plt_gam, plt_sin, ncol = 2, nrow = 2,\n          labels = \"AUTO\")\n```\n\n\n## Extension of Nonlinear Models\n\nLike linear models, nonlinear models have also been extended to include multiple predictors, interactions, and other terms to capture complex relationships between the variables. The first type of more complex nonlinear models accommodates a wider range of data distributions by generalising to non-normal error distributions through link functions. These models are called generalised nonlinear models (GNLMs). The examples of GLMs in @sec-generalised-linear-model should prepare you sufficiently to handle nonlinear models too. The other type deals with hierarchical data structures and incorporates fixed and random effects. As such, you can also correctly model repeated measures and longitudinal, and nested (grouped) designs. These hierarchical models are called nonlinear mixed models (NLMMs). Examples of NLMMs are provided in @sec-mf-treatments and @sec-perturbation.\n\n\n## Considerations for Model Selection\n\n```{r, fig.width=c(6,5),fig.asp=0.5,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of growth rate data fitted with a von Bertalanffy model, a first- (straight line), second- and third-order polynomial, and a GAM.\"\n#| label: fig-combo\n#| fig.align: center\n#| fig-pos: \"t\"\n\nset.seed(13)\n\n# Parameters for the von Bertalanffy model\nL_inf <- 100  # theoretical maximum length\nk <- 0.2      # growth rate\nt0 <- -1      # hypothetical age at length zero\n\n# Generate time points\nt <- 0:20\n\n# Generate lengths using the von Bertalanffy equation with some added noise\nL_t <- L_inf * (1 - exp(-k * (t - t0))) + rnorm(21, mean = 0, sd = 5)\n\n# Create a data frame\ndat_vb <- data.frame(t, L_t)\n\n# Fit the von Bertalanffy model\nmod_vb <- nls(L_t ~ L_inf * (1 - exp(-k * (t - t0))), data = dat_vb, start = list(L_inf = 80, k = 0.1, t0 = 0))\n\n# Fit polynomial model2\nmod_poly1 <- lm(L_t ~ poly(t, 1, raw = FALSE), data = dat_vb)\nmod_poly2 <- lm(L_t ~ poly(t, 2, raw = FALSE), data = dat_vb)\nmod_poly3 <- lm(L_t ~ poly(t, 3, raw = FALSE), data = dat_vb)\n\n# Fit the GAM\nmod_gam <- gam(L_t ~ s(t), data = dat_vb)\n\n# Create a grid for predictions\nt_grid <- seq(min(t), max(t), length.out = 21)\npred_vb <- data.frame(t = t_grid)\nL_t_pred <- predict(mod_vb, newdata = pred_vb)\ny1_pred <- predict(mod_poly1, newdata = pred_vb)\ny2_pred <- predict(mod_poly2, newdata = pred_vb)\ny3_pred <- predict(mod_poly3, newdata = pred_vb)\ny_gam_pred <- predict(mod_gam, newdata = pred_vb)\ndat_vb <- cbind(dat_vb, L_t_pred, y1_pred, y2_pred, y3_pred, y_gam_pred)\n\n# Combine the original data and predictions for consistent aes mapping\nplot_data <- data.frame(\n  t = rep(t_grid, 5),\n  Length = c(dat_vb$L_t_pred, dat_vb$y1_pred, dat_vb$y2_pred, dat_vb$y3_pred, dat_vb$y_gam_pred),\n  Model = rep(c(\"von Bertalanffy\", \"poly1\", \"poly2\", \"poly3\", \"GAM\"), each = length(t_grid))\n)\n\n# Plot the data and the fitted model\nggplot(dat_vb, aes(t, L_t)) +\n  geom_point(size = 2, shape = 1, colour = \"royalblue2\") +\n  geom_line(data = plot_data, aes(t, Length, colour = Model), alpha = 0.6) +\n  scale_color_manual(name = \"Model\",\n                     values = c(\"von Bertalanffy\" = \"black\", \"poly1\" = \"coral3\", \"poly2\" = \"deepskyblue3\", \"poly3\" = \"deeppink3\", \"GAM\" = \"seagreen3\")) +\n  xlab(\"Time (years)\") +\n  ylab(\"Length (cm)\") +\n  theme(legend.position = \"right\")\n```\n\nThere are a few practical considerations to keep in mind when choosing a suitable nonlinear (in shape) model. Sometimes different models can provide similar fits to the same data, but they may have different implications for the interpretation of the relationship between the variables. See for example @fig-combo. The plot shows growth rate data fitted with a first-, second- and third-order polynomial, a GAM, and a NLS von Bertalanffy model. To the untrained eye and inexperienced biologist, all models seem to provide a good fit to the data, but they do differ subtly in the shape of the fitted curve. The von Bertalanffy model is a saturating growth model (it reaches a plateau), while the polynomial models and the GAM are more flexible and can capture a wider range of shapes. The choice of model should be guided by the underlying biological or physical processes that generated the data and the research question you are trying to answer.\n\nSince you will often have to decide among polynomial regressions, nonlinear models, and GAMs, I'll outline some general guidelines to help you make an informed decision.\n\n-   **Linearity vs. Nonlinearity:** If the relationship between the variables is linear or can be adequately approximated by a polynomial function, polynomial regression is a suitable choice. Nonlinear models or GAMs may be more appropriate if the relationship is nonlinear and does not follow a specific polynomial form. In @fig-combo, it is obvious that the straight line model is not a good fit for the data, but the second- and third-order polynomial models, the GAM, and the von Bertalanffy model all provide better fits.\n\n-   **Complexity of the Relationship:** Polynomial regression is limited in its ability to capture complex nonlinear relationships, especially those with more bends, peaks, or valleys than a polynomial of order <3 (or even 4 at a push) can capture. Another consideration is the process the data represent: if it is inherently nonlinear according to a known function such as exponential growth or decay, seasonal sinusoidal patterns, or logistic growth, then nonlinear models or GAMs are more flexible and can capture a wider range of nonlinear responses. In @fig-combo, the von Bertalanffy model is a saturating growth model, which is a known biological process that can be captured by a nonlinear model. The 3rd-order polynomial model also seems to capture a saturating growth pattern, but it also somewhat influenced by the dip in the raw data around 12.5 years (in addition to some other nuances), but this is likely due to some random variation and is not part of the growth response.\n\n-   **Interpretability vs. Flexibility:** Polynomial regression provides coefficients that relate to the powers of the predictor variables, but the interpretation of the $\\beta$ parameters is not as intuitive as in a linear model of order 1. In contrast, nonlinear models and GAMs offer greater flexibility in capturing complex patterns. GAMs may lack direct interpretability of the coefficients, but the nonlinear model offers coefficients that can be interpreted in the context of the model's structure. In @fig-combo, the von Bertalanffy model has a clear biological interpretation (see @sec-vonbertalanffy), while the 3rd-order polynomial model and the GAM are more flexible and can capture a wider range of shapes (it follows the dips and peaks in the raw data closer). The 2nd-order polynomial does not fit the data as well at very low ages at 20 year, but it is still a better fit than the linear model.\n\n-   **Overfitting Concerns:** Polynomial regression with high-degree polynomials can lead to overfitting, especially when the model complexity exceeds the underlying data patterns. Nonlinear models and GAMs can also overfit if not properly regularised or constrained. These insights can be seen when we examine the summaries of the regression fits, and can be formally assessed using cross-validation or information criteria. In @fig-combo, the 3rd-order polynomial model seems to capture some of the random variation in the data, which may be an indication of overfitting. The GAM also seems to capture some of the random variation, but it is less pronounced than in the 3rd-order polynomial model.\n\n-   **Data Size and Complexity:** For small to moderate-sized datasets with complex nonlinear relationships, GAMs may be more suitable due to their flexibility and ability to capture intricate patterns. For simpler relationships or when interpretability is important, nonlinear regression (with mechanistically-informed parameters) may be preferred. These are not of concern in @fig-combo.\n\n-   **Model Complexity and Assumptions:** Polynomial regression assumes a specific polynomial form for the relationship, which may not hold in practice. Nonlinear models and GAMs are more flexible and do not always impose strict parametric assumptions (see @sec-assumptions), making them more robust to deviations from the assumed form. A detailed assessment of the model assumptions and the complexity of the relationship can help guide the choice of model. We need to add to this our biologist specialist knowledge to make the best choice.\n\n-   **Computational Considerations:** Polynomial regression is relatively simple to implement and computationally efficient, especially for low-degree polynomials. Nonlinear models and GAMs may require more computational resources, especially for large datasets or complex models. Not a concern for the models represented in @fig-combo.\n\n## Requirements and Assumptions {#sec-assumptions}\n\nPolynomial regression, nonlinear regression, and GAMs are built upon the principles of linear regression; therefore, the fundamental assumptions of normality and homoscedasticity of residuals usually still apply. Specifically, these models assume that the residuals are independent and identically distributed (i.i.d.), which implies that they are normally distributed with a constant variance (homoscedasticity). However, the specifics can vary depending on the model and the distribution of the response variable. Of course, there is also the requirement for the response variable to be continuous and independent. These assumptions help ensure that the error terms (residuals) in the model are well-behaved so that reliable inference and predictions can be obtained.\n\nNuances:\n\n-   **Polynomial Regression:** While a type of nonlinear regression,\n    polynomial models are still linear in their parameters. This means\n    that they are more bound to the classic regression assumptions and\n    can be more sensitive to violations.\n-   **GAMs:** Offer more flexibility in handling nonlinear\n    relationships. Depending on the distributions used for the outcome\n    variable and the link functions employed, GAMs can potentially relax\n    some of the strict normality assumptions.\n-   **Nonlinear Models in General:** Some truly nonlinear models (like\n    those based on exponential or logarithmic functions) may have\n    inherently different error structures and may not strictly require\n    the same assumptions of normality and homoscedasticity. However,\n    these models come with their own set of assumptions and\n    considerations.\n\nImportant considerations:\n\n-   **Diagnostic Checks:** Regardless of the model type, it's\n    *essential* to perform residual diagnostics to assess if assumptions\n    are met. Visualisations (e.g., histograms, Q-Q plots, residuals vs.\n    fitted plots) are well-known tools.\n-   **Transformations:** If violations of assumptions\n    are found, data transformation techniques (e.g., Box-Cox, log)\n    could be considered to improve model validity.\n-   **Generalised Linear Models (GLMs):** An important class of models\n    designed to handle various non-normal responses (e.g., count,\n    binary) while extending the linear modeling framework. GLMs are good alternative to both polynomial regression and GAMs in\n    certain contexts.\n-   **Mixed models:** Linear Mixed Models (LLMs), Generalised Linear Mixed Models (GLMMs), and Generalised Nonlinear Models (GNLMs) can be used to account for dependencies in the data, such as repeated measures or hierarchical\n    structures. GAMs also accommodate mixed data structures.\n\nThe rest of this chapter will focus on the practical aspects of fitting\npolynomial regression models and nonlinear regressions in R. GAMs will\nbe covered in a separate chapter due to their unique characteristics and\nimplementation details.\n\n## R Functions and Packages\n\n### Polynomial Regression\n\nTo fit a polynomial model in R, use the simple linear regression function `lm()` to fit the model. The purpose of `poly()` is to generate polynomial terms of a specified degree. The basic form is:\n\n```{r}\n#| eval: FALSE\n#| echo: TRUE\n\npoly_model <- lm(y ~ poly(x, degree = 2), data = data)\n```\n\nGLMs are a generalisation of ordinary linear regression that allows for the response variable to have\nnon-Gaussian error distributions such as one of the exponential family\ndistributions (e.g., binomial, Poisson, gamma). These distributions are\naccommodated via so-called link functions within the GLM framework. The\nmost common R function for fitting GLMs is `glm()`.\n\nMixed models that include random and fixed effects (see box 'Fixed and\nRandom Effects') are also available. These are necessary for the\nanalysis of data that have correlations within groups or hierarchies\n(e.g., repeated measures[^2] or the inclusion of grouped variables).\nCommonly used are `lmer()` for LLMs and `glmer()` for GLMMs. Both functions are in the\n**lme4** package. Another package that accommodates LLMs is **nlme** and\nits `lme()` function. It has somewhat different capabilities and syntax\ncompared to **lme4**.\n\n[^2]: Repeated measures are multiple observations taken on the same\n    subject or unit over time or under different conditions. Sometimes\n    this is called longitudinal data.\n\n::: callout-note\n## Fixed and Random Effects\n\nRandom effects and fixed effects are used in regression models to\naccount for different sources of variation in the data.\n\n*Fixed effects* are variables or factors that represent\nsources of variation that are of primary interest in the study or that\nhave a finite and fixed number of levels or categories. These effects\nare assumed to have an influence on the mean response.\nExamples of fixed effects include:\n\n-   Treatment groups in an experiment (e.g., fertiliser A, fertiliser B, control)\n-   Categorical variables (e.g., sex, age group, species)\n-   Continuous variables (e.g., time, temperature, concentration)\n\nThe coefficients associated with fixed effects are estimated and\ninterpreted as the primary effects of interest in the model.\n\n*Random effects* are variables or factors that represent\nsources of variation that are not of primary interest but need to be\naccounted for in the model. These effects are assumed to be randomly\nsampled from a larger population, and their levels are theoretically\ninfinite or too numerous to be modeled as fixed effects. Examples of\nrandom effects include:\n\n-   Subjects or individuals in a study (e.g., individual plants or animals)\n-   Clusters or groups (e.g., plots, aquaria, transects)\n-   Repeated measures or time points within subjects\n\nRandom effects are used to model the correlation or dependence among\nobservations within the same cluster, subject, or time series. They allow for\nsubject-specific or cluster-specific adjustments to the overall model,\naccounting for the fact that observations within the same group are more\nsimilar than observations from different groups.\n\nIn LMMs and GLMMs, both fixed and random effects are included. The fixed\neffects represent the primary effects of interest and the random\neffects account for the correlation or dependence within clusters or\nsubjects.\n:::\n\n### Nonlinear Regression\n\nIn R, nonlinear regressions can be performed using the `nls()` function\nin the **base** package. It uses iterative algorithms to minimise the\nresidual sum of squares and find the best-fit parameters for the\nuser-specified nonlinear model.\n\nThe `nls()` function is most frequently used to fit user-specified\nnonlinear functions. The basic syntax is:\n\n```{r}\n#| eval: FALSE\n#| echo: TRUE\n\nnls_model <- nls(y ~ f(x, theta1, theta2, ...), data = data,\n                 start = list(theta1 = value1, theta2 = value2, ...))\n```\n\nGNLMs extend nonlinear models by\nallowing the response variable to follow one of the exponential family\ndistributions, such as binomial, Poisson, or gamma, etc. This is done\nthrough a link function that relates the mean of the distribution to the\npredictors through the nonlinear model. GNLMs are fit using maximum\nlikelihood estimation, which is flexible enough to handle various types\nof error distribution and link functions. The **gnm** package rovides\nthe `gnm()` function designed for this purpose.\n\nFor data with dependencies within groups or hierarchies (such as in\nlongitudinal studies), NLMMs are available\nwithin `nlme()`. NLMMs incorporate fixed effects (associated with the\nnonlinear terms) and random effects (to account for correlation and\nvariation within groups).\n\n## Example: Algal Nutrient Uptake Kinetcis {#sec-ex1}\n\nWe can measure algal nutrient uptake rates using two types of experiments: multiple flask experiments and perturbation experiments. The fundamental concept underlying both methods is to introduce a known quantity of nutrients (termed the substrate) into a flask or a series of flasks and then measure the rate of nutrient uptake ($V$) at different substrate concentrations ($[S]$). We calculate the nutrient uptake rate as the change in nutrient concentration in the flask over a predefined time interval ($V = \\Delta [S]/\\Delta t$). Consequently, both experiments generate data that relate the nutrient uptake rate to the corresponding substrate concentration. The primary difference between the two methods lies in the experimental setup and the data analysis.\n\nIn the **multiple flask method**, we prepare a series of flasks, each containing a different initial concentration of the substrate nutrient to span the range typically encountered by the specimen in its natural environment. We then measure the nutrient uptake rate in *each individual flask* over a specific time period, for example by taking measurements at the start ($t=0$) and end ($t=30$ minutes) of the incubation. We calculate the change in substrate concentration over this time interval in each flask to determine the corresponding nutrient uptake rate. The resulting data from this method therefore consists of the different initial substrate concentrations used in each flask, paired with their respective measured nutrient uptake rates over the incubation period.\n\n<!-- ChatGPT query to simulate data for the experiment -->\n\n<!-- Please refer to the above text about the multiple flask experiment. Develop R code that will simulate data for seven replicate flasks participating in a multiple flask experiment. These are the conditions per each set of multiple flasks: -->\n\n<!--   - the concentrations of nutrient at $t=0$ are 50, 40, 30, 25, 20, 15, 12.5, 10, 7.5, 5, 2.5, and 0 $\\mu M$ nitrate -->\n<!--   - the disappearance of nitrate is measured at $t=0$ and $t=30$ minutes -->\n<!--   - there is ~1.5 g of seaweed per 150 ml incubation medium per flask -->\n<!--   - there are 7 replicate flasks per each concentration of nutrients -->\n\n<!-- Produce R code to simulate random data from the Michaelis-Menten relationship with a $V_{max} = 35.0 \\pm 1.8 \\, \\mu \\text{M} \\, N \\, g^{-1} \\, hr^{-1}$ and a $K_m = 5.6 \\pm 1.3 \\mu \\text{M} N$. The data should be normally distributed. Present this data in a table of $[S]$, which is the nutrient concentration at $t=0$ and the corresponding $V$. -->\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n\n# Define the model function\nmm_fun <- function(S, Vmax, Km) {\n  Vmax * S / (Km + S)\n}\n\ngenerate_data <- function(n_trt, n_rep, conc_vec, Km_vec,\n                          Vmax_vec, Km_vec_sd, Vmax_vec_sd) {\n  # Define the substrate concentrations\n  concentrations <- conc_vec\n  \n  # Create a dataframe with the specified structure\n  data <- expand.grid(\n    trt = paste(\"Treatment\", 1:n_trt),\n    S = concentrations,\n    rep = 1:n_rep\n  ) |> \n    arrange(trt, S, rep)\n  \n  # Add Km and Vmax values\n  set.seed(13)\n  data <- data |> \n    group_by(trt)  |> \n    mutate(\n      Km = rnorm(n(), mean = Km_vec[as.numeric(str_extract(trt, \"\\\\d+\"))], \n                 sd = Km_vec_sd[as.numeric(str_extract(trt, \"\\\\d+\"))]),\n      Vmax = rnorm(n(), mean = Vmax_vec[as.numeric(str_extract(trt, \"\\\\d+\"))], \n                   sd = Vmax_vec_sd[as.numeric(str_extract(trt, \"\\\\d+\"))])\n    ) |> \n    ungroup() |> \n    mutate(V = mm_fun(S, Vmax, Km),\n           rep = as.factor(rep),\n           trt = as.factor(trt)) |> \n    select(-Km, -Vmax)\n  \n  return(data)\n}\n\n# Example usage\nconc_vec <- c(0, 0.1, 0.5, 2, 5, 7.5, 10, 12.5, 15, 17.5, 20, 25, 30)\nn_trt <- 3  # Number of treatment levels\nn_rep <- 5  # Number of replicates per treatment\nKm_vec <- c(10, 8, 7)  # Km means for each treatment\nVmax_vec <- c(50, 40, 20)  # Vmax means for each treatment\nKm_vec_sd <- c(1.2, 1.3, 1.2)  # Km SD for each treatment\nVmax_vec_sd <- c(0.7, 1.3, 0.9)  # Vmax SD for each treatment\n\n# Generate the data for one treatment\nmf_data <- generate_data(n_trt = 1, n_rep, conc_vec, Km_vec,\n                         Vmax_vec, Km_vec_sd, Vmax_vec_sd)\n```\n\nThe **perturbation method** uses a single flask to which we add a high initial concentration of the substrate nutrient, set at a level that is ecologically meaningful and relevant to the study system. Instead of using multiple flasks, we measure the change in the remaining substrate concentration at multiple time points within this *same flask*, for example by taking samples every 10 or 20 minutes until all the substrate is depleted, say at 120 minutes. We calculate the change in substrate concentration between each successive time point to determine the corresponding nutrient uptake rate over that time interval. The resulting data, therefore, consist of a time series of substrate concentrations at each measurement time point, paired with the nutrient uptake rates calculated over the periods between those time points.\n\nThe important differences between the multiple flask and perturbation experiments are summarised in @tbl-diffs.\n\n| Feature            | Multiple Flask Experiments                 | Perturbation Experiments                       |\n|--------------------|--------------------------------------------|------------------------------------------------|\n| Experimental Setup | Multiple flasks, each with different $[S]$ | Single flask with initial high $[S]$           |\n| Data Independence  | Data points are independent                | Data points are correlated (repeated measures) |\n| Analysis           | Nonlinear least squares regression (NLS)  | Nonlinear mixed model (NLMM)                  |\n| R Function         | `nls()`                                    | `nlme::nlme()`                                 |\n\n: Key differences between multiple flask and perturbation experiments. {#tbl-diffs}\n\nOur choice between multiple flask and perturbation experiments depends on our research questions and experimental constraints. In both methods, we must consider all sources of error and variability, such as measurement error, the type of nutrient, the physiological state of the alga, the light intensity, the experimental temperature, and other variables that might affect the uptake response.\n\nWe apply the Michaelis-Menten model (@eq-mm) to data from multiple flask and perturbation experiments to characterise nutrient uptake. Applied to algae, this model assumes an irreversible uptake process that saturates at high substrate concentrations. It effectively quantifies key characteristics of the nutrient uptake system, including the maximum uptake rate and the algae's affinity for the nutrient.\n\nWe use the `nls()` function to fit the Michaelis-Menten model to the data from multiple flask experiments. For the perturbation experiment, things are a bit more complicated. This method includes dependent data points because the measurements are taken from the same flask at different times, introducing a correlation between observations. This violates the independence assumption required for standard regression models. To accurately analyse these data, I recommend a *nonlinear mixed-effects model* implemented in the `nlme()` function. Mixed-effects models account for fixed effects (overall trends across all observations) and random effects (variations specific to individual experimental units, in this case, time points within the same flask). This helps handle the correlation between repeated measures and produces reliable estimates of the uptake dynamics within the flask. \n\nThe Michaelis-Menten equation is given by:\n\n$$V_i = \\frac{V_{max} \\cdot [S_i]}{K_m + [S_i]} + \\epsilon_i$$ {#eq-mm}\n\nWhere:\n\n-   $V_i$ is the uptake rate at the $i$-th observation,\n-   $V_{max}$ is the maximum nutrient uptake rate achieved,\n-   $[S_i]$ is the substrate concentration at the $i$-th observation,\n-   $K_m$ is the Michaelis constant, which represents the substrate concentration at which the uptake rate is half of $V_{max}$, and\n-   $\\epsilon_i$ is the error term at the $i$-th observation. and\n\nThe two parameters of the Michaelis-Menten model are rooted in theory and have ecophysiological interpretations. $K_m$ is a measure of the alga's affinity for the nutrient and is determined by the kinetic constants governing the formation and dissociation of the enzyme-substrate complex responsible for taking up the nutrient; lower values indicate a higher affinity. $V_{max}$ represents the maximum capacity of the alga to utilise the nutrient.\n\n### Hypothesis Testing and the Michaelis-Menten Model\n\n#### Linear vs. Michaelis-Menten Model {#sec-linear-vs-mm}\n\nOften, we aim to understand the relationship between two variables but we may not yet know which model best describes this relationship. For instance, in algal nutrient uptake kinetics, both a linear model and a nonlinear Michaelis-Menten model can be used to describe the relationship between nutrient uptake rate and substrate concentration. Both models are valid but they have different interpretations and unique ecophysiological implications. The choice between the two models depends on the biological system.\n\n- **Linear models** indicate that the uptake process is inherently unsaturated, such as with the uptake of ammonium. In this case, the uptake rate continues to increase linearly with substrate concentration.\n- The **Michaelis-Menten model** suggests that the uptake rate eventually saturates as the substrate concentration increases, which is often the case with nitrate.\n\nThe key question is: How do we decide which model fits our data best?\n\nThe simplest way is to visually inspect the scatter of points on a plot of the $V$ vs. $[S]$ data, which would be part of any exploratory data analysis. If the data exhibit a clear saturation pattern, where the uptake rate levels off at high substrate concentrations, the Michaelis-Menten model is likely to provide a better fit. Conversely, if the data show a linear relationship over the observed range of substrate concentrations, the linear model may be more appropriate.\n\nIt is also important to consider the biological plausibility of the models. If there is prior knowledge or theoretical reasons to expect a saturating relationship between the uptake rate and substrate concentration, the Michaelis-Menten model may be more appropriate, even if both models provide a similar fit to the data.\n\nConfirmation can be obtained by fitting both models to our data and comparing their performance using statistical measures such as the sum of squared residuals (SSR), Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), or log-likelihood test.\n\nTo proceed with the statistical approach, we must first set hypotheses such as these to compare the models:\n\n**$H_0$:** The Michaelis-Menten model does not provide a better fit to the data than a simple linear model.\n\nIn other words, we suggest with the null hypothesis that the relationship between nutrient uptake rate and the substrate concentration is adequately described by a linear model rather than the Michaelis-Menten nonlinear model. The implication is that the uptake rate increases linearly with substrate concentration, without saturation.\n\n**$H_a$:** The Michaelis-Menten model provides a significantly better fit to the data than a simple linear model.\n\nWith the alternative hypothesis we propose that the relationship between the nutrient uptake rate and the substrate concentration is best described by the nonlinear Michaelis-Menten model, so the uptake rate initially increases with substrate concentration but eventually levels off, indicating saturation.\n\nTo test these hypotheses, we can:\n\n1. Fit both the Michaelis-Menten model and a linear model to the data.\n2. Compare the goodness-of-fit of both models using statistical measures such as the SSR, AIC, or BIC.\n3. Perform a model comparison test (such as an *F*-test or likelihood ratio test) to determine if the improvement in fit provided by the Michaelis-Menten model is statistically significant compared to the linear model.\n\nIn the above scenario, which is to decide among the linear and Michaelis-Menten models, hypotheses concerning the parameters of the models are not directly tested as they are not really of interest (except for estimating their magnitude, perhaps). Instead, the focus is on the overall goodness-of-fit of the models to the data.\n\n#### Comparing Two Michaelis-Menten Models {#sec-mm-comparison}\n\nHere, we may be interested in testing whether the parameters $V_\\text{max}$ and $K_m$ differ from some hypothesised values or across different experimental conditions.\n\nIn the first instance, we can set up the hypotheses as follows:\n\n**$H_0:$** $V_\\text{max} = V_\\text{max}^*$ and $K_m = K_m^*$\n\nwhere $V_\\text{max}^*$ and $K_m^*$ are the hypothesised values (or values from a reference condition) for the maximum uptake rate and Michaelis constant, respectively.\n\n**$H_a:$** $V_\\text{max} \\neq V_\\text{max}^*$ or $K_m \\neq K_m^*$\n\nThis alternative hypothesis states that at least one of the parameters ($V_\\text{max}$ or $K_m$) differs from the hypothesised value.\n\nIf the experiment involves different experimental conditions or treatments, we can modify the hypotheses accordingly. For example, if we want to test whether the parameters differ between two experimental conditions (A and B), the hypotheses could be:\n\n$H_0: V_\\text{max}^A = V_\\text{max}^B$ and $K_m^A = K_m^B$\n\n$H_a: V_\\text{max}^A \\neq V_\\text{max}^B$ or $K_m^A \\neq K_m^B$\n\nIn this case, the null hypothesis states that the maximum uptake rate and Michaelis constant are the same for both experimental conditions, while the alternative hypothesis states that at least one of the parameters differs between the two conditions.\n\nAfter fitting the Michaelis-Menten model to the data using the `nls()` or `nlme()` functions in R, appropriate statistical tests (e.g., likelihood ratio tests, Wald tests, or other model comparison techniques) can be performed to evaluate the hypotheses and determine whether the parameter estimates significantly differ from the hypothesised values or across experimental conditions.\n\n### Multiple Flask Experiment\n\n#### Fitting a single model (NLS) {#sec-mf-single}\n\nTo demonstrate fitting a nonlinear model to $V$ vs $[S]$ data produced from a multiple flask experiment, I simulate data across a range of substrate concentrations. We then fit the model to the data using the `nls()` function in R. The dataset consists of five replicate flask sets ($n=5$) for each of 13 substrate concentrations. Each set therefore results in independently estimated uptake rates for the initial nutrient concentrations. The dataset is shown in @tbl-mf1, and a plot of $V$ as a function of $[S]$ is shown in @fig-mf1. \n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"Simulated data for a multiple flask experiment on an alga (showing only the top and bottom three rows).\"\n#| label: tbl-mf1\n\nmf_data |> \n  select(rep, S, V) |>\n  mutate(V = round(V, 2)) |>\n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n  cols_align(\n    align = \"center\",\n    columns = \"rep\") |> \n  cols_label(rep = html(\"Replicate flask\"),\n             S = html(\"[S]\"),\n             V = html(\"V\"))\n```\n\n<!-- ```{r} -->\n<!-- #| echo: true -->\n\n<!-- # html only -->\n<!-- DT::datatable(mf_data, rownames = FALSE, options = list(pageLength = 5)) -->\n<!-- ``` -->\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of $V$ as a function of $[S]$ for a multiple flask experiment involving seven replicate flask sets.\"\n#| label: fig-mf1\n#| fig.align: center\n#| fig-pos: \"t\"\n\nggplot(mf_data, aes(x = S, y = V, group = rep)) +\n  geom_jitter(size = 2, shape = 1, colour = \"royalblue2\", width = 0.08) +\n  labs(x = TeX(\"S [$\\\\mu$M]\"),\n       y = TeX(\"V [$\\\\mu$M $g^{-1}_{dry}$ $h^{-1}$]\")) +\n  theme(legend.position = \"none\")\n```\n\nIn @fig-mf1, there is a clear indication that the uptake rates plateau at higher substrate concentrations, suggesting that fitting a Michaelis-Menten model is advisable. Later, I will compare this with a linear model for completeness. A central feature of this dataset is that the data were collected independently, with each flask set representing a separate experimental unit. There is no correlation between flasks within a set, and no correlation across the initial substrate concentrations. Consequently, the assumption of independence is fully met, allowing the simplest expression of the `nls()` function to be used to fit the Michaelis-Menten model to the data.\n\nThe Michaelis-Menten model is fit to the data using the `nls()` function in R. It is specified as:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Define the model function\nmm_fun <- function(S, Vmax, Km) {\n  Vmax * S / (Km + S)\n}\n\n# Fit the nonlinear model Michaelis-Menten model\nnls_mod <- nls(V ~ mm_fun(S, Vmax, Km), # <1>\n            data = mf_data,\n            start = c(Vmax = 30, Km = 5)) # <2>\n```\n1. The model formula specifies the Michaelis-Menten equation, with `V` as the dependent variable on the left-hand side and `S` as the independent variable on the right. The model parameters `Vmax` and `Km` will be estimated when fitting the model.\n2. The `start` argument provides initial values for the model parameters. The `Vmax` and `Km` parameters are estimated by minimising the sum of squared residuals between the observed and predicted values of `V`. The `nls()` function uses an iterative process to find the best-fitting values for these parameters, and the starting values improve the success of model convergence.\n\nHere is the model summary:\n\n```{r}\nsummary(nls_mod)\n```\n\nThe above output provides the estimates for $V_{\\max}$ and $K_m$, along with their standard errors, *t*-values, and *p*-values:\n\n-   The estimated maximum uptake rate ($V_{\\max}$) is approximately 49.24 $\\mu M N g^{-1} hr^{-1}$ and the small standard error associated with this parameter (0.89) indicates a precise estimate. The *t*-value (55.18) is very high, and the corresponding *p*-value is extremely small (<0.0001), indicating that $V_{\\max}$ is highly significantly different from zero.\n-   The estimated Michaelis constant ($K_m$) is approximately 9.50 $\\mu M$ and its standard error (0.45) is also small, suggesting a precise estimate. The *t*-value (21.22) and the very small *p*-value (<0.0001) indicate that $K_m$ is also highly significantly different from zero.\n-   The residual standard error is 1.10 on 63 degrees of freedom, indicating the average deviation of the observed uptake rates from the fitted model values.\n-   The model converged in 4 iterations with a very small convergence tolerance, indicating a good fit and stability of the model.\n\n::: {.callout-tip}\n## Results\n\nThe Michaelis-Menten parameters, maximum uptake rate ($V_{\\max}$) and half-saturation constant ($K_m$), were estimated using nonlinear regression (@fig-mf2). The estimated $V_{\\max}$ was 49.24 $\\mu$M N g$^{-1}$ hr$^{-1}$ (SE = 0.89, $t = 55.18$, $p < 0.0001$), and the estimated $K_m$ was 9.50 $\\mu$M (SE = 0.45, $t = 21.22$, $p < 0.0001$). Both parameters were significantly different from zero. The model fit was good, converging in 3 iterations with a residual standard error of 1.10 (63 degrees of freedom).\n:::\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of the Michaelis-Menten model fitted to the data in @fig-mf1. The vertical and horizontal dashed lines indicate the estimated $K_m$ and $V_{max}$ values, respectively.\"\n#| label: fig-mf2\n#| fig-align: center\n\n# Extract coefficients\ncoefficients <- coef(nls_mod)\nVmax_est <- coefficients[\"Vmax\"]\nKm_est <- coefficients[\"Km\"]\n\n# Creating a sequence for smooth curve\nconc_seq <- seq(min(mf_data$S), max(mf_data$S), length.out = 100)\npredicted_V <- (Vmax_est * conc_seq) / (Km_est + conc_seq)\n\n# Plot\nggplot(mf_data, aes(x = S, y = V)) +\n  geom_jitter(aes(colour = \"Data Points\", width = 0.08),\n    shape = 1, size = 2, colour = \"royalblue2\") +\n  geom_line(aes(x = conc_seq, y = predicted_V),\n            data = data.frame(S = conc_seq, V = predicted_V),\n            color = \"black\", size = 0.8) +\n  geom_vline(xintercept = Km_est, linetype = \"dashed\",\n             color = \"hotpink1\", size = 0.4, show.legend = TRUE) +\n  geom_hline(yintercept = Vmax_est, linetype = \"dashed\",\n             color = \"hotpink1\", size = 0.4, show.legend = TRUE) +\n  labs(x = TeX(\"S [$\\\\mu$M]\"),\n       y = TeX(\"V [$\\\\mu$M $g^{-1}_{dry}$ $h^{-1}$]\")) +\n  # theme_minimal() +\n  theme(legend.position = \"none\")\n```\n\nThe text is clear and concise, but here are a few minor changes for improved readability and precision:\n\n**Assumption tests** Since these data are simulated and drawn from a normal distribution with equal variances across the range of substrate concentrations, the assumptions of homoscedasticity and normality of residuals are inherently met. In this example, we fit the model solely to obtain estimates of the Michaelis-Menten parameters, rather than to make predictions, inferences, or calculate confidence intervals. Therefore, assumption tests are not critical at this stage. We will formally test assumptions in @sec-mf-treatments when comparing the effects of experimental treatments on kinetic parameters.\n\n#### Is the Michaelis-Menten model a better fit than a linear model?\n\nIn @sec-linear-vs-mm, we pose a hypothesis that requires comparing a linear model to a Michaelis-Menten model fitted to the same data. @fig-mf2 indicates the nonlinear model indeed provides a very good fit but in some situations this distinction may be less clear and require verification. Let us fit a linear model to the above data and compare it to the Michaelis-Menten model.\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Fit the linear model\nlm_mod <- lm(V ~ S, data = mf_data)\n\nsummary(lm_mod)\n```\n\nThe linear model summary shows that the slope and intercept are significantly different from zero, indicating a good fit. The $R^2$ value is 0.86, which is very high, suggesting that the linear model explains 86% of the variance in the data. The residual standard error is 5.13, which is higher than the Michaelis-Menten model, indicating a worse fit. We can test the difference between the models formally by examining the AIC, BIC, or SSR, and the likelihood ratio test.\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nAIC(lm_mod, nls_mod)\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nBIC(lm_mod, nls_mod)\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Calculate the sum of squared residuals (SSR)\nsum(residuals(lm_mod)^2)\nsum(residuals(nls_mod)^2)\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nanova(lm_mod, nls_mod)\n```\n\nThe AIC, BIC, and SSR values for the Michaelis-Menten model are lower than those for the linear model. Low is good, and we conclude that the Michaelis-Menten model is a better fit. The likelihood ratio test also shows that the Michaelis-Menten model is significantly better than the linear model (d.f. = 1, $F=375.43$, $p<0.0001$). Therefore, we can conclude that the Michaelis-Menten model is the most appropriate model for these data and that the rate of nutrient uptake by the seaweed (in this example) is saturated at high nutrient concentrations.\n\n#### Comparing treatment effects (NLS and NLMM) {#sec-mf-treatments}\n\nExperiments are seldom as simple as the one above. To develop our example further, consider an experiment designed to assess whether an experimental treatment, such as light intensity or seawater temperature, affects the nutrient uptake rate of a seaweed. It is biologically plausible to expect that each treatment will result in unique $V_{max}$ and/or $K_m$ values. For example, we know that the uptake rate of nitrate (\\ce{NO3-}) might increase at higher light intensities and higher temperatures. Therefore, our hypothesis for this experiment is that the nutrient uptake kinetics of the seaweed is influenced by the treatment, as more formally stated in @sec-mm-comparison. To test this hypothesis, we fit a Michaelis-Menten model so that it allows estimates of $V_{max}$ and $K_m$ to vary among treatment groups.\n\nThe data for a multiple flask experiment with a treatment effect comprised of three levels are provided in @tbl-mf2. Except for a new variable (treatment), the data are in all other respects identical to those in @sec-mf-single. \n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"Simulated data with three treatment levels for a multiple flask experiment on a seaweed species.\"\n#| label: tbl-mf2\n\nset.seed(13)\nmf_data2 <- generate_data(n_trt = 3, n_rep, conc_vec, Km_vec,\n                          Vmax_vec, Km_vec_sd, Vmax_vec_sd)\n\nmf_data2 |> \n  select(trt, rep, S, V) |>\n  mutate(V = round(V, 2)) |>\n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n  cols_align(\n    align = \"center\",\n    columns = c(\"trt\", \"rep\")) |> \n  cols_label(trt = html(\"Treatment\"),\n             S = html(\"[S]\"),\n             rep = html(\"Replicate flask\"),\n             V = html(\"V\"))\n```\n\n**Option 1** The `nls()` function in R does not handle factor variables directly, which means we cannot include the treatment variable as a factor in the model formula. To address this limitation, we fit the `nls()` model separately for each treatment group. This approach allows each treatment to have its own $V_{\\max}$ and $K_m$ values, effectively accommodating the variability in the Michaelis-Menten parameters across treatments.\n\nIn addition to fitting separate models for each treatment, we also fit a global model (a null model) to all the data. The global model assumes that the effect of the experimental treatment is negligible, meaning that all treatments share the same $V_{\\max}$ and $K_m$. This global fit serves as a baseline for comparison.\n\nTo determine whether the Michaelis-Menten parameters significantly differ among the treatment groups, we perform a likelihood ratio test. The likelihood ratio test compares the fit of the global model (where parameters are shared across treatments) to the combined fit of the separate models (where parameters vary by treatment). The test statistic is the difference in the log-likelihoods of the two models, which follows a $\\chi^2$ distribution with degrees of freedom equal to the difference in the number of parameters between the two models.\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Fit separate models\nseparate_models <- mf_data2 |>\n  group_by(trt) |>\n  nest() |>\n  mutate(model = map(data, ~nls(V ~ mm_fun(S, Vmax, Km),\n                                data = .x,\n                                start = list(Vmax = 40, Km = 10))))\n\n# Extract model summaries of separate models\nmodel_summaries <- separate_models|>\n  mutate(summary = map(model, broom::tidy))\n\n# Display summaries of separate models\nmodel_summaries |>\n  select(trt, summary) |>\n  unnest(summary)\n\n# Fit the global model\nglobal_model <- nls(V ~ mm_fun(S, Vmax, Km),\n                    data = mf_data2,\n                    start = list(Vmax = 45, Km = 9))\n\n# Extract log-likelihoods and degrees of freedom\nlogLik_global <- logLik(global_model)\ndf_global <- attr(logLik_global, \"df\")\n\n# Combined log-likelihoods and degrees of freedom\nlogLik_separate <- sum(sapply(separate_models$model, logLik))\ndf_separate <- sum(sapply(separate_models$model,\n                          function(m) attr(logLik(m), \"df\")))\n\n# Perform the likelihood ratio test\nlrt_stat <- 2 * (logLik_separate - logLik_global)\np_value <- pchisq(lrt_stat, df = df_separate - df_global,\n                  lower.tail = FALSE)\n\n# Display results\ncat(\"Global model log-likelihood:\", logLik_global, \"\\n\")\ncat(\"Separate models log-likelihood:\", logLik_separate, \"\\n\")\ncat(\"Degree of freedom:\", df_separate - df_global, \"\\n\")\ncat(\"Likelihood ratio test statistic:\", lrt_stat, \"\\n\")\ncat(\"p-value:\", p_value, \"\\n\")\n```\n\nThe results of the likelihood ratio test indicate whether the variation in $V_{\\max}$ and $K_m$ among the treatments is statistically significant. If the test is significant, it suggests that the Michaelis-Menten parameters differ across treatments. We interpret the results as follows:\n\n- The log-likelihood value (-620.7498) for the global model, indicating the fit of the model with shared parameters.\n- The combined log-likelihood value (-313.1862) for the separate models, indicating the fit of the models with parameters varying by treatment.\n- The calculated test statistic (615.1273) for the likelihood ratio test on 6 degrees of freedom.\n- The *p*-value of the test is less than 0.0001 and provides strong evidence that $V_{\\max}$ and $K_m$ differ significantly among the treatment groups.\n\n::: {.callout-tip}\n## Results\n\nThe analysis aimed to determine if the Michaelis-Menten parameters $V_{\\max}$ and $K_m$ significantly differed among the three experimental treatments. This was evaluated by fitting a global model with shared $V_{\\max}$ and $K_m$ values across all treatments and comparing it to a model allowing separate $V_{\\max}$ and $K_m$ estimates for each treatment. The log-likelihood value for the global model, which assumes shared $V_{\\max}$ and $K_m$ values across all treatments, was -620.75, indicating the fit of the model with common parameters. In contrast, the combined log-likelihood value for the separate models, which allow $V_{\\max}$ and $K_m$ to vary by treatment, was -313.19, indicating the fit of the models with treatment-specific parameters. The calculated test statistic for the likelihood ratio test was 615.13 (d.f. = 6, *p* < 0.001), providing strong evidence that the Michaelis-Menten parameters $V_{\\max}$ and $K_m$ differ significantly among the treatment groups. Consequently we estimate a $V_{max}$ of 49.2 ± 0.96, 39.4 ± 0.87 $\\mu$M N g$^{-1}$ hr$^{-1}$ and 18.9 ± 0.65 and a $K_m$ of 9.55 ± 0.48, 7.54 ± 0.48 and 5.50 ± 0.64 $\\mu$M for treatments 1, 2 and 3 respectively.\n:::\n\n**Option 2** If Option 1 seems cumbersome, we can fit a NLMM using the **nlme** package instead. This package allows us to fit a mixed model with random effects for each treatment group. In this model, the fixed effects are the Michaelis-Menten parameters $V_{\\max}$ and $K_m$, which vary by treatment, while the random effects are the replicate-specific intercepts. Thus, the cumbersome `nls()` formulation is replaced by the compact but more fiddly `nlme()` model specification. Pick your poison. The model is specified as follows:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Fit the model with the same parameters for both treatments\n# Starting values for Vmax and Km\nstart_vals <- c(Vmax = 50, Km = 10)\nglobal_model <- nlme(\n  V ~ mm_fun(S, Vmax, Km),\n  data = mf_data2,\n  fixed = Vmax + Km ~ 1, # <1>\n  random = Vmax ~ 1 | trt/rep, # <2>\n  start = start_vals\n)\n\n# Fit the model with parameters varying by treatment\n# Starting values for Vmax and Km for each treatment\nstart_vals <- c(Vmax1 = 50, Vmax2 = 40, Vmax3 = 30,\n                Km1 = 10, Km2 = 10, Km3 = 5) # <3>\nseparate_models <- nlme(\n  V ~ mm_fun(S, Vmax, Km),\n  data = mf_data2,\n  fixed = list(Vmax ~ trt, Km ~ trt), # <4>\n  random = Vmax ~ 1 | trt/rep,\n  start = start_vals\n)\n```\n1. The fixed effects indicate that both $V_{\\max}$ and $K_m$ are fixed (do not vary) across treatments.\n2. The random effects indicate that the $V_{\\max}$ parameter varies by treatment and replicate.\n3. The starting values for the $V_{\\max}$ and $K_m$ parameters are specified for each treatment group. Because we are now fitting a separate model for each treatment, we need to provide starting values for each treatment.\n4. The fixed effects now indicate that both $V_{\\max}$ and $K_m$ vary by treatment.\n\nThe estimated parameters for the global model and the separate models can be extracted using the `summary()` function:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Extract the estimated parameters (abbreviated output)\n# summary(global_model) # for verbose output\nsummary(global_model)$tTable\n```\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Extract the estimated parameters (abbreviated output)\n# summary(separate_models) # for verbose output\nsummary(separate_models)$tTable\n```\n\nThe log-likelihood ratio test can then easily be performed using the `anova()` function, which compares the global model with the separate models:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nanova(global_model, separate_models)\n```\n\nAgain, the results of the likelihood ratio test indicate that the variation in $V_{\\max}$ and $K_m$ among the treatments is statistically significant (log-likelihood = 45.20, *p* < 0.0001). The AIC values can also be used to compare the models, with lower AIC values indicating a better fit. In this case, the separate models have a lower AIC value (644.28), suggesting that they provide a better fit to the data than the global model (681.479). The data fitted with the global and separate models is presented in @fig-mf3.\n\n**Assumption tests** To complete our example comparing the Michaelis-Menten parameters among treatments, let's confirm the assumptions by examining the residuals. Residuals in nonlinear regression models have the same interpretation as in linear models, and therefore, the assumption tests available for linear models can be applied here as well. For instance, we can use the `shapiro.test()` function to check the normality of residuals, as shown below, and the `hist()` and `plot()` functions for diagnostic plots. In real-world data, it is advised to verify these assumptions before accepting the analysis and drawing conclusions from the nonlinear regression model. Let's check the normality of residuals for each treatment and plot the residuals to check for normality and homoscedasticity (@fig-mf-assump).\n\n```{r}\n#| echo: true\n#| eval: true\n#| messages: false\n#| warning: false\n\n# Add residuals and fitted information to the data frame\nmf_data2$residuals_separate <- residuals(separate_models)\nmf_data2$fitted_values_separate <- fitted(separate_models)\n\n# Perform the Shapiro-Wilk test for each treatment\nshapiro.test(mf_data2$residuals_separate[mf_data2$trt == \"Treatment 1\"])\nshapiro.test(mf_data2$residuals_separate[mf_data2$trt == \"Treatment 2\"])\nshapiro.test(mf_data2$residuals_separate[mf_data2$trt == \"Treatment 3\"])\n```\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| eval: true\n#| messages: false\n#| warning: false\n#| fig.cap: \"Histograms (A) of residuals and plots of residuals vs. the fitted values (B) for residuals for the three treatments in the multiple-flask experiment.\"\n#| label: fig-mf-assump\n#| fig-align: center\n\n# Make histograms with frequency polygons overlain\n# for visual comfirmation (optional)\nplt1 <- ggplot(mf_data2, aes(x = residuals_separate)) +\n  geom_histogram(aes(y = ..density..), bins = 10,\n                 fill = \"lightblue\", colour = \"lightblue\") +\n  geom_density(alpha = 0.5) +\n  facet_wrap(~ trt) +\n  labs(x = \"Residuals\", y = \"Density\")\n\nplt2 <- ggplot(mf_data2, aes(x = fitted_values_separate, y = residuals_separate)) +\n  geom_point(colour = \"royalblue2\", shape = 1) +\n  geom_smooth(method = \"gam\", se = FALSE,\n              linewidth = 0.6, colour = \"indianred2\") +\n  facet_wrap(~trt) +\n  theme(legend.position = \"none\") +  # Turn off the legend\n  labs(x = \"Fitted Values\",\n       y = \"Residuals\")\n\nggarrange(plt1, plt2, nrow = 2, labels = c(\"A\", \"B\"))\n```\n\nThe Shapiro-Wilk test results indicate that the residuals are normally distributed for Treatments 1 and 2 (*p* > 0.05) but not for Treatment 3 (*p* < 0.05). However, the histograms in @fig-mf-assump show that the residuals are approximately normally distributed for all treatment groups, with the median roughly in the middle of the distribution in each case. This apparent discrepancy can be explained by the sensitivity of the Shapiro-Wilk test to sample size. With large sample sizes, even minor deviations from normality can be detected as statistically significant. In situations such as this one, I suggest that it is important to consider the sample size and visual inspection of the data when interpreting the results of normality tests. Here, given the relatively large sample size and the visual assessment of the histograms, we can reasonably conclude that the residuals are approximately normally distributed for all treatment groups. \n\nAnother normality tests such as the Kolmogorov-Smirnov (K-S) test might be less sensitive to sample size and could be considered for comparison. The K-S test is a non-parametric statistical test that is used to determine if a sample comes from a specific probability distribution. Here I use it to test if a sample follows a normal distribution (`pnorm`), but it can also be used to test against other theoretical distributions or to compare two empirical distributions. The K-S test can be performed using the `ks.test()`, as shown below.\n\n```{r}\n#| echo: true\n#| eval: true\n#| messages: false\n#| warning: false\n\nperform_ks_test <- function(data, treatment) {\n  ks.test(data$residuals_separate[data$trt == treatment], \"pnorm\", \n          mean = mean(data$residuals_separate[data$trt == treatment]), \n          sd = sd(data$residuals_separate[data$trt == treatment]))\n}\n\n# Perform the test for each treatment group\nperform_ks_test(mf_data2, \"Treatment 1\")\nperform_ks_test(mf_data2, \"Treatment 2\")\nperform_ks_test(mf_data2, \"Treatment 3\")\n```\n\nWe see that the K-S test indicates that the residuals are normally distributed for all treatment groups (*p* > 0.05). As already noted, this test is less sensitive to sample size than the Shapiro-Wilk test, and the results are consistent with the visual assessment of the histograms.\n\nWe should also check for homoscedasticity (here I use the Levene test) and a plot of residuals versus fitted values. \n\n```{r}\n#| echo: true\n#| eval: true\n#| messages: false\n#| warning: false\n\n# Perform the Levene test\ncar::leveneTest(residuals_separate ~ trt, data = mf_data2)\n```\n\nThe Levene test shows that the variances are the same across the three treatments and this is confirmed by the plot of residuals against the fitted values in @fig-mf-assump. \n\n::: {.callout-tip}\n## Results\n\nMichaelis-Menten models were fitted to nutrient uptake data across three experimental treatments to investigate the effects of the treatments on seaweed nutrient kinetics. A global model, assuming shared kinetic parameters ($V_{max}$ and $K_m$) across all treatments, was compared to a model with separate parameters for each treatment. The model allowing treatment-specific parameters (AIC = 644.3) provided a significantly better fit to the data than the global model (AIC = 681.5), a finding confirmed by the log-likelihood test (log-likelihood ratio = 45.20, d.f. = 4, *p* < 0.0001). As the assumption tests do not indicate any cause for concern regarding the distribution of residuals, we conclude that the experimental treatments significantly influenced the nutrient uptake kinetics of the seaweed (@fig-mf3).\n\nSpecifically, all three treatments exhibited unique combinations of $V_{max}$ and $K_m$ values (Treatment 1: $V_{max}$ = 49.2, $K_m$ = 9.5; Treatment 2: $V_{max}$ = 39.3, $K_m$ = 7.5; Treatment 3: $V_{max}$ = 19.0, $K_m$ = 5.5). These findings support the hypothesis that nutrient uptake kinetics in this seaweed species are sensitive to environmental perturbations.\n:::\n\n```{r, fig.width=c(6,5),fig.asp=0.5,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of the Michaelis-Menten model fitted to the data in @tbl-mf2. Fits are provided for the separate models and the global model.\"\n#| label: fig-mf3\n#| fig-align: center\n#| fig-pos: \"t\"\n\n# Extract coefficients for shared model\nVmax_est_shared <- global_model$coefficients$fixed[\"Vmax\"]\nKm_est_shared <- global_model$coefficients$fixed[\"Km\"]\n\n# Extract coefficients for separate models\ncoeffs <- separate_models$coefficients$fixed\nVmax_est_separate <- coeffs[\"Vmax.(Intercept)\"] +\n  c(0, coeffs[paste0(\"Vmax.trtTreatment \", 2:3)])\nKm_est_separate <- coeffs[\"Km.(Intercept)\"] +\n  c(0, coeffs[paste0(\"Km.trtTreatment \", 2:3)])\n\n# Assign individual variables for clarity\nVmax_est_separate_1 <- Vmax_est_separate[1]\nVmax_est_separate_2 <- Vmax_est_separate[2]\nVmax_est_separate_3 <- Vmax_est_separate[3]\nKm_est_separate_1 <- Km_est_separate[1]\nKm_est_separate_2 <- Km_est_separate[2]\nKm_est_separate_3 <- Km_est_separate[3]\n\n# Creating a sequence for smooth curve\nconc_seq <- seq(min(mf_data2$S), max(mf_data2$S), length.out = 100)\n\n# Predicting V values for shared and separate models\npredicted_V <- lapply(\n  list(shared = list(Vmax = Vmax_est_shared, Km = Km_est_shared),\n       trt1 = list(Vmax = Vmax_est_separate_1, Km = Km_est_separate_1),\n       trt2 = list(Vmax = Vmax_est_separate_2, Km = Km_est_separate_2),\n       trt3 = list(Vmax = Vmax_est_separate_3, Km = Km_est_separate_3)),\n  function(params) {\n    (params$Vmax * conc_seq) / (params$Km + conc_seq)\n  }\n)\n\n# Creating the dataframe\npred_df <- data.frame(\n  S = rep(conc_seq, 4),\n  V = unlist(predicted_V),\n  trt = rep(c(\"Global\", \"Treatment 1\", \"Treatment 2\", \"Treatment 3\"),\n            each = 100)\n)\n\n# Plot the data and model fits\nmf_data2 %>%\n  ggplot(aes(x = S, y = V, colour = trt)) +\n  geom_jitter(shape = 1, width = 0.08) +\n  geom_line(data = pred_df, aes(y = V, colour = trt, linewidth = trt)) +\n  scale_colour_manual(values = c(\"#804145\", \"#51728E\",\n                                 \"#5D995C\", \"#EE915C\"),\n                      name = NULL) +\n  scale_linewidth_manual(values = c(1.0, 0.6, 0.6, 0.6)) +\n  labs(x = \"Substrate Concentration\",\n       y = \"Reaction Velocity\") +\n  labs(x = TeX(\"S [$\\\\mu$M]\"),\n       y = TeX(\"V [$\\\\mu$M $g^{-1}_{dry}$ $h^{-1}$]\")) +\n  guides(linewidth = \"none\")\n```\n\n### The Perturbation Method (NLMM) {#sec-perturbation}\n\n```{r}\n#| eval: TRUE\n#| echo: FALSE\n#| messages: false\n#| warning: false\n\nmm_data <- read.csv(\"data/flow_rates.txt\", sep = \"\")\n\nmm_data <- mm_data|>\n  mutate(flask = as.factor(rep(c(1, 2, 3), 44)),\n         trt = as.factor(trt))\n```\n\nThe data for this example is by @smit2002nitrogen. A perturbation experiment was conducted to determine the nutrient uptake rate versus nutrient concentration of the red seaweed, *Gracilaria* sp. The experiment involved flasks, initially enriched to approximately 55 μM nitrate, sampled 16 times over approximately 2.5 hours. The uptake rates were measured under three rates of water movement (treatments): low, medium, and high. Each treatment had three replicate flasks (@tbl-mm1). The primary objective was to determine if the Michaelis-Menten parameters significantly differ among the three levels of water movement, and we must state a hypothesis similar to those in @sec-mm-comparison.\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"Simulated data for a multiple flask experiment on an alga (showing only the top and bottom three rows).\"\n#| label: tbl-mm1\n\nmm_data |> \n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n  cols_align(\n    align = \"center\",\n    columns = c(\"flask\", \"trt\")) |> \n  cols_label(flask = html(\"Replicate flask\"),\n             trt = html(\"Treatment\"),\n             V = html(\"V\"),\n             S = html(\"[S]\"))\n```\n\nFor the reasons discussed in @sec-ex1, we will use a nonlinear mixed effects model, `nlme()`, to analyse these data. Models such as these can be quite challenging to fit. There are several things we have to deal with. First and most obviously is the fact that the data are repeated measures, and the residuals may be correlated. Second, the flasks are nested within the treatment levels, and we need to account for this in the model. Finally, we need to account for the possibility that the Michaelis-Menten parameters may vary among the treatment levels---in fact, we want to test this! Here is the model:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\n# Determine the number of levels in the factor 'trt'\nnum_levels <- length(levels(mm_data$trt))\n\n# Starting values for the fixed parameters\n# (one set for each level of 'trt')\nstart_vals <- list(fixed = c(Vmax = rep(max(mm_data$V), num_levels),\n                             Km = rep(median(mm_data$S), num_levels)))\n\nnlme_mod2 <- nlme(V ~ mm_fun(S, Vmax, Km),\n                  data = mm_data,\n                  fixed = Vmax + Km ~ trt, # <1>\n                  random = Vmax + Km ~ 1 | flask, # <2>\n                  start = start_vals,\n                  method = \"REML\")\n```\n\n1. The `fixed` argument specifies that the Michaelis-Menten parameters `Vmax` and `Km` are fixed effects that vary among the treatment levels, and a grouping variable (`trt`) is used to specify the levels of the treatment factor.\n2. The `random` argument specifies that the Michaelis-Menten parameters `Vmax` and `Km` are random effects that vary among the replicate flasks.\n\nThis model brings us closer to our goal, but there are some notable omissions. The specification allows the Michaelis-Menten parameters to vary among the treatment levels, which is central to our hypothesis. We have also accounted for the replication structure of the data, recognising that random variations may arise not due to the treatment levels but due to the replicate flasks. \n\nHowever, we have not accounted for the central feature of a perturbation experiment, which is the correlation structure of the residuals. We must deal with the fact that the residuals may be correlated due to the repeated measures nature of the data. Additionally, we have omitted the nesting of the flasks within the treatment levels. \n\nLet's update our model accordingly:\n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n\nnlme_mod3 <- nlme(V ~ mm_fun(S, Vmax, Km),\n                  data = mm_data,\n                  fixed = list(Vmax ~ trt, Km ~ trt),\n                  random = Vmax ~ 1 | trt/flask, # <1>\n                  groups = ~ trt/flask, # <2>\n                  correlation = corAR1(form = ~ 1 | trt/flask), # <3>\n                  start = start_vals,\n                  method = \"REML\")\n```\n1. The `random` argument specifies that the Michaelis-Menten parameter `Vmax` is a random effect that varies among the replicate flasks nested within the treatment levels.\n2. The `groups` argument specifies that the replicate flasks are nested within the treatment levels.\n3. The `correlation` argument specifies that the residuals have a first-order autoregressive correlation structure. This structure assumes that the correlation between residuals decreases exponentially with the time lag between observations. Flask is nested *within* treatment.\n\nIf we are not convinced that `nlme_mod3` is the best model, we can compare it to `nlme_mod2` using a likelihood ratio test. It is used to compare the fit of two models, where one model is a special case of the other. The test statistic is the difference in the log-likelihoods of the two models, and the null hypothesis is that the simpler model is the best fit. \n\n```{r}\n#| echo: true\n#| messages: false\n#| warning: false\n#| eval: true\n\nanova(nlme_mod2, nlme_mod3)\n\n# Likelihood ratio test\nlrt_stat <- -2 * (logLik(nlme_mod2) - logLik(nlme_mod3))\n\n# Determine degrees of freedom and p-value\ndf_diff <- attr(logLik(nlme_mod3), \"df\") - attr(logLik(nlme_mod2), \"df\") \np_value <- pchisq(lrt_stat, df = df_diff, lower.tail = FALSE) \n\nprint(paste(\"LRT statistic:\", lrt_stat))\nprint(paste(\"Degrees of freedom:\", df_diff))\nprint(paste(\"P-value:\", p_value))\n```\n\nThe likelihood ratio test indicates that `nlme_mod3` is a better fit than `nlme_mod2` (*p* < 0.001). This result suggests that the Michaelis-Menten parameters vary among the treatment levels, and the residuals have a first-order autoregressive correlation structure.\n\n```{r}\nsummary(nlme_mod3)\n```\n\n\n## Example: The Growth Rate of Fish (NLMM) {#sec-vonbertalanffy}\n\nThe von Bertalanffy model (@eq-vb) is used to describe the growth patterns of animals over time. For example, in a fish growth study, we measure the length of individual fish at regular intervals as the fish ages. We can estimate growth parameters specific to the fish species by fitting the von Bertalanffy model to these length-at-age data\n\nThe model is given by:\n\n$$L(t) = L_{\\infty} \\left(1 - e^{-k(t-t_0)}\\right)$$ {#eq-vb}\n\nWhere:\n\n- $L(t)$ is the length of the fish at time $t$.\n- $L_{\\infty}$ is the asymptotic length, representing the theoretical maximum length that the individual would reach if it grew indefinitely.\n- $k$ is the growth coefficient, indicating the rate at which the growth of the fish approaches its maximum size. A higher $k$ value means it reaches its asymptotic length more quickly.\n- $t_0$ is the hypothetical age at which the individual's length would be zero according to the model.\n\n$L_{\\infty}$ (the asymptotic length) represents the length towards which the individual grows as time ($t$) approaches infinity. The concept behind $L_{\\infty}$ is that as the fish ages, its growth rate slows down and eventually approaches zero, with its length nearing the asymptotic value $L_{\\infty}$. $k$ (the growth rate coefficient) determines how quickly the fish reaches its asymptotic length. Physiologically, $k$ reflects the metabolic rates and general fitness of the fish, while ecologically, it can be influenced by environmental factors such as food availability and temperature. Lastly, $t_0$ (the theoretical age at zero length) is not directly observable in practice but provides a useful way to shift the growth curve along the time axis to provide a better fit to the data, especially in the early developmental stages.\n\nConsider a study where the lengths of 30 Atlantic Cod, *Gadus morua*, in captivity are measured twice a year from hatching to 15 years. This creates a longitudinal dataset with repeated length measurements for each fish over time. In this experiment, we will focus on the growth patterns of individual fish, assuming they were raised under identical conditions. This allows us to attribute any growth differences to inherent biological variation among the fish. Apart from the repeated measures on individual fish, we will assume that the data are independent in all other respects.\n\nThe longitudinal nature of the data requires that we use appropriate statistical methods that account for the correlation among the repeated measures. We will use a nonlinear mixed-effects regression for the data in Table 1. \n\n```{r}\n#| echo: false\n#| messages: true\n#| warning: true\n\n# Set up parameters for the von Bertalanffy growth model\nset.seed(13)\n\n# Define parameters\nn_fish <- 30\nn_years <- 15\nn_measurements_per_year <- 2\ntotal_measurements <- n_years * n_measurements_per_year\nages <- seq(0, n_years, by = 1/n_measurements_per_year)\n\n# Initial lengths at hatching (small variation)\ninitial_lengths <- rnorm(n_fish, mean = 5, sd = 0.5)\n\n# von Bertalanffy growth parameters\nL_inf <- 120  # Asymptotic length\nL_inf_sd <- 1\nk_mean <- 0.2\nk_sd <- 0.01\n\n# Generate growth curves for each fish\nvb_data <- data.frame()\nfor (i in 1:n_fish) {\n  k <- rnorm(1, mean = k_mean, sd = k_sd)\n  L_inf <- rnorm(1, mean = L_inf, sd = L_inf_sd)\n  length_at_age <- L_inf * (1 - exp(-k * ages))\n  length_at_age <- initial_lengths[i] + (length_at_age - min(length_at_age))\n  \n  fish_data <- data.frame(\n    Fish_ID = as.factor(rep(i, length(ages))),\n    Age = ages,\n    Length = round(length_at_age, 1)\n  )\n  \n  vb_data <- bind_rows(vb_data, fish_data)\n}\n```\n\n```{r}\n#| echo: false\n#| messages: false\n#| warning: false\n#| tbl-cap: \"The Atlantic Cod data set with 30 fish and 15 years of growth data (showing only the top and bottom three rows).\"\n\nvb_data |> \n  filter(row_number() <= 3 | row_number() > n() - 3) |> \n  gt() |> \n    cols_align(\n    align = \"center\",\n    columns = c(\"Age\", \"Length\")) |> \n  cols_label(\n    Fish_ID = html(\"Fish ID\"),\n    Age = html(\"Age (yr)\"),\n    Length = html(\"Length (cm)\")\n  )\n```\n\nA plot of the data is shown in @fig-vb1; here, each line represents the growth trajectory of an individual fish over time.\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Plot of growth data measured in 30 Atlantic cod, *Gadus morua*.\"\n#| label: fig-vb1\n#| fig.align: center\n\n# Plot the simulated data\nggplot(vb_data, aes(x = Age, y = Length, group = Fish_ID)) +\n  geom_jitter(alpha = 0.6, size = 2, shape = 1,\n              colour = \"black\", width = 0.08) +\n  geom_line(alpha = 0.6, linesize = 0.1,\n            colour = \"red\", linetype = \"dashed\") +\n  labs(x = \"Age (years)\",\n       y = \"Length (cm)\")\n  theme(legend.position = \"none\")\n```\n\nWe will fit the von Bertalanffy growth model to the data using `nlme::nlme()` as follows, and the output is provided: \n\n```{r}\n#| messages: false\n#| warning: false\n\n# von Bertalanffy growth function\nvb_growth <- function(age, L_inf, k, t0) {\n  L_inf * (1 - exp(-k * (age - t0)))\n}\n\n# Define the nonlinear mixed-effects model\nnlme_model <- nlme(Length ~ vb_growth(Age, L_inf, k, t0),\n                   data = vb_data,\n                   fixed = L_inf + k + t0 ~ 1, # <1>\n                   random = L_inf + k ~ 1 | Fish_ID, # <2>\n                   groups = ~ Fish_ID, # <3>\n                   correlation = corAR1(form = ~ 1), # <4>\n                   start = c(L_inf = 100, k = 0.2, t0 = -0.5))\n\n# Print the summary of the model\nsummary(nlme_model)\n```\n1. The fixed effects are the parameters of the von Bertalanffy growth model which are invariant among fish.\n2. The random effects are the asymptotic length and growth rate to account for the intrinsic differences among fish.\n3. The grouping variable is the fish ID.\n4. The correlation structure is autoregressive of order 1 to account for the correlation among repeated measures within the same fish, the `~ 1` indicates that the order of the observations in the data must be used along which measurements are serially correlated, and since no grouping variable is provided, all fish will have the same correlation structure.\n\n\n```{r, fig.width=c(6,5),fig.asp=0.65,out.width=c(\"80%\",\"12cm\")}\n#| echo: false\n#| messages: false\n#| warning: false\n#| fig.cap: \"Fit of the von Bertalanffy model to experimental data obtained from 30 Atlantic Cod individuals.\"\n#| label: fig-vb2\n#| fig.align: center\n\n# Extract fixed effect coefficients\ncoef_fixed <- fixed.effects(nlme_model)\n\n# Generate fitted values for the plot\nvb_data$Fitted_Length <- vb_growth(vb_data$Age, coef_fixed[\"L_inf\"], coef_fixed[\"k\"], coef_fixed[\"t0\"])\n\n# Create the plot\nggplot(vb_data, aes(x = Age, y = Length, group = Fish_ID)) +\n  geom_jitter(size = 2, shape = 1, colour = \"royalblue2\", alpha = 0.4, width = 0.08) +\n  geom_line(aes(y = Fitted_Length), colour = \"indianred2\", linewidth = 0.8) +\n  labs(x = \"Age (years)\",\n       y = \"Length (cm)\")\n```\n\n\n## Scrathpad\n\n### To include in the article\n\n-   **Assumptions:** Not necessary for simply estimating model parameters, but if the model is used for prediction or inference, it is important to state the assumptions of the model (e.g., linearity, homoscedasticity, independence of residuals) and test them.\n-   **i.i.d:** The residuals are assumed to be independent and identically distributed (i.i.d.), which is a common assumption in linear regression models. For a normal distribution, this is written as $\\epsilon_i \\sim N(0, \\sigma^2)$, where $\\sigma^2$ is the variance of the residuals.\n\n\n### Contuinuing the MM model\n\n\n\n\n\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":12,"fig-height":7.5,"fig-format":"svg","fig-dpi":300,"fig-asp":0.65,"df-print":"default","error":false,"eval":true,"cache":false,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"center","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":true,"code-line-numbers":true,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","pdf-engine":"lualatex","embed-resources":false,"highlight-style":"tango","html-math-method":"katex","number-sections":true,"reference-location":"margin","self-contained":false,"toc":true,"toc-depth":2,"output-file":"non-linear_regression.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.4","author":[{"name":"Albertus J. Smit","url":"https://bcbstats.netlify.app","affiliation":"University of the Western Cape","affiliation-url":"https://uwc.ac.za","orcid":"0000-0002-3799-6126"}],"pagetitle":"{{< meta title >}} | Albertus J. Smit","author-meta":"Albertus J. Smit","comments":{"hypothesis":true},"bibliography":["references.bib"],"citation":true,"csl":"marine-biology.csl","copyright":"AJ Smit","footnotes-hover":true,"anchor-sections":true,"grid":{"sidebar-width":"300px","body-width":"1000px","margin-width":"300px","gutter-width":"1.5rem"},"citations-hover":true,"code-block-bg":true,"code-copy":true,"crossrefs-hover":true,"out-width":300,"fig-cap-location":"margin","fontsize":"1.1em","mainfont":"Palatino","monofont":"Roboto Mono","number-depth":2,"page-layout":"article","smooth-scroll":true,"tbl-cap-location":"margin","theme":["cosmo","theme.scss"],"toc-location":"right","toc-title":"On this page","knitr":{"opts_chunk":{"dev":["svg","pdf"]}}},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":6,"fig-height":4,"fig-format":"pdf","fig-dpi":300,"fig-asp":0.65,"df-print":"default","error":false,"eval":true,"cache":false,"freeze":false,"echo":true,"output":true,"warning":false,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"center","fig-pos":"t","fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"latex-tinytex":false},"pandoc":{"pdf-engine":"lualatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","highlight-style":"arrow","include-in-header":[{"text":"\\usepackage{amsmath}\n\\setmathfont{Lato Math}\n\\setmainfont{Lato}\n\\usepackage[version=4]{mhchem}\n\\usepackage{iftex}\n\\usepackage{makeidx}\n\\makeindex\n\\usepackage[dvipsnames]{xcolor}\n\\frenchspacing\n"}],"include-after-body":[{"text":"\\printindex\n"}],"number-sections":true,"toc":true,"toc-depth":2,"output-file":"non-linear_regression.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"block-headings":true,"author":[{"name":"Albertus J. Smit","url":"https://bcbstats.netlify.app","affiliation":"University of the Western Cape","affiliation-url":"https://uwc.ac.za","orcid":"0000-0002-3799-6126"}],"pagetitle":"{{< meta title >}} | Albertus J. Smit","author-meta":"Albertus J. Smit","comments":{"hypothesis":true},"bibliography":["references.bib"],"citation":true,"csl":"marine-biology.csl","copyright":"AJ Smit","footnotes-hover":true,"code-block-bg":"#f8f9fa","colorlinks":true,"citecolor":"teal","documentclass":"book","indent":true,"fontsize":"10","geometry":["heightrounded"],"linkcolor":"teal","lof":false,"lot":false,"monofont":"FiraCode Nerd Font","monofontoptions":["Scale=0.91"],"mathfontoptions":["Scale=1.08"],"microtypeoptions":"final,tracking=true,factor=1100,stretch=10,shrink=10","number-depth":2,"papersize":"a4","toccolor":"teal","urlcolor":"teal","knitr":{"opts_chunk":{"dev":["svg","pdf"]}}},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}