{
  "hash": "931ca42c0eab4b34fa0c8db2d03be7d3",
  "result": {
    "engine": "knitr",
    "markdown": "# Introduction\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n## The Scientific Method in Practice\n\nAnswering questions about the natural world using a scientific workflow requires that we draw on many years' of accumulated knowledge and experience. The workflow unpacks into roughly the following sequence of steps:\n\n1. Look around you at the world, be curious about it, and ask questions to figure out an explanation for the pattern or phenomenon that tickled your interest. \n2. Create an unambiguous statement of the question you want to answer, think about what is causing the pattern or phenomenon you observed, and how you might go about measuring the response (the thing you observed initially).\n3. Translate this question into a testable hypothesis. This is the statement that you can test using the data you will collect.\n4. Design an experiment or sampling campaign to collect data that will allow you to test this hypothesis. Clearly understand what the data you'll collect will look like, both for the response and the explanatory variables. For example, do you have a categorical or continuous predictor, is the response continuous, binary, ordinal, etc.? For this, you should have a firm grasp of the various kinds of [Data Classes and Structures in R](https://tangledbank.netlify.app/BCB744/basic_stats/01-data-in-R.html).\n5. Think deeply about any confounding influences that might affect your data, and specify exactly what additional data you will have to collect to isolate the hypothesised influence in your analysis. You need to fully understand all the ways that factors not considered in your hypothesis might affect your study's outcome. Omissions cannot be rectified after the fact without repeating the entire experiment or sampling work. It requires knowledge and experience to avoid confounding influences ruining your work.\n6. Depending on your experiment's design (4) and the nature of the data you'll obtain (4, 5), choose the appropriate statistical methods to analyse them. You should be able to develop a good idea of what statistical methods you'll use---even before the experiment has been done! Decide on the parametric test, or, should the statistical god with the dice not provide an outcome that favours your expectations, you can also decide upfront on a non-parametric equivalent. It is important not to decide on the statistical method after you've collected the data. This is called *p*-hacking, and it is almost a cardinal sin in science.\n7. Do the experiment or go out into the world to sample, and collect the data. Have fun---this is why we do science, afterall!\n8. Go have a few drinks after a hard day's work and celebrate your success.\n9. Analyse your newly-collected data. This will include explaratory data analyses (see [Exploring With Summaries and Descriptions](https://tangledbank.netlify.app/BCB744/basic_stats/02-summarise-and-describe.html) and [Exploring With Figures](https://tangledbank.netlify.app/BCB744/basic_stats/03-visualise.html)), and then the application of the statistical methods you chose in step 6.\n10. Communicate your results in tables and figures.\n\nThis textbook deals with many of these steps (except for 1, 5, and 7). This knowledge is codified in the form of the statistical method, which provides a systematic framework for collecting,[^0] analysing, and interpreting data. In this chapter, I introduce the fundamental concepts of inferential statistics, which allow us to make inferences about populations based on sample data. I also provide an overview of the types of statistical methods used in inferential statistics, and discuss the importance of understanding the assumptions underlying these methods.\n\n[^0]: Yes, statistics also informs us about how to collect data. \n\n## The Statistical Toolbox\n\nWith inferential statistics you can analyse data obtained from representative samples to draw conclusions or test hypotheses about populations or processes. I broadly categorise these methods into four main types, each serving different research applications[^1]:\n\n[^1]: This categorisation reflects my teaching approach, based on the order in which I think topics need to be covered, rather than a strict classification by statisticians. It is intended to provide a high-level overview of the types of statistical methods used in inferential statistics.\n\n1. **Hypothesis Tests**: These parametric and non-parametric techniques assess whether sample data provide evidence for or against a specific claim (hypothesis) about population parameters such as their means, proportions, variances, or correlations between variables. Common hypothesis tests include:\n\n    - Comparisons of group means or medians for a continuous variable (e.g., *t*-tests, ANOVA, Mann-Whitney *U* test)\n    - Comparisons of group proportions for a categorical variable (e.g., $\\chi$-square test, Fisher's exact test)\n    - Assessments of the relationship between two continuous or ordinal variables (e.g., Pearson's correlation, Spearman's rank correlation)\n\n2. **Regression Analysis**: Regression with its parametric and non-parametric offerings lets us analyse the relationship between a response variable and one or more predictor variables. Regression models estimate coefficients representing the predictor effects, allow for prediction of the response, and enable hypothesis tests on the predictors. Common regression models include:\n\n    - Linear regression for continuous response variables\n    - Logistic regression for binary response variables\n    - Generalised linear models (GLMs) for non-normal response variables\n    - Various non-linear regressions for complex relationships, such as generalised additive models (GAMs)\n\n3. **Survival Analysis**: Methods like the Kaplan-Meier estimator and Cox proportional hazards model analyse time-to-event data, where the interest lies in modelling the waiting times until certain events occur. I do not cover survival analysis in this book or any of my modules.\n\n4. **Multivariate Analysis:** This includes an assortment of methods to analyse multiple response and predictor variables simultaneously. Dimension reduction methods, such as canonical correlation analysis (CCA) and non-metric multidimensional scaling (nMDS), help simplify complex datasets by identifying key patterns and relationships. Classification, including cluster analysis, is used to group similar observations together based on their characteristics. Multivariate approaches make fewer assumptions about the dataâ€™s distribution, and there are techniques to deal with parametric and non-parametric data types (often without discrimination). Although these methods are not covered in this textbook, they are taught in my [Quantitative Ecology](https://tangledbank.netlify.app/BCB743/BCB743_index.html) module, which will eventually be developed into its own textbook.\n\nThe above methods include parametric or non-parametric (sometimes called 'robust') methods. Parametric methods assume that the data follow a specific distribution (e.g., normal, Poisson), while non-parametric methods make fewer assumptions about the data distribution. I will cover the parametric methods first, in Part A, followed by non-parametric methods in Part B. Part C of the book will look at semi-parametric methods, which combine aspects of both parametric and non-parametric approaches.\n\n\n## I. Parametric Methods (Known Distribution)\n\nParametric statistics rely on specific assumptions about the underlying probability distribution of the population from which the sample data were drawn. Biologists are taught that our data must be normally distributed, but this an unreasonable expectation considering the widely varying data sources we will encounter. Some biological processes simply do not generate normally distributed data! \n\nNevertheless, parametric statistics have through convention (rather than best practice) become the starting point for introductory forays into statistics. This is not terrible, because, should we be fortunate enough to have normally distributed data, parametric methods are more powerful than their non-parametric counterparts; however, they are also more sensitive to violations of some assumptions about our data.\n\nThe staple parametric statistics, such as the *t*-test, ANOVAs, Pearson correlation, and simple linear regression, require that two key assumptions are met: i) that our data (or sometimes the residuals) are **normality distributed** and ii) that the **variances are homoscedastic**. Section X is devoted to statistical tests that we may use to test the assumptions. However, because of the Central Limit Theorem, parametric methods can withstand moderate violations of the normality assumption when the sample size is large.[^2]\n\n[^2]: The CLT states that the sampling distribution of the sample mean approaches a normal distribution as the sample size increases, even if the underlying population is not perfectly normal.\n\nA common mistake biologists makes is to think that parametric tests only apply to normal data. This is not true. Generalised linear models (GLMs) extend the statistical framework to accommodate non-normal error distributions, such as Poisson for count data or binomial for binary outcomes.[^3] GLMs require that the distribution of the response variable belongs to the exponential family of distributions and that a suitable link function is chosen to connect the mean of the response to the linear predictor. Therefore, the defining characteristic of parametric methods is the assumption of a **known distribution** for the response variable, not necessarily that is is normal.\n\n[^3]: In fact, many statistical tests that would ordinarily require the assumption of normality to be met have been extended to other probability distributions, as can be seen from the practice to append the word 'Generalised' to the name of the test. For example, the Generalised Additive Model (GAM) is a generalised semi-parametric method, Generalised Non-Linear Models (GNLMs) permit fitting non-linear models to non-parametric data, and Generalised Linear and Non-Linear Mixed-Effects Models (GLMMs and GNLMMs) do the same with hierarchical data.\n\nWithin the parametric statistics framework, we can divide the methods into four groups depending on the type of question we are asking. We can ask questions about i) **difference in means**, ii) **differences in proportions**, iii) **relationships between variables**, or iv) the **effect of one or more predictors on a response variable**. \n\n\n### A. Hypotheses About the Means of Groups\n\nThe simplest form of comparison is to test whether the sample **means** of two or more groups differ.[^4] Although this seems quite unimaginative, comparisons of the measures of central tendency are very common statistical tests in biology. Because this concept is so simple to understand, it serves as a good starting point for learning about hypothesis testing and the interpretation of the statistics which tell us about the strength of the evidence for or against our hypotheses.\n\n[^4]: When it comes to central tendency, the mean is the parameter that is being compared by parametric statistics. Non-parametric statistics, on the other hand, consider the median as the statistic of central tendency.\n\nYou might have hypotheses that require you to compare the means of the outcomes of different experimental treatments, differences in the number of sea urchins among populations of kelp, or the number of species within replicate samples taken from different vegetation types. Look at some of the following examples to see if any of them resonate with your own research question, and then use this as a guide to find the appropriate statistical test in this book.\n\n#### One-Sample *t*-Test (Section X.X.X)\n\n**Example:** Is the mean height of a sample of *Protea* sp. grown in a specific experimental landscape (given below) different from the known (established *a priori*) average height of the same species (163.3 $\\pm$ 15.5 cm) in the general population?\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n   Height\n1     150\n2     152\n3     148\n8     150\n9     149\n10    148\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThe example requires that you have *one normally-distributed continuous outcome variable* with *independent observations* and that you want to compare its mean value against a known population mean established *a priori*. \n\nIn this case, you'll want to use the R function `t.test()`. Since this function can accommodate data with equal or unequal variances[^5] via the `var.equal` argument, you only need to assure the data are normally distributed. The test can be one-sided or two-sided. Alternatively, consider non-parametric alternatives, such as the Wilcoxon signed-rank test.\n\n[^5]: A *t*-test for equal variances is typically called the Student's *t*-test, while a *t*-test for unequal variances is called Welch's *t*-test. By default, the `t.test()` function in R performs Welch's *t*-test, which is more robust to unequal variances.\n\n#### Two-Sample *t*-Test (Section X.X.X)\n\n<!-- **Example:** Is the uptake rate of ammonium by *Chlorella* sp. in the presence of a nitrogen-fixing bacteria different from the uptake rate in the absence of the bacteria? -->\n\n**Example:** Is the average number of leopard cubs born per female leopard in the Overberg region different from that in the Cederberg region? The dataset is:\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n      Region Cubs_Per_Female\n1   Overberg               2\n2   Overberg               3\n3   Overberg               2\n18 Cederberg               3\n19 Cederberg               2\n20 Cederberg               1\n```\n\n\n:::\n:::\n\n\n\n\n\n\nThis requires that we obtain *two samples of continuous, normally-distributed measurements*. In other words, our experiment or sampling campaign will include two groups (sometimes two treatments, other times a treatment and a control) and we collect a sample of measurements of the response in both of them. This is again catered for by the `t.test()` function, and, as before, we don't have to fuss too much about the variances as equal and unequal variances can be accommodated. If the normality assumption is not met, consider a non-parametric alternative such as the Mann-Whitney U test.\n\nA variant of the two-sample *t*-test is the paired *t*-test, which is used when the two samples are related (not independent); for example, the same individuals are measured before and after applying a treatment.\n\n#### Analysis of Variance (ANOVA) for >2 Samples (Section X.X.X)\n\n<!-- **Example:** Is the average density of kelp plants within a kelp forest the same within a marine protected area compared to areas 2 km and 5 km away from the MPA? -->\n\n**Example:** Is the chirp rate of bladder grasshoppers different between the four seasons?\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Chirp Rate Data for Bladder Grasshoppers Across Four Seasons\n\n|   |Season | Chirp Rate|\n|:--|:------|----------:|\n|1  |Spring |       17.7|\n|2  |Spring |       13.9|\n|3  |Spring |       15.7|\n|58 |Winter |       10.2|\n|59 |Winter |        4.0|\n|60 |Winter |       10.6|\n\n\n:::\n:::\n\n\n\n\n\nWe have *three or more samples of continuous, normally-distributed observations*. These data must also have more-or-less equal variances, so the homoscedasticity assumption is important. The `aov()` function in R is used to perform the ANOVA, which can be one-way, two-way, a repeated measures ANOVA, or an ANCOVA.[^6] If the normality or homoscedasticity assumptions are not met, consider non-parametric alternatives, such as the Kruskal-Wallis test, or try transforming the data.\n\n[^6]: A repeated measures ANOVA is used when the same subjects are measured at different time points or under different conditions. A two-way ANOVA is used when there are two independent variables (there are also higher-order ANOVAs but they become more of a pain to interpret and require cumbersome experimental designs). An ANCOVA is used when you want to compare the means of groups while controlling for the effect of a continuous covariate. There are many kinds of ANOVA designs and each relates to specific experimental designs well beyond the scope of this book. Tony Underwood provides a pedantic overview of ANOVA designs in his book *Experiments in Ecology* [@underwood1997experiments] if you really want to go there.\n\n#### Analysis of Covariance (ANCOVA)* (Section X.X.X)\n\n**Example:** We have a set of data about African penguins and we want to determine if there are differences between male and female penguins in terms of their mean foraging time, and if that difference is influenced by their diving depth. The dataset is as follows:\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\caption{\\label{tab:unnamed-chunk-6}Foraging time and diving depth of African penguin.}\n\\centering\n\\begin{tabular}[t]{ccc}\n\\toprule\nSex & Foraging time\n(hr) & Diving depth\n(m)\\\\\n\\midrule\nMale & 1.2 & 10\\\\\nMale & 1.5 & 15\\\\\nMale & 1.8 & 20\\\\\nFemale & 2.0 & 25\\\\\nMale & 2.3 & 30\\\\\n\\addlinespace\nFemale & 2.5 & 35\\\\\nFemale & 2.8 & 40\\\\\nFemale & 3.0 & 45\\\\\nMale & 3.3 & 50\\\\\nMale & 3.5 & 55\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\n\n:::\n:::\n\n\n\n\n\n\nIn this example, we are interested in the mean foraging time of male and female penguins, controlling for their diving depth. An ANCOVA focuses on the differences in means (the categorical variable), and the continuous covariates (diving depth) is specifically controlled for to remove its effect from the dependent variable. This reduces the error variance and so more accurately assesses the comparison of group means. The assumptions of normality and homoscedasticity apply. The functions `aov()` accommodates the categorical and continuous predictors.\n\n#### Multivariate Analysis of Variance (MANOVA)\n\nMANOVAs are similar to ANOVAs, except here you have *multiple dependent variables*, all *independent, continuous, and normally-distributed*. This is useful when you want to compare the means of multiple groups across multiple dependent variables. For example, you might want to compare the average foraging time together with diving depth of African penguins in three colonies (two in South Africa and one in Namibia) around the coast. The `manova()` function in R is used to perform a MANOVA and there are similar variants to what we have seen in ANOVA.\n\n### B. Hypotheses About the Proportions of Groups\n\nYou can compare the proportions of groups using tests for proportions when the outcome variable is binary (e.g., success/failure, presence/absence, up/down, day/night). These tests are used to determine if the proportion of successes differs between groups. Use the following tests to compare group proportions:\n\n#### One-Sample Test for Proportions\n\n**Example:** Is the proportion of African penguins foraging in a specific colony different from the known proportion of the same species in the general population? The data might look like this:\n\n- `Sample data: 55 of the 100 penguins observed were foraging in a specific colony`\n- `The known proportion of penguins foraging in the general population is 60%`\n\nIn this scenario, we are comparing the proportion of a single sample (the proportion of foraging African penguins in a specific colony) to a known population proportion. The data must consist of a *binary outcome variable* (e.g., foraging vs. not foraging) and the observations must be independent. The `prop.test()` function in R is used to perform this test, which can be either one-sided or two-sided. If the requirement of independent observations is not met, consider non-parametric alternatives, such as the sign test.\n\n#### Two-Sample Test for Proportions\n\n**Example:** Is the proportion of endangered sea turtles successfully reaching the ocean different between two beaches? Here are data:\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Number of Sea Turtles Reaching the Ocean on Two Beaches\n\n|Beach   | Successes| Observed|\n|:-------|---------:|--------:|\n|Beach A |        75|      100|\n|Beach B |        65|      120|\n\n\n:::\n:::\n\n\n\n\n\n\nHere we compare the proportions from two independent samples (e.g., the proportion of sea turtles successfully reaching the ocean on Beach A versus Beach B). As before, the data yield *a binary outcome* (e.g., reached the ocean vs. did not reach the ocean) for each group, and the observations within each group are independent. The `prop.test()` function is used it has one-sided or two-sided options. If the sample sizes are small or expected frequencies are low, consider using Fisher's exact test instead of the proportion test. If the assumption of independent observations within groups is violated, you may need to consider methods that account for dependency in the data, such as Generalised Estimating Equations (GEE) or mixed-effects models.\n\n#### Chi-square Test for Count Data\n\n**Example:** Is there an association between vegetation type and the presence of leopards in different areas of Kruger National Park? A hypothetical dataset:\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Contingency Table of Plant Species and Insect Occurrence\n\n|          | Presence| Absence|\n|:---------|--------:|-------:|\n|Grassland |       20|      30|\n|Woodland  |       25|      40|\n|Shrubland |       35|      15|\n\n\n:::\n:::\n\n\n\n\n\n\nHere we examine the relationship between two categorical variables (vegetation type and leopard presence) within Kruger National Park. The data are organised into a contingency table, where each cell represents the count or frequency of observations for a specific combination of categories. The chi-square test of independence is used to determine if there's a significant association between the variables.\n\nAs with other categorical tests, the data yield *discrete outcomes* (e.g., savanna, woodland, or riverine for vegetation type; present or absent for leopard presence). The observations should be independent, meaning the presence of a leopard in one area should not influence its presence in another.\n\nThe `chisq.test()` function in R is commonly used for this analysis. This test compares the observed frequencies in each cell of the contingency table to the frequencies that would be expected if there were no association between vegetation type and leopard presence.\n\nIf the sample size is large and the expected frequencies in each cell are adequate (typically > 5), the chi-square test is appropriate. However, if the sample size is small or if there are cells with low expected frequencies, consider using Fisher's exact test instead.\n\nIf the assumption of independence is violated (e.g., if the data include multiple observations from the same leopard individuals or territories), you may need to consider more advanced methods that account for dependency in the data, such as log-linear models or Generalised Estimating Equations (GEE).\n\n#### Fisher's Exact Test\n\n**Example:** Is there a significant association between the presence of certain plant species and the occurrence of rare fynbos endemic insects in the Cape Floristic Region? Here are the data:\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Contingency Table of Plant Species and Insect Occurrence\n\n|        | Present| Absent|\n|:-------|-------:|------:|\n|Plant A |       2|      8|\n|Plant B |       3|      7|\n\n\n:::\n:::\n\n\n\n\n\n\nFisher's Exact Test is used when we have two categorical variables and want to determine if there's a significant association between them, particularly when sample sizes are small or when we have sparse data in some categories. This test is especially useful in ecological studies where rare species or events are being investigated.\n\nIn this example we examine the relationship between the presence of specific plant species and the occurrence of rare fynbos endemic insects. The data are organised into a 2x2 contingency table, where each cell represents the count of observations for a combination of presence/absence of the plant species and the insect species.\n\nThe test calculates the exact probability of observing the given set of cell frequencies under the null hypothesis of no association. It does not rely on approximations and it more accurate than the chi-square test for small samples.\nUse the `fisher.test()` function to perform this analysis. Like other categorical tests, the observations should be independent, meaning the presence of an insect in one area should not influence its presence in another.\n\nFisher's Exact Test is particularly appropriate when:\n\n- The total sample size is less than 1000\n- The expected frequency in any cell of the contingency table is less than 5\n- You're dealing with rare events or species\n\nIf the sample size becomes very large, Fisher's Exact Test can become computationally intensive, and the chi-square test may be more practical.\n\nIf the assumption of independence is violated (e.g., if the data include multiple observations from the same locations over time), you may need to consider more advanced methods that account for dependency in the data, such as mixed-effects models or Generalised Estimating Equations (GEE).\n\n### C. Hypotheses About the Strength of Association {#sec-pearson}\n\n**Example:** Is there a relationship between the foraging time and diving depth of African penguins? \n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\caption{\\label{tab:unnamed-chunk-10}Foraging time and diving depth of African penguin.}\n\\centering\n\\begin{tabular}[t]{cc}\n\\toprule\nForaging time\n(hr) & Diving depth\n(m)\\\\\n\\midrule\n1.2 & 10\\\\\n1.5 & 15\\\\\n1.8 & 20\\\\\n2.0 & 25\\\\\n2.3 & 30\\\\\n\\addlinespace\n2.5 & 35\\\\\n2.8 & 40\\\\\n3.0 & 45\\\\\n3.3 & 50\\\\\n3.5 & 55\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\n\n:::\n:::\n\n\n\n\n\n\nYou'll want to use a Pearson's correlation to determine if there is a linear relationship between *two continuous variables*, both of them normally distributed and homoscedastic. A correlation analysis does not presume causation and does not provide a predictive model, both of which are the domain of regression. The strength of the relationship is quantified by the correlation coefficient called Pearson's rho, which ranges from -1 to 1. Use the `cor.test(..., method = \"pearson\")` function in R to perform this analysis. \n\nNon-parametric alternatives such as the Spearman's rank correlation or Kendall's tau correlation (see 'II. Non-Parametric Methods') are available and implemented with the same R function.\n\n### D. Modelling and Predicting Causal Relationships\n\nThe relationship between one or a few predictors and an outcome can be represented by a function, which is a model that reconstructs part of the 'reality' of the observed phenomenon. Regression analysis helps you understand how changes in the continuous predictor variable(s) drive changes in a continuous outcome variable. The model quantifies the strength of the associations and makes predictions for new data points. You may use regression models for hypothesis testing and for identifying which predictor variables have the most substantial impact on the outcome.\n\n#### Simple Linear Regression\n\n**Example:** The same dataset of [foraging time and diving depth of African penguins](#sec-pearson) can be used to model the relationship between these two variables. Does diving depth depend on foraging time?\n\nWhat is different now is that we are interested in *predicting the diving depth* (response) of penguins based on their foraging time (predictor). Assuming there is a linear response, we can use a simple linear regression model to quantify the relationship between these two continuous variables. The model provides an equation that describes how the diving depth changes as the foraging time increases. The assumptions of normality and homoscedasticity apply to the residuals, and are accessed after having fit the model.\n\nThis calls for a simple linear regression model and you can fit it using the `lm()` function in R. The model can also be specified as a generalised linear model (GLM) with `glm(..., family = gaussian)`.\n\nIf assumptions fail, apply data transformations (e.g., log, square root), robust regression (`rlm()` in **MASS** package), or consider non-linear models.\n\n#### Polynomial Regression\n\nI'll not provide an example here. It suffices to say that a polynomial regression is effectively a simple linear regression that allows for a curvilinear relationship between the predictor and the outcome. To accomplish this, the model includes polynomial terms (e.g., quadratic, cubic, which are simply powers of the predictor) to capture the non-linear patterns in the data. The model can be fit using the `lm()` function in R.\n\nAssess the relationship between $x$ vs. $y$ by making a scatterplot of the data and eye balling a best fit curve through the scatter of points. Is the line curvy or bendy? Do you know in advance if a more complicated model describes the response? If the answer is 'yes' to the first and 'no' to the second question, then a polynomial regression might be just the thing for you.\n\n#### Multiple Linear Regression (MLR) {#sec-mlr}\n\n**Example:** I've added a second predictor to the dataset of [foraging time and diving depth of African penguins](#sec-pearson). Does diving depth depend on the penguins' body mass index (BMI) and foraging time?\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\\begin{table}\n\\centering\n\\caption{\\label{tab:unnamed-chunk-11}Foraging time and diving depth of African penguin.}\n\\centering\n\\begin{tabular}[t]{ccc}\n\\toprule\nBMI & Foraging time\n(hr) & Diving depth\n(m)\\\\\n\\midrule\n1.2 & 1.2 & 10\\\\\n1.5 & 1.5 & 15\\\\\n1.8 & 1.8 & 20\\\\\n2.0 & 2.0 & 25\\\\\n2.3 & 2.3 & 30\\\\\n\\addlinespace\n2.5 & 2.5 & 35\\\\\n2.8 & 2.8 & 40\\\\\n3.0 & 3.0 & 45\\\\\n3.3 & 3.3 & 50\\\\\n3.5 & 3.5 & 55\\\\\n\\bottomrule\n\\end{tabular}\n\\end{table}\n\n\n:::\n:::\n\n\n\n\n\n\nThe only difference between this example and the simple linear regression is that we now have two predictors (foraging time and BMI) instead of one. The predictors can be *continuous* (as in the example) *and/or categorical*. If you are more concerned with the means of the categorical variables, consider an ANCOVA as an alternative option. The multiple linear regression model can be extended to include interaction terms between predictors. You can quantify the relationship between both predictors and the outcome simultaneously, and ask which of the two best predicts the response. The same assumptions apply as in the simple linear regression and we hope for a linear relationship between $x_1$ and $x_2$ vs. $y$. Other considerations are provided in the chapter on [MLR](multiple_linear_regression.qmd).\n\nThe R functions `lm()` and `glm(..., family = gaussian)` accommodate situations such as these where we have multiple predictors.\n\n\n\n#### Generalised Linear Models (GLM)\n\nGLMs are a class of regression models that extend the simple linear regression framework to accommodate various types of response distributions. As such, they can accommodate data that violate the assumptions of normality and homoscedasticity, as well as situations where the response variable is not continuous.\n\nUse GLMs to model count data (e.g., number of occurrences), binary outcomes (e.g., success/failure), and other non-continuous response variables that cannot be adequately represented by a normal distribution. Unlike linear models, which assume a normal error distribution, GLMs specify the distribution of the response variable using a probability distribution from the exponential family, such as the Gaussian (normal), binomial, Poisson, or negative binomial distributions.\n\nGLMs incorporate a link function that relates the linear predictor (a linear combination of the predictor variables) to the expected value of the response variable. This link function can take various forms, including the identity (linear), logit (for binary data), probit, or other transformations, depending on the nature of the response variable and the desired relationship between the predictors and the outcome.\n\nThe `glm()` function is a staple for fitting GLMs. It is designed to handle the exponential family distributions and will allow you to specify the appropriate distribution and link function for your data and research question. A few common types of GLMs are presented next.\n\n*Logistic Regression* (@sec-generalised-linear-model)\n\nYou'll encounter binomial data in experiments or processes with binary outcomes, such as presence/absence, success/failure, or alive/dead. To model this type of data, you will want to use logistic regression. Logistic regression estimates the log-odds of the outcome as a linear combination of the predictor variables. The logistic function is then used to convert these log-odds into probabilities, which range from 0 to 1, so it is suitable for predicting the likelihood of the binary outcomes.\n\n-   **Use When:** You have a binary outcome variable and want to model the relationship between predictors and the probability of the outcome.\n-   **Data Requirements:** Binary outcome, continuous or categorical predictors.\n-   **Assumptions:** Linear relationship between the log-odds of the outcome and predictors.\n-   **Diagnostics:** Check for influential observations, multicollinearity, and overall model fit.\n-   **If Assumptions Fail:** Consider interactions, alternative link functions (probit, complementary log-log) in `glm()`, or non-linear logistic regression, zero-inflated models when excess zeroes.\n-   **R Function:** `glm(..., family = binomial)`\n-   **Model Selection:** Stepwise regression, regularisation techniques, information criteria (AIC, BIC).\n\n*Poisson Regression* (@sec-generalised-linear-model)\n\nTypical examples of count data include the number of offspring, parasites, or seeds. Poisson regression is used to model the relationship between predictors and the count outcome. The model assumes that the count data follow a Poisson distribution, where the mean and variance are equal. Poisson regression is suitable for data with a single count outcome.\n\n-   **Use When:** You have count data and want to model the relationship between predictors and the count outcome.\n-   **Data Requirements:** Count outcome, continuous or categorical predictors.\n-   **Assumptions:** Equidispersion (variance equals the mean).\n-   **Diagnostics:** Check for overdispersion, excess zeros, and overall model fit.\n-   **If Assumptions Fail:** Negative binomial regression (`glm.nb()` in the **MASS** package, overdispersion), zero-inflated models (`zeroinfl()` in the **pscl** package, excess zeros).\n-   **R Function:** `glm(..., family = poisson)`\n\n*Negative Binomial Regression*\n\nNegative binomial regression is an extension of Poisson regression that accommodates overdispersion, where the variance exceeds the mean. It is used when the count data exhibit more variability than expected under a Poisson distribution. The model assumes that the count data follow a negative binomial distribution, which has an additional parameter to account for overdispersion. Biological and ecological processes such as species abundance, parasite counts, and gene expression often exhibit overdispersion.\n\n-   **Use When:** You have count data with overdispersion and want to model the relationship between predictors and the count outcome.\n-   **Data Requirements:** Count outcome, continuous or categorical\n-   **Assumptions:** Overdispersion (variance exceeds the mean).\n-   **Diagnostics:** Check for overdispersion, excess zeros, and overall model fit.\n-   **R Function:** `glm.nb()` in **MASS** package\n\n*Gamma Regression*\n\nGamma regression is for modelling continuous, positive outcomes that exhibit a right-skewed distribution and possibly also a non-constant variance (heteroscedasticity). The gamma distribution is well suited for continuous measurements where the variability increases as the mean increases. You might encounter this kind of distribution in growth rates, enzyme activity levels, species abundance data, and other phenomena or processes characterised by positive, skewed data.\n\n-   **Use When:** You have a continuous, positive outcome and want to model the relationship between predictors and the outcome.\n-   **Data Requirements:** Continuous, positive outcome, continuous or categorical predictors.\n-   **Assumptions:** Outcome values are positive, potentially non-constant variance.\n-   **Diagnostics:** Check for overall model fit, influential observations, and residual\n-   **R Function:** `glm(..., family = Gamma)`\n\n*Beta Regression*\n\nBeta regression is a statistical technique appropriate when the response variable is a continuous proportion or rate bounded between 0 and 1. These types of data might, for example, arise in ecology where one might study the proportions of time animals spend exhibiting different behaviours, the relative abundances of species in a community, or the proportions of habitat patches comprising a landscape. Proportional data inherently exhibit heteroscedasticity (non-constant variance).\n\n-   **Use When:** You have a proportional outcome ($0 < y < 1$) and want to model the relationship between predictors and the outcome.\n-   **Data Requirements:** Proportional outcome ($0 < y < 1$), continuous or categorical predictors.\n-   **Assumptions:** Outcome values within ($0,1$), potentially non-constant variance.\n-   **Diagnostics:** Check for overall model fit, influential observations, and residual analysis.\n-   **If Assumptions Fail:** Transformations, consider alternative link functions, or zero/one-inflated beta regression.\n-   **R Function:** `betareg()` in the **betareg** package\n\n**Modelling Non-Linear Relationships**\n\nWe use non-linear models when the relationship between predictor variables and the outcome variable is not linear. This non-linearity arises from the predictor variables themselves being non-linearly related to the outcome or from the model's parameters (coefficients) appearing non-linearly in the functional form. The visualised response curve is typically curved, rather than a straight line. These models are often derived from theoretical understanding or prior knowledge about the underlying mechanisms governing the relationship between the predictors and the outcome variables.\n\n*Non-Linear Least Squares (NLS) Regression* (@sec-nonlinear-regression)\n\n-   **Use When:** The relationship between the predictors and the outcome is non-linear.\n-   **Data Requirements:** Continuous outcome, continuous predictors.\n-   **Assumptions:** Appropriate functional form, normality, and homoscedasticity of residuals.\n-   **Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points.\n-   **R Function:** `nls()` (for non-linear regression models with user-specified functions)\n\n**Generalised Non-Linear Models (GNLMs)**\n\nGNLMs are an extension of generalised linear models (GLMs) that allow for non-linear relationships between the predictors and the outcome variable. GNLMs are used when the relationship between the predictors and the outcome is non-linear, and the outcome variable follows a non-normal distribution. GNLMs are particularly useful for count data, binary outcomes, and other non-continuous response variables that exhibit non-linear relationships with the predictors.\n\n**Linear and Non-Linear Hierarchical Models (Mixed-Effects Models)**\n\nHierarchical models are used when data are structured hierarchically, such as when multiple observations are nested within higher-level units (e.g., plants within fields, sheep within rangelands). These models account for the correlation between observations within the same group and allow for the estimation of both fixed effects (population-level parameters) and random effects (group-level parameters). Hierarchical models are also known as multilevel models or mixed-effects models.\n\n*Linear Mixed-Effects Models (LMMs)* (Section X.X.X)\n\n-   **Use When:** You have nested or hierarchical data structures and the relationship between the predictors and the outcome is linear.\n-   **Data Requirements:** Continuous outcome, continuous predictors, potentially with nested or hierarchical data structures.\n-   **Assumptions:** Normality, homoscedasticity of residuals, correct specification of random effects structure.\n-   **If Assumptions Fail:** Consider transformations, robust regression, or non-linear mixed-effects models.\n-   **Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.\n-   **R Function:** `lmer()` in the **lme4** package (for linear mixed-effects models with user-specified functions)\n\n*Non-Linear Mixed-Effects Models (NLMMs)* (@sec-nonlinear-regression)\n\n-   **Use When:** You have nested or hierarchical data structures and the relationship between the predictors and the outcome is non-linear.\n-   **Data Requirements:** Continuous outcome, continuous predictors, potentially with nested or hierarchical data structures.\n-   **Assumptions:** Appropriate functional form, normality, and homoscedasticity of residuals, correct specification of random effects structure.\n-   **If Assumptions Fail:** Generalised non-linear mixed models (GNLMMs) and generalised additive mixed models (GAMMs) can be used when the assumptions of non-linear mixed models (NLMMs) are violated. Else, consult a statistician.\n-   **Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.\n-   **R Function:** `nlme()` in the **nlme** package (for non-linear mixed-effects models with user-specified functions)\n\n**Generalised Linear and Non-Linear Mixed-Effects Models (GLMMs and GNLMMs)**\n\nGLMMs and GNLMMs combine the flexibility of regression model generalisation (i.e. by accommodating non-Gaussian distribution families) with the ability to account for nested or hierarchical data structures. GLMMs are used when the outcome variable is not normally distributed (a different, known distribution) and the data are structured hierarchically. GLMMs include both fixed effects (population-level parameters) and random effects (group-level parameters) and can accommodate a wide range of outcome distributions, including binary, count, and continuous outcomes.\n\n-   **Use When:** You have non-normally distributed outcome data and nested or hierarchical data structures.\n-   **Data Requirements:** Binary outcome, continuous or categorical predictors, potentially with nested or hierarchical data structures.\n-   **Assumptions:** Linear relationship between the log-odds of the outcome and predictors, correct specification of random effects structure.\n-   **Diagnostics:** Check residual plots, normality of residuals, and leverage/influence points, assess random effects structure.\n-   **R Function:** `glmer()` in the **lme4** package\n\n**Other Regression Models**\n\n*Zero-Inflated Models*\n\n-   **Use When:** You have count data with an excess of zeros and want to model the zero-inflation separately from the count process.\n-   **Data Requirements:** Count outcome, continuous or categorical\n-   **Assumptions:** Correct specification of zero-inflation and count processes, no omitted variables.\n-   **Diagnostics:** Check zero-inflation and count process, overall model fit.\n-   **R Function:** `zeroinfl()` in the **pscl** package\n\n*Survival Analysis*\n\n-   **Data Requirements:** Time-to-event outcome, continuous or categorical predictors.\n-   **Assumptions:** Proportional hazards, non-informative censoring.\n-   **Diagnostics:** Check proportional hazards assumption, influential observations, and overall model fit.\n-   **R Function:** `survival::coxph()`\n\n*Time Series Analysis*\n\n-   **Data Requirements:** Time-ordered data, potentially with autocorrelation.\n-   **Assumptions:** Stationarity, no autocorrelation in residuals.\n-   **Diagnostics:** Check autocorrelation, stationarity, and overall model fit.\n-   **R Function:** `arima()`, `auto.arima()` in the **forecast** package\n\n*Structural Equation Modelling (SEM)*\n\n-   **Data Requirements:** Continuous outcome, continuous\n-   **Assumptions:** Correct specification of the structural model, no omitted variables, no measurement error.\n-   **Diagnostics:** Check model fit, parameter estimates, and overall model validity.\n-   **R Function:** `sem()` in the **lavaan** package\n\n*Bayesian Regression*\n\n-   **Data Requirements:** Continuous outcome, continuous or categorical predictors.\n-   **Assumptions:** Correct specification of priors, likelihood, and model structure.\n-   **Diagnostics:** Check for convergence, posterior predictive checks, and overall model fit.\n-   **R Function:** `brms::brm()`\n\n## II. Non-Parametric Methods (Distribution-Free)\n\nNon-parametric statistics are statistical methods that do not rely on assumptions about the specific form or parameters of the population distribution. They are also referred to as *distribution-free methods*. These methods often use ranks or other order statistics of the data rather than the actual data values themselves.\n\n\n### A. Hypotheses About Groups\n\n*One-Sample Tests for Medians*\n\nUse a one-sample test to compare the median of a single sample to a known population median. It is as an alternative to one-sample *t*-tests when the data do not meet the assumptions of parametric tests.\n\n-   Wilcoxon signed-rank test\n-   Sign test\n\n*Two-Sample Tests for Medians* (Section X.X.X)\n\nUse two-sample tests to compare the medians of two independent or related samples. Use it when the assumptions of parametric two-sample tests are violated.\n\n-   Mann-Whitney U test (two independent groups)\n-   Wilcoxon rank-sum test (two independent groups)\n-   Kruskal-Wallis test (multiple groups)\n-   Friedman test (related samples)\n\n\n### B. Hypotheses About Proportions\n\n-   *Chi-Square Test for Independence:* Comparing proportions of two groups\n\n\n### C. Correlation Analysis for Tests of Association\n\nUse non-parametric correlation to assess the strength and direction of a relationship between two continuous (or ordinal) variables when the assumptions of parametric correlation tests cannot be met.\n\n*Spearman's Rank Correlation* (@sec-correlation)\n\nA non-parametric measure of the strength and direction of association between two variables.\n\n*Kendall's Tau Correlation* (@sec-correlation)\n\nA non-parametric measure of the strength and direction of association between two variables.\n\n\n### D. Regression Analysis\n\n*Quantile Regression* (Section X.X.X)\n\nModels different quantiles of the response distribution.\n\n*Robust Regression* (Section X.X.X)\n\nLess sensitive to outliers than ordinary least squares regression.\n\n*Kernel Density Estimation*\n\nKDE is a non-parametric method for visualising the distribution of a continuous variable. Unlike histograms, which bin data into discrete intervals, KDE creates a smooth curve that represents the estimated probability density function (PDF) of the underlying data. It does this by placing a kernel function (often a symmetric curve like a Gaussian or Epanechnikov) at each data point and summing up the contributions of these kernels across the entire range of the variable.  The bandwidth of the kernel controls the smoothness of the resulting density estimate. Wider bandwidths lead to smoother curves but may obscure finer details, while narrower bandwidths reveal more local fluctuations but can be noisy. KDE is useful when the underlying distribution of the data is unknown or non-standard and it offers a convenient way to visualise and understand the shape and spread of the data without being constrained by parametric assumptions.\n\n*Local Regression (LOESS)*\n\nLOESS (Locally Estimated Scatterplot Smoothing) is a non-parametric regression technique that produces a smooth curve through a set of data points by fitting simple models to localised subsets of the data. It achieves this by weighting the data points in each subset, with higher weights assigned to points closer to the point being estimated. The model used for local fitting is typically a low-degree polynomial, although other choices are possible.\n\nLOESS is primarily used for data exploration and visualisation. It is best known for smoothing scatterplots and revealing underlying trends or patterns in the data. It is advantageous because it doesn't assume any particular functional form for the relationship between the predictors and the response variable, so it to adapts to various data shapes. But LOESS does not provide a single, easily interpretable equation for the entire dataset, making it less suitable for making predictions or drawing global inferences. It can also be computationally demanding with large datasets as it fits separate models in the vicinity of locally-selected points.\n\n*Penalised Regression*\n\nPenalised regression (also known as regularisation) is used to enhance the performance of regression models. This might be desirable when dealing with high-dimensional data or when the predictor variables are highly collinear. It introduces a penalty to the regression objective function which discourages the model from having overly complex or large coefficients. This effectively prevents overfitting. Common types of penalised regression include Ridge regression (L2 regularisation), which adds the sum of the squared coefficients as a penalty term, and Lasso regression (L1 regularisation), which adds the sum of the absolute values of the coefficients. The penalty terms encourage simpler models by shrinking some coefficients towards zero, with Lasso potentially setting some coefficients exactly to zero, thus performing variable selection. The balance between fitting the data well and maintaining model simplicity helps in improving the modelâ€™s generalisation to new data. Penalised regression methods can achieve a trade-off between bias and variance and result in more robust and interpretable models.\n\n\n## III. Semi-Parametric Methods\n\nSemi-parametric methods combine parametric and non-parametric techniques to provide a balance between flexibility and efficiency. These methods are useful when the assumptions of parametric tests are violated, but the data do not meet the requirements for non-parametric tests. Semi-parametric methods are often more powerful than non-parametric tests, as they make fewer assumptions about the data distribution. These methods are particularly useful when the sample size is small or when the data are skewed or have outliers.\n\n*Generalised Additive Models (GAMs)* (@sec-generalised-additive-models)\n\n-   **Use When:** You have non-linear relationships between predictors and outcome.\n-   **R Function:** `gam()` in the **mgcv** package; also `gamm4()` in the **gamm4** package\n-   **Data Requirements:** Continuous, binary, or categorical outcome, continuous or categorical predictors, potentially with nested or hierarchical data structures.\n-   **Advantages:** Flexible modelling of non-linear relationships using smoothing functions, can handle mixed-effects structures.\n-   **Limitations:** Interpretation can be challenging, potential overfitting.\n\n*Generalised Estimating Equations (GEEs)*\n\n-   **Use When:** You have correlated data and non-normally distributed outcomes.\n-   **R Function:** `geeglm()` in the **geepack** package; also functions in the **gee** package\n-   **Data Requirements:** Correlated data, non-normal outcomes, continuous or categorical predictors.\n-   **Advantages:** Robust to misspecification of the correlation structure, can handle non-normal outcomes, flexible in handling missing data.\n-   **Limitations:** Assumes correct specification of the correlation structure, may be less efficient than mixed-effects models.\n\n*Semi-Parametric Survival Models*\n\n-   **Use When:** You have time-to-event data and want to model the hazard function.\n-   **R Function:** `coxph()` in the **survival** package\n-   **Data Requirements:** Time-to-event data, censoring, continuous or categorical predictors.\n-   **Assumptions:** Proportional hazards assumption, independence of censoring.\n-   **Diagnostics:** Check proportional hazards assumption, influential observations, goodness\n\n*Spline Regression*\n\n-   **Use When:** You have non-linear relationships between predictors and outcome.\n-   **R Function:** `lm()` with splines, `gam()` in the **mgcv** package\n-   **Data Requirements:** Continuous outcome, continuous predictors.\n-   **Assumptions:** Linearity within each spline, potentially non-constant variance.\n-   **Diagnostics:** Check for overall model fit, influential observations, and residual analysis.\n-   **If Assumptions Fail:** Transformations, consider alternative link functions, or penalised regression.\n\n\n## IV. Machine Learning Methods\n\nMachine learning methods are a set of algorithms that can learn patterns from data without being explicitly programmed. These methods are particularly useful for prediction, classification, and clustering tasks. Machine learning models can handle complex relationships in the data and are often more flexible than traditional statistical models. However, they can be more computationally intensive and may require more data to train effectively.\n\n*Random Forests*\n\nA machine learning method that uses an ensemble of decision trees to predict an outcome.\n\n*Support Vector Machines*\n\nA machine learning method that finds the optimal hyperplane to separate two classes of data.\n\n*Ensemble Methods*\n\nA machine learning technique that combines the predictions of multiple models to improve accuracy.\n\n*Neural Networks*\n\nA machine learning method that uses interconnected nodes to model complex relationships in data.\n\n*Deep Learning*\n\nA subset of machine learning that uses neural networks with multiple layers to model complex relationships in data.\n\n\n## V. Miscellaneous Methods\n\n*Bootstrapping*\n\nA resampling method for estimating the sampling distribution of a statistic.\n\n*Permutation Tests*\n\nA non-parametric method for testing hypotheses by randomly permuting the data.\n\n*Monte Carlo Simulation*\n\nA method for estimating the distribution of a statistic by generating random samples from a known distribution.\n\n*Bayesian Methods*\n\nA statistical approach that uses Bayes' theorem to update prior beliefs based on observed data.\n\n*Dimensionality Reduction*\n\nAlso called muitvariate analyses. A set of techniques for reducing the number of variables in a dataset while preserving important information.\n\n*Clustering*\n\nA set of unsupervised learning techniques for grouping similar data points together.\n\n*Feature Selection*\n\nA process for identifying the most important variables in a dataset for predicting an outcome.\n\n*Regularisation*\n\nSee penalised regression. A technique for preventing overfitting by adding a penalty term to the model coefficients.\n\n*Cross-Validation*\n\nA method for estimating the performance of a model by splitting the data into training and test sets.\n\n*Hyperparameter Tuning*\n\nThe process of selecting the optimal values for the parameters of a machine learning model.\n\n*Model Evaluation*\n\nThe process of assessing the performance of a model using metrics such as accuracy, precision, recall, and F1 score.\n\n*Model Interpretation*\n\nThe process of understanding how a model makes predictions by examining the relationship between the input variables and the output.\n\n*Model Deployment*\n\nThe process of putting a trained model into production so that it can be used to make predictions on new data.\n\n*Model Monitoring*\n\nThe process of tracking the performance of a deployed model over time to ensure that it continues to make accurate predictions.\n\n*Model Explainability*\n\nThe process of explaining how a model makes predictions in a way that is understandable to humans.\n\n*Model Fairness*\n\nThe process of ensuring that a model does not discriminate against certain groups of people based on sensitive attributes.\n\n*Model Robustness*\n\nThe process of ensuring that a model performs well on new data that is different from the training data.\n\n\n\n<!-- The basic high-level decision that would cause a person to decide between any inferential statistical method excluding regressions, and regressions (including all various types) primarily revolves around the research question and the type of relationship or effect they are interested in analysing, namely *describing relationships* vs. *predicting and modelling outcomes*. -->\n\n<!-- **Inferential Statistical Methods (Excluding Regressions):** -->\n\n<!-- - **Purpose:** Often used to test hypotheses, compare groups, and determine if there are significant differences or associations between variables. -->\n\n<!-- - **Example Methods:** *t*-tests, ANOVA, chi-square tests, correlation analysis. -->\n\n<!-- - **Research Questions:** These methods are used when the primary goal is to determine if there is a significant effect, difference, or association without necessarily predicting outcomes. For example: -->\n\n<!--     - Is there a significant difference in mean test scores between two groups? -->\n<!--     - Is there an association between two categorical variables? -->\n<!--     - Are two variables correlated? -->\n\n<!-- **Regressions (All Various Types):** -->\n\n<!-- - **Purpose:** Used to model relationships between a dependent (response) variable and one or more independent (predictor) variables, often with the goal of predicting the outcome variable or understanding the effect of predictors. -->\n\n<!-- - **Example Methods:** Linear regression, logistic regression, Poisson regression, mixed-effects models, generalised additive models (GAMs), etc. -->\n\n<!-- - **Research Questions:** These methods are used when the primary goal is to predict an outcome variable based on one or more predictors or to understand the magnitude and direction of the effect of predictors on an outcome. For example: -->\n\n<!--     - How does the amount of study time predict test scores? -->\n<!--     - What factors influence the probability of disease presence? -->\n<!--     - How do multiple environmental variables affect species abundance? -->\n\n<!-- **Decision Point:** -->\n\n<!-- - **If the goal is to understand and quantify the relationship between variables by constructing models that can be used to predict or assess the impact of predictors on an outcome variable, regression methods are appropriate.** -->\n\n<!-- - **If the goal is to test for differences between groups, associations between categorical variables, or simple relationships without prediction or complex modelling, other inferential statistical methods are appropriate.** -->\n\n",
    "supporting": [
      "intro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{\"knit_meta_id\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]}},\"value\":[{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"booktabs\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"longtable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"array\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"multirow\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"wrapfig\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"float\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"colortbl\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"pdflscape\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"tabu\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttable\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"threeparttablex\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"ulem\"]},{\"type\":\"character\",\"attributes\":{},\"value\":[\"normalem\"]},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"makecell\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]},{\"type\":\"list\",\"attributes\":{\"names\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"name\",\"options\",\"extra_lines\"]},\"class\":{\"type\":\"character\",\"attributes\":{},\"value\":[\"latex_dependency\"]}},\"value\":[{\"type\":\"character\",\"attributes\":{},\"value\":[\"xcolor\"]},{\"type\":\"NULL\"},{\"type\":\"NULL\"}]}]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}